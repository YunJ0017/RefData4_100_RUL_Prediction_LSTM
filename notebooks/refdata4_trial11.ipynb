{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdcace53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "[SEED 9819123] device=cuda\n",
      "[SEED 9819123] out=./Trial11\\seed_9819123\n",
      "==============================\n",
      "[SEED 9819123] [001/300] train_weighted_mse=0.039145 | val_rmse_cycles=3303.883 | val_mae_cycles=2457.076 | best_val_rmse_cycles=3303.883\n",
      "[SEED 9819123] [010/300] train_weighted_mse=0.049197 | val_rmse_cycles=3153.491 | val_mae_cycles=2336.496 | best_val_rmse_cycles=3126.093\n",
      "[SEED 9819123] [020/300] train_weighted_mse=0.021909 | val_rmse_cycles=3233.410 | val_mae_cycles=2385.679 | best_val_rmse_cycles=3113.272\n",
      "[SEED 9819123] [030/300] train_weighted_mse=0.020806 | val_rmse_cycles=3461.328 | val_mae_cycles=2415.187 | best_val_rmse_cycles=3091.084\n",
      "[SEED 9819123] [040/300] train_weighted_mse=0.016961 | val_rmse_cycles=3621.615 | val_mae_cycles=2432.724 | best_val_rmse_cycles=3091.084\n",
      "[SEED 9819123] [050/300] train_weighted_mse=0.004363 | val_rmse_cycles=3423.581 | val_mae_cycles=2375.014 | best_val_rmse_cycles=3091.084\n",
      "[SEED 9819123] Early stopping at epoch 59.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_41012\\1991876804.py:774: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 9819123] best_by_val_cycles: VAL rmse_cycles=3091.084, mae_cycles=2288.161 | TEST rmse_cycles=1647.133, mae_cycles=1133.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_41012\\1991876804.py:774: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 9819123] last_epoch: VAL rmse_cycles=3625.272, mae_cycles=2480.304 | TEST rmse_cycles=2056.218, mae_cycles=1367.794\n",
      "\n",
      "==============================\n",
      "[SEED 111] device=cuda\n",
      "[SEED 111] out=./Trial11\\seed_111\n",
      "==============================\n",
      "[SEED 111] [001/300] train_weighted_mse=0.044485 | val_rmse_cycles=3762.690 | val_mae_cycles=2563.945 | best_val_rmse_cycles=3762.690\n",
      "[SEED 111] [010/300] train_weighted_mse=0.023880 | val_rmse_cycles=3994.176 | val_mae_cycles=2724.106 | best_val_rmse_cycles=3719.708\n",
      "[SEED 111] [020/300] train_weighted_mse=0.019884 | val_rmse_cycles=4016.354 | val_mae_cycles=2734.159 | best_val_rmse_cycles=3719.708\n",
      "[SEED 111] [030/300] train_weighted_mse=0.014272 | val_rmse_cycles=4689.584 | val_mae_cycles=3029.132 | best_val_rmse_cycles=3719.708\n",
      "[SEED 111] Early stopping at epoch 32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_41012\\1991876804.py:774: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 111] best_by_val_cycles: VAL rmse_cycles=3719.708, mae_cycles=2517.583 | TEST rmse_cycles=3694.665, mae_cycles=2292.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_41012\\1991876804.py:774: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 111] last_epoch: VAL rmse_cycles=4929.633, mae_cycles=3202.295 | TEST rmse_cycles=2714.217, mae_cycles=1702.677\n",
      "\n",
      "==============================\n",
      "[SEED 222] device=cuda\n",
      "[SEED 222] out=./Trial11\\seed_222\n",
      "==============================\n",
      "[SEED 222] [001/300] train_weighted_mse=0.037182 | val_rmse_cycles=2567.027 | val_mae_cycles=1742.052 | best_val_rmse_cycles=2567.027\n",
      "[SEED 222] [010/300] train_weighted_mse=0.022092 | val_rmse_cycles=2641.186 | val_mae_cycles=1715.973 | best_val_rmse_cycles=2541.242\n",
      "[SEED 222] [020/300] train_weighted_mse=0.019378 | val_rmse_cycles=2562.231 | val_mae_cycles=1633.343 | best_val_rmse_cycles=2400.351\n",
      "[SEED 222] [030/300] train_weighted_mse=0.007679 | val_rmse_cycles=2727.231 | val_mae_cycles=1712.680 | best_val_rmse_cycles=2400.351\n",
      "[SEED 222] [040/300] train_weighted_mse=0.000622 | val_rmse_cycles=2782.379 | val_mae_cycles=1766.637 | best_val_rmse_cycles=2400.351\n",
      "[SEED 222] Early stopping at epoch 47.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_41012\\1991876804.py:774: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 222] best_by_val_cycles: VAL rmse_cycles=2400.351, mae_cycles=1589.989 | TEST rmse_cycles=2691.902, mae_cycles=1891.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_41012\\1991876804.py:774: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 222] last_epoch: VAL rmse_cycles=2720.179, mae_cycles=1732.897 | TEST rmse_cycles=3515.189, mae_cycles=2415.670\n",
      "\n",
      "==============================\n",
      "[SEED 333] device=cuda\n",
      "[SEED 333] out=./Trial11\\seed_333\n",
      "==============================\n",
      "[SEED 333] [001/300] train_weighted_mse=0.041292 | val_rmse_cycles=2400.113 | val_mae_cycles=1619.334 | best_val_rmse_cycles=2400.113\n",
      "[SEED 333] [010/300] train_weighted_mse=0.024098 | val_rmse_cycles=2437.700 | val_mae_cycles=1633.408 | best_val_rmse_cycles=2279.313\n",
      "[SEED 333] [020/300] train_weighted_mse=0.020821 | val_rmse_cycles=2345.180 | val_mae_cycles=1610.575 | best_val_rmse_cycles=2254.316\n",
      "[SEED 333] [030/300] train_weighted_mse=0.014833 | val_rmse_cycles=2770.773 | val_mae_cycles=1755.308 | best_val_rmse_cycles=2254.316\n",
      "[SEED 333] [040/300] train_weighted_mse=0.000980 | val_rmse_cycles=2968.037 | val_mae_cycles=1953.960 | best_val_rmse_cycles=2254.316\n",
      "[SEED 333] Early stopping at epoch 44.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_41012\\1991876804.py:774: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 333] best_by_val_cycles: VAL rmse_cycles=2254.316, mae_cycles=1569.147 | TEST rmse_cycles=1827.847, mae_cycles=1161.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_41012\\1991876804.py:774: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 333] last_epoch: VAL rmse_cycles=2913.581, mae_cycles=1924.587 | TEST rmse_cycles=1809.710, mae_cycles=1102.009\n",
      "\n",
      "==============================\n",
      "[SEED 444] device=cuda\n",
      "[SEED 444] out=./Trial11\\seed_444\n",
      "==============================\n",
      "[SEED 444] [001/300] train_weighted_mse=0.039325 | val_rmse_cycles=3348.574 | val_mae_cycles=2096.386 | best_val_rmse_cycles=3348.574\n",
      "[SEED 444] [010/300] train_weighted_mse=0.022599 | val_rmse_cycles=3631.418 | val_mae_cycles=2254.189 | best_val_rmse_cycles=3348.574\n",
      "[SEED 444] [020/300] train_weighted_mse=0.022335 | val_rmse_cycles=3528.354 | val_mae_cycles=2180.479 | best_val_rmse_cycles=3348.574\n",
      "[SEED 444] [030/300] train_weighted_mse=0.021057 | val_rmse_cycles=3564.005 | val_mae_cycles=2198.192 | best_val_rmse_cycles=3348.574\n",
      "[SEED 444] Early stopping at epoch 31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_41012\\1991876804.py:774: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 444] best_by_val_cycles: VAL rmse_cycles=3348.574, mae_cycles=2096.386 | TEST rmse_cycles=2226.443, mae_cycles=1599.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_41012\\1991876804.py:774: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 444] last_epoch: VAL rmse_cycles=3513.876, mae_cycles=2195.907 | TEST rmse_cycles=2288.341, mae_cycles=1616.769\n",
      "=== WIN-RATE SUMMARY (TEST; lower is better) ===\n",
      "- test_mae_cycles: last wins=2, best wins=3, ties=0 | mean(last-best)=25.073159, std(last-best)=368.300410\n",
      "- test_rmse_cycles: last wins=2, best wins=3, ties=0 | mean(last-best)=59.137110, std(last-best)=598.849377\n",
      "- test_mae_norm: last wins=3, best wins=2, ties=0 | mean(last-best)=-0.002238, std(last-best)=0.022262\n",
      "- test_rmse_norm: last wins=2, best wins=3, ties=0 | mean(last-best)=-0.000548, std(last-best)=0.027496\n",
      "\n",
      "=== MEAN ± STD across seeds (TEST) ===\n",
      "                   test_mae_cycles             test_rmse_cycles              \\\n",
      "                              mean         std             mean         std   \n",
      "checkpoint                                                                    \n",
      "best_by_val_cycles     1615.910613  493.331646      2417.598136  819.161740   \n",
      "last_epoch             1640.983772  492.355836      2476.735246  669.334321   \n",
      "\n",
      "                   test_mae_norm           test_rmse_norm            \n",
      "                            mean       std           mean       std  \n",
      "checkpoint                                                           \n",
      "best_by_val_cycles      0.123064  0.027223       0.156953  0.032471  \n",
      "last_epoch              0.120826  0.011915       0.156405  0.012419  \n",
      "\n",
      "Saved:\n",
      " - ./Trial11\\summary_across_seeds.csv\n",
      " - ./Trial11\\win_rate_summary.csv\n",
      " - ./Trial11\\win_rate_summary.txt\n",
      "\n",
      "DONE. Check Trial11 folder:\n",
      " - per seed results: Trial11/seed_<seed>/...\n",
      " - paper figures: seed_<seed>/<ckpt>/paper_figures/<split>/\n",
      " - cycle seq mean: <ckpt>/<split>_cycle_sequence_mean.csv\n",
      " - PH/α–λ metrics: <ckpt>/<split>_prognostics_metrics_per_file.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Trial11: Trial10 + (OPTION 1) Weighted Cycle-Loss (recommended)\n",
    "# - Goal: keep \"cycle-scale training/selection\" BUT remove RUL0-scale dominance\n",
    "#\n",
    "# 핵심 변경 (vs Trial10):\n",
    "#   1) Training loss:\n",
    "#        Trial10: MSE(pred_cycles, y_cycles)\n",
    "#        Trial11: MSE( (pred_cycles - y_cycles) / rul0 , 0 )  == mean( ((pred_cycles-y_cycles)/rul0)^2 )\n",
    "#      => 파일별 RUL0 크기에 덜 끌리고, 일반화가 좋아질 확률↑\n",
    "#\n",
    "#   2) Best checkpoint rule 그대로:\n",
    "#        best_by_val_cycles (val_rmse_cycles 최소)\n",
    "#\n",
    "# - EVAL ONLY (from Trial9) 그대로 포함:\n",
    "#     * windows -> cycle mean representative\n",
    "#     * PH / α–λ / CRA / convergence\n",
    "#     * paper-style figures (α+PH, α–λ single λ)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0) Reproducibility\n",
    "# ============================================================\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Config (Trial11)\n",
    "# ============================================================\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_dir: str = r\"C:\\Users\\11HOME_AHCI\\Desktop\\PoF\\Winter 2026\\Ref Data4\\100\"\n",
    "    out_dir: str = r\"./Trial11\"\n",
    "\n",
    "    # seeds to sweep\n",
    "    seeds: Tuple[int, ...] = (9819123, 111, 222, 333, 444)\n",
    "\n",
    "    # sliding window\n",
    "    seq_len: int = 100\n",
    "    stride: int = 5\n",
    "    pred_horizon: int = 0\n",
    "\n",
    "    # split by FILE\n",
    "    train_ratio: float = 0.7\n",
    "    val_ratio: float = 0.2\n",
    "    test_ratio: float = 0.1\n",
    "\n",
    "    # training\n",
    "    batch_size: int = 512\n",
    "    epochs: int = 300\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 0.0\n",
    "    patience: int = 30\n",
    "    grad_clip: float = 1.0\n",
    "\n",
    "    # model\n",
    "    hidden_size: int = 512\n",
    "    num_layers: int = 2\n",
    "    dropout: float = 0.2\n",
    "\n",
    "    # output controls\n",
    "    save_figures: bool = True\n",
    "    max_files_to_plot: Optional[int] = None  # None=all\n",
    "    num_workers: int = 0\n",
    "\n",
    "    # ===========================\n",
    "    # Trial11: Weighted cycle-loss settings\n",
    "    # ===========================\n",
    "    eps_rul0: float = 1e-8  # avoid div by zero\n",
    "\n",
    "    # ===========================\n",
    "    # Evaluation settings (from Trial9)\n",
    "    # ===========================\n",
    "    alpha: float = 0.20\n",
    "    ph_consecutive_m: int = 5\n",
    "    rep_method: str = \"mean\"\n",
    "    lambdas: Tuple[float, ...] = (0.2, 0.4, 0.6, 0.8)\n",
    "    lambda_to_plot: float = 0.6\n",
    "    eps_rul: float = 1e-8\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Data utils\n",
    "# ============================================================\n",
    "def list_csv_files(data_dir: str) -> List[Path]:\n",
    "    p = Path(data_dir)\n",
    "    files = sorted([f for f in p.glob(\"*.csv\") if f.is_file()])\n",
    "    if len(files) == 0:\n",
    "        raise FileNotFoundError(f\"No CSV files found in: {data_dir}\")\n",
    "    return files\n",
    "\n",
    "\n",
    "def read_one_csv(csv_path: Path) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    df = pd.read_csv(csv_path, header=None)\n",
    "    if df.shape[1] < 2:\n",
    "        raise ValueError(f\"{csv_path.name}: expected at least 2 columns, got {df.shape[1]}\")\n",
    "\n",
    "    vce = df.iloc[:, 0].astype(np.float32).to_numpy()\n",
    "    rul = df.iloc[:, 1].astype(np.float32).to_numpy()\n",
    "\n",
    "    if len(vce) != len(rul):\n",
    "        raise ValueError(f\"{csv_path.name}: length mismatch vce={len(vce)}, rul={len(rul)}\")\n",
    "    if len(vce) < 5:\n",
    "        raise ValueError(f\"{csv_path.name}: too short sequence length={len(vce)}\")\n",
    "\n",
    "    return vce, rul\n",
    "\n",
    "\n",
    "def split_files(\n",
    "    files: List[Path],\n",
    "    train_ratio: float,\n",
    "    val_ratio: float,\n",
    "    test_ratio: float,\n",
    "    seed: int\n",
    ") -> Dict[str, List[Path]]:\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-9\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "    files_shuffled = files[:]\n",
    "    rng.shuffle(files_shuffled)\n",
    "\n",
    "    n = len(files_shuffled)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "\n",
    "    train_files = files_shuffled[:n_train]\n",
    "    val_files = files_shuffled[n_train:n_train + n_val]\n",
    "    test_files = files_shuffled[n_train + n_val:]\n",
    "\n",
    "    return {\"train\": train_files, \"val\": val_files, \"test\": test_files}\n",
    "\n",
    "\n",
    "def compute_dvce(vce: np.ndarray) -> np.ndarray:\n",
    "    dv = np.zeros_like(vce, dtype=np.float32)\n",
    "    dv[1:] = vce[1:] - vce[:-1]\n",
    "    return dv\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Dataset\n",
    "# ============================================================\n",
    "class WindowedRULDatasetNorm2F(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_list: List[Path],\n",
    "        seq_len: int,\n",
    "        stride: int,\n",
    "        pred_horizon: int,\n",
    "        scaler_x: StandardScaler = None,\n",
    "        fit_scaler: bool = False,\n",
    "    ):\n",
    "        self.file_list = file_list\n",
    "        self.seq_len = seq_len\n",
    "        self.stride = stride\n",
    "        self.pred_horizon = pred_horizon\n",
    "        self.scaler_x = scaler_x if scaler_x is not None else StandardScaler()\n",
    "\n",
    "        # store: (name, X2(T,2), rul(T,), rul0)\n",
    "        self.series: List[Tuple[str, np.ndarray, np.ndarray, float]] = []\n",
    "        for fp in self.file_list:\n",
    "            vce, rul = read_one_csv(fp)\n",
    "            rul0 = float(rul[0])\n",
    "            if rul0 <= 0:\n",
    "                raise ValueError(f\"{fp.name}: RUL0 must be > 0, got {rul0}\")\n",
    "\n",
    "            dv = compute_dvce(vce)\n",
    "            x2 = np.stack([vce, dv], axis=1).astype(np.float32)  # (T,2)\n",
    "            self.series.append((fp.name, x2, rul.astype(np.float32), rul0))\n",
    "\n",
    "        if fit_scaler:\n",
    "            all_x = np.concatenate([x2 for _, x2, _, _ in self.series], axis=0)\n",
    "            self.scaler_x.fit(all_x)\n",
    "\n",
    "        # window index\n",
    "        self.index: List[Tuple[int, int]] = []\n",
    "        for fi, (_name, x2, _rul, _rul0) in enumerate(self.series):\n",
    "            T = x2.shape[0]\n",
    "            last_start = T - (seq_len + pred_horizon)\n",
    "            if last_start < 0:\n",
    "                continue\n",
    "            for s in range(0, last_start + 1, stride):\n",
    "                self.index.append((fi, s))\n",
    "\n",
    "        if len(self.index) == 0:\n",
    "            raise ValueError(\"No windows were created. Check seq_len/pred_horizon vs file lengths.\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        fi, s = self.index[idx]\n",
    "        name, x2, rul, rul0 = self.series[fi]\n",
    "\n",
    "        x = x2[s:s + self.seq_len, :]\n",
    "        y_idx = s + self.seq_len - 1 + self.pred_horizon\n",
    "        y_cycles = float(rul[y_idx])\n",
    "        y_norm = np.array([y_cycles / rul0], dtype=np.float32)\n",
    "\n",
    "        x = self.scaler_x.transform(x).astype(np.float32)\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x),\n",
    "            torch.from_numpy(y_norm),\n",
    "            name,\n",
    "            torch.tensor(s, dtype=torch.long),\n",
    "            torch.tensor(y_cycles, dtype=torch.float32),\n",
    "            torch.tensor(rul0, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Model\n",
    "# ============================================================\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 2, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last = out[:, -1, :]\n",
    "        return self.head(last)  # (B,1) norm-scale\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Basic eval + Save window-level predictions\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def evaluate_basic(model, loader, device) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "\n",
    "    mae_norm_list, mse_norm_list = [], []\n",
    "    mae_cyc_list, mse_cyc_list = [], []\n",
    "\n",
    "    for x, y_norm, _name, _s, y_cycles, rul0 in loader:\n",
    "        x = x.to(device)\n",
    "        y_norm = y_norm.to(device)\n",
    "        y_cycles = y_cycles.to(device).view(-1, 1)\n",
    "        rul0 = rul0.to(device).view(-1, 1)\n",
    "\n",
    "        pred_norm = model(x)\n",
    "\n",
    "        # norm metrics\n",
    "        err_norm = pred_norm - y_norm\n",
    "        mae_norm_list.append(torch.mean(torch.abs(err_norm)).item())\n",
    "        mse_norm_list.append(torch.mean(err_norm ** 2).item())\n",
    "\n",
    "        # cycle metrics\n",
    "        pred_cycles = pred_norm * rul0\n",
    "        err_cyc = pred_cycles - y_cycles\n",
    "        mae_cyc_list.append(torch.mean(torch.abs(err_cyc)).item())\n",
    "        mse_cyc_list.append(torch.mean(err_cyc ** 2).item())\n",
    "\n",
    "    return {\n",
    "        \"mae_norm\": float(np.mean(mae_norm_list)) if mae_norm_list else float(\"nan\"),\n",
    "        \"rmse_norm\": float(np.sqrt(np.mean(mse_norm_list))) if mse_norm_list else float(\"nan\"),\n",
    "        \"mae_cycles\": float(np.mean(mae_cyc_list)) if mae_cyc_list else float(\"nan\"),\n",
    "        \"rmse_cycles\": float(np.sqrt(np.mean(mse_cyc_list))) if mse_cyc_list else float(\"nan\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_predictions_windows_csv(model, loader, device, out_csv: str, seq_len: int) -> None:\n",
    "    model.eval()\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    for x, y_norm, name, s, y_cycles, rul0 in loader:\n",
    "        x = x.to(device)\n",
    "        y_norm = y_norm.to(device)\n",
    "        y_cycles = y_cycles.to(device).view(-1, 1)\n",
    "        rul0 = rul0.to(device).view(-1, 1)\n",
    "\n",
    "        pred_norm = model(x)\n",
    "        pred_cycles = pred_norm * rul0\n",
    "\n",
    "        pred_norm_np = pred_norm.cpu().numpy().reshape(-1)\n",
    "        y_norm_np = y_norm.cpu().numpy().reshape(-1)\n",
    "        pred_cyc_np = pred_cycles.cpu().numpy().reshape(-1)\n",
    "        y_cyc_np = y_cycles.cpu().numpy().reshape(-1)\n",
    "\n",
    "        rul0_np = rul0.cpu().numpy().reshape(-1)\n",
    "        s_np = s.cpu().numpy().reshape(-1)\n",
    "        name_list = list(name)\n",
    "\n",
    "        for i in range(len(pred_norm_np)):\n",
    "            rows.append({\n",
    "                \"file\": name_list[i],\n",
    "                \"start_idx\": int(s_np[i]),\n",
    "                \"cycle\": int(s_np[i] + (seq_len - 1)),\n",
    "                \"rul0\": float(rul0_np[i]),\n",
    "                \"RUL_true\": float(y_cyc_np[i]),\n",
    "                \"RUL_pred\": float(pred_cyc_np[i]),\n",
    "                \"RUL_true_norm\": float(y_norm_np[i]),\n",
    "                \"RUL_pred_norm\": float(pred_norm_np[i]),\n",
    "            })\n",
    "\n",
    "    pd.DataFrame(rows).to_csv(out_csv, index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Window -> Cycle sequence (mean representative)\n",
    "# ============================================================\n",
    "def windows_to_cycle_sequence_mean(windows_csv: str) -> pd.DataFrame:\n",
    "    dfw = pd.read_csv(windows_csv)\n",
    "    if dfw.empty:\n",
    "        raise ValueError(f\"Empty windows csv: {windows_csv}\")\n",
    "\n",
    "    g = dfw.groupby([\"file\", \"cycle\"], as_index=False).agg(\n",
    "        rul0=(\"rul0\", \"first\"),\n",
    "        RUL_true=(\"RUL_true\", \"mean\"),\n",
    "        RUL_pred=(\"RUL_pred\", \"mean\"),\n",
    "        n_windows=(\"RUL_pred\", \"count\"),\n",
    "    )\n",
    "    return g\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) Prognostics metrics (PH / α–λ / CRA / convergence)\n",
    "# ============================================================\n",
    "def compute_metrics_for_one_file(\n",
    "    df_seq_one_file: pd.DataFrame,\n",
    "    seq_len: int,\n",
    "    alpha: float,\n",
    "    ph_consecutive_m: int,\n",
    "    lambdas: Tuple[float, ...],\n",
    "    eps_rul: float,\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    df = df_seq_one_file.sort_values(\"cycle\").reset_index(drop=True).copy()\n",
    "\n",
    "    t_s = seq_len - 1\n",
    "    last_cycle = int(df[\"cycle\"].max())\n",
    "    EOL_true = last_cycle + 1\n",
    "    t_e = EOL_true - 1\n",
    "\n",
    "    df_eval = df[(df[\"cycle\"] >= t_s) & (df[\"cycle\"] <= t_e)].copy()\n",
    "    df_eval.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if df_eval.empty:\n",
    "        summary = {\n",
    "            \"t_s\": t_s, \"t_e\": t_e, \"EOL_true\": EOL_true,\n",
    "            \"PH\": np.nan, \"t_PH_start\": np.nan,\n",
    "            \"CRA\": np.nan, \"Convergence_cycles\": np.nan,\n",
    "        }\n",
    "        for lam in lambdas:\n",
    "            summary[f\"t_lambda_{lam:.2f}\"] = np.nan\n",
    "            summary[f\"alpha_lambda_ok_{lam:.2f}\"] = np.nan\n",
    "        return df_eval, summary\n",
    "\n",
    "    denom = np.maximum(np.abs(df_eval[\"RUL_true\"].values), eps_rul)\n",
    "    rel_err = np.abs(df_eval[\"RUL_true\"].values - df_eval[\"RUL_pred\"].values) / denom\n",
    "    RA = 1.0 - rel_err\n",
    "\n",
    "    df_eval[\"rel_err\"] = rel_err\n",
    "    df_eval[\"RA\"] = RA\n",
    "    df_eval[\"in_alpha\"] = df_eval[\"rel_err\"] <= alpha\n",
    "\n",
    "    CRA = float(np.mean(df_eval[\"RA\"].values))\n",
    "\n",
    "    # PH start: M consecutive in_alpha\n",
    "    flags = df_eval[\"in_alpha\"].values.astype(np.int32)\n",
    "    t_PH_start = np.nan\n",
    "    if len(flags) >= ph_consecutive_m:\n",
    "        run = 0\n",
    "        for i, ok in enumerate(flags):\n",
    "            if ok:\n",
    "                run += 1\n",
    "                if run >= ph_consecutive_m:\n",
    "                    start_i = i - ph_consecutive_m + 1\n",
    "                    t_PH_start = int(df_eval.loc[start_i, \"cycle\"])\n",
    "                    break\n",
    "            else:\n",
    "                run = 0\n",
    "\n",
    "    if np.isfinite(t_PH_start):\n",
    "        PH = float(EOL_true - t_PH_start)\n",
    "        Convergence_cycles = float(t_PH_start - t_s)\n",
    "    else:\n",
    "        PH = np.nan\n",
    "        Convergence_cycles = np.nan\n",
    "\n",
    "    # α–λ\n",
    "    rul0 = float(df_eval[\"rul0\"].iloc[0])\n",
    "    lam_results = {}\n",
    "    for lam in lambdas:\n",
    "        target_rul = (1.0 - float(lam)) * rul0\n",
    "        idx = int(np.argmin(np.abs(df_eval[\"RUL_true\"].values - target_rul)))\n",
    "        t_lam = int(df_eval.loc[idx, \"cycle\"])\n",
    "        ok = bool(df_eval.loc[idx, \"rel_err\"] <= alpha)\n",
    "\n",
    "        lam_results[f\"t_lambda_{lam:.2f}\"] = t_lam\n",
    "        lam_results[f\"alpha_lambda_ok_{lam:.2f}\"] = int(ok)\n",
    "\n",
    "    summary = {\n",
    "        \"t_s\": int(t_s),\n",
    "        \"t_e\": int(t_e),\n",
    "        \"EOL_true\": int(EOL_true),\n",
    "        \"alpha\": float(alpha),\n",
    "        \"ph_consecutive_m\": int(ph_consecutive_m),\n",
    "        \"CRA\": CRA,\n",
    "        \"t_PH_start\": t_PH_start if np.isfinite(t_PH_start) else np.nan,\n",
    "        \"PH\": PH,\n",
    "        \"Convergence_cycles\": Convergence_cycles,\n",
    "        **lam_results\n",
    "    }\n",
    "    return df_eval, summary\n",
    "\n",
    "\n",
    "def compute_metrics_from_windows_csv(\n",
    "    windows_csv: str,\n",
    "    seq_len: int,\n",
    "    alpha: float,\n",
    "    ph_consecutive_m: int,\n",
    "    lambdas: Tuple[float, ...],\n",
    "    eps_rul: float,\n",
    "    out_dir: str,\n",
    "    split_name: str,\n",
    ") -> Tuple[str, str]:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    df_seq = windows_to_cycle_sequence_mean(windows_csv)\n",
    "    seq_path = os.path.join(out_dir, f\"{split_name}_cycle_sequence_mean.csv\")\n",
    "    df_seq.to_csv(seq_path, index=False)\n",
    "\n",
    "    rows = []\n",
    "    for f in df_seq[\"file\"].unique():\n",
    "        sub = df_seq[df_seq[\"file\"] == f].copy()\n",
    "        _df_eval, summary = compute_metrics_for_one_file(\n",
    "            df_seq_one_file=sub,\n",
    "            seq_len=seq_len,\n",
    "            alpha=alpha,\n",
    "            ph_consecutive_m=ph_consecutive_m,\n",
    "            lambdas=lambdas,\n",
    "            eps_rul=eps_rul,\n",
    "        )\n",
    "        summary[\"file\"] = f\n",
    "        rows.append(summary)\n",
    "\n",
    "    dfm = pd.DataFrame(rows)\n",
    "    metrics_path = os.path.join(out_dir, f\"{split_name}_prognostics_metrics_per_file.csv\")\n",
    "    dfm.to_csv(metrics_path, index=False)\n",
    "\n",
    "    return seq_path, metrics_path\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) Plotters\n",
    "# ============================================================\n",
    "def _safe_name(s: str) -> str:\n",
    "    return s.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "\n",
    "def plot_alpha_ph(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    title: str,\n",
    "    alpha: float,\n",
    "    PH_start: Optional[float],\n",
    "    out_path: str,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.figure()\n",
    "\n",
    "    x = df_eval[\"cycle\"].values\n",
    "    y_true = df_eval[\"RUL_true\"].values\n",
    "    y_pred = df_eval[\"RUL_pred\"].values\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.plot(x, y_true, color=\"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, color=\"r\", label=\"Prediction (cycles)\")\n",
    "    plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} alpha accuracy zone\")\n",
    "    plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} alpha accuracy zone\")\n",
    "\n",
    "    if PH_start is not None and np.isfinite(PH_start):\n",
    "        plt.axvline(int(PH_start), color=\"g\", linestyle=\"-.\", label=\"PH start\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title}\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_alpha_lambda(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    title: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    t_lambda: Optional[int],\n",
    "    out_path: str,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.figure()\n",
    "\n",
    "    x = df_eval[\"cycle\"].values\n",
    "    y_true = df_eval[\"RUL_true\"].values\n",
    "    y_pred = df_eval[\"RUL_pred\"].values\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.plot(x, y_true, color=\"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, color=\"r\", label=\"Prediction (cycles)\")\n",
    "\n",
    "    if t_lambda is not None and np.isfinite(t_lambda):\n",
    "        t_lambda = int(t_lambda)\n",
    "        plt.axvline(t_lambda, linestyle=\":\", color=\"g\", label=f\"t_λ (λ={lambda_to_plot:.2f})\")\n",
    "        mask = x >= t_lambda\n",
    "        if np.any(mask):\n",
    "            plt.plot(x[mask], upper[mask], color=\"b\", linestyle=\"--\",\n",
    "                     label=f\"+{alpha:.2f} alpha–lambda accuracy zone\")\n",
    "            plt.plot(x[mask], lower[mask], color=\"b\", linestyle=\"--\",\n",
    "                     label=f\"-{alpha:.2f} alpha–lambda accuracy zone\")\n",
    "        else:\n",
    "            plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} α zone\")\n",
    "            plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} α zone\")\n",
    "    else:\n",
    "        plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} α zone\")\n",
    "        plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} α zone\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title}\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def make_paper_figures_for_split(\n",
    "    cycle_seq_csv: str,\n",
    "    metrics_per_file_csv: str,\n",
    "    out_fig_dir: str,\n",
    "    title_prefix: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    max_files: Optional[int] = None,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    df_seq = pd.read_csv(cycle_seq_csv)\n",
    "    dfm = pd.read_csv(metrics_per_file_csv)\n",
    "\n",
    "    files = df_seq[\"file\"].unique().tolist()\n",
    "    if max_files is not None:\n",
    "        files = files[:max_files]\n",
    "\n",
    "    os.makedirs(out_fig_dir, exist_ok=True)\n",
    "\n",
    "    lam_key = f\"t_lambda_{lambda_to_plot:.2f}\"\n",
    "\n",
    "    for f in files:\n",
    "        sub = df_seq[df_seq[\"file\"] == f].sort_values(\"cycle\").copy()\n",
    "        mrow = dfm[dfm[\"file\"] == f]\n",
    "        if mrow.empty:\n",
    "            continue\n",
    "        mrow = mrow.iloc[0].to_dict()\n",
    "\n",
    "        t_s = int(mrow[\"t_s\"])\n",
    "        t_e = int(mrow[\"t_e\"])\n",
    "        PH_start = mrow.get(\"t_PH_start\", np.nan)\n",
    "\n",
    "        df_eval = sub[(sub[\"cycle\"] >= t_s) & (sub[\"cycle\"] <= t_e)].copy()\n",
    "        if df_eval.empty:\n",
    "            continue\n",
    "\n",
    "        t_lambda = None\n",
    "        if lam_key in mrow and np.isfinite(mrow[lam_key]):\n",
    "            t_lambda = int(mrow[lam_key])\n",
    "\n",
    "        safe = _safe_name(f)\n",
    "\n",
    "        out1 = os.path.join(out_fig_dir, f\"FIG1_alpha_PH__{safe}.png\")\n",
    "        plot_alpha_ph(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            title=f\"{title_prefix} | α+PH\",\n",
    "            alpha=alpha,\n",
    "            PH_start=PH_start if np.isfinite(PH_start) else None,\n",
    "            out_path=out1,\n",
    "            dpi=dpi,\n",
    "        )\n",
    "\n",
    "        out2 = os.path.join(out_fig_dir, f\"FIG2_alpha_lambda__lam{lambda_to_plot:.2f}__{safe}.png\")\n",
    "        plot_alpha_lambda(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            title=f\"{title_prefix} | α–λ (λ={lambda_to_plot:.2f})\",\n",
    "            alpha=alpha,\n",
    "            lambda_to_plot=lambda_to_plot,\n",
    "            t_lambda=t_lambda,\n",
    "            out_path=out2,\n",
    "            dpi=dpi,\n",
    "        )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9) One seed run (Trial11 training + Trial9 eval outputs)\n",
    "# ============================================================\n",
    "def run_one_seed(cfg: Config, seed: int) -> Dict[str, Any]:\n",
    "    set_seed(seed)\n",
    "\n",
    "    seed_dir = os.path.join(cfg.out_dir, f\"seed_{seed}\")\n",
    "    os.makedirs(seed_dir, exist_ok=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"[SEED {seed}] device={device}\")\n",
    "    print(f\"[SEED {seed}] out={seed_dir}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    # split\n",
    "    files = list_csv_files(cfg.data_dir)\n",
    "    splits = split_files(files, cfg.train_ratio, cfg.val_ratio, cfg.test_ratio, seed)\n",
    "\n",
    "    # save split lists\n",
    "    for k in [\"train\", \"val\", \"test\"]:\n",
    "        pd.Series([p.name for p in splits[k]]).to_csv(\n",
    "            os.path.join(seed_dir, f\"{k}_files.csv\"), index=False, header=False\n",
    "        )\n",
    "\n",
    "    # datasets (fit scaler on train only)\n",
    "    scaler_x = StandardScaler()\n",
    "    train_ds = WindowedRULDatasetNorm2F(\n",
    "        splits[\"train\"], cfg.seq_len, cfg.stride, cfg.pred_horizon,\n",
    "        scaler_x=scaler_x, fit_scaler=True\n",
    "    )\n",
    "    val_ds = WindowedRULDatasetNorm2F(\n",
    "        splits[\"val\"], cfg.seq_len, cfg.stride, cfg.pred_horizon,\n",
    "        scaler_x=train_ds.scaler_x, fit_scaler=False\n",
    "    )\n",
    "    test_ds = WindowedRULDatasetNorm2F(\n",
    "        splits[\"test\"], cfg.seq_len, cfg.stride, cfg.pred_horizon,\n",
    "        scaler_x=train_ds.scaler_x, fit_scaler=False\n",
    "    )\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"feature\": [\"min_vce\", \"d_min_vce\"],\n",
    "        \"mean\": train_ds.scaler_x.mean_.ravel(),\n",
    "        \"std\": np.sqrt(train_ds.scaler_x.var_).ravel(),\n",
    "    }).to_csv(os.path.join(seed_dir, \"scaler_x_mean_std.csv\"), index=False)\n",
    "\n",
    "    # loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True,  num_workers=cfg.num_workers)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "\n",
    "    train_eval = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "    val_eval   = DataLoader(val_ds,   batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "    test_eval  = DataLoader(test_ds,  batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "\n",
    "    # model\n",
    "    model = LSTMRegressor(\n",
    "        input_size=2,\n",
    "        hidden_size=cfg.hidden_size,\n",
    "        num_layers=cfg.num_layers,\n",
    "        dropout=cfg.dropout,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "    # best checkpoint rule: val_rmse_cycles\n",
    "    best_by_val_cycles = float(\"inf\")\n",
    "    best_path = os.path.join(seed_dir, \"best_by_val_cycles.pt\")\n",
    "    last_path = os.path.join(seed_dir, \"last_epoch.pt\")\n",
    "\n",
    "    history: List[Dict[str, Any]] = []\n",
    "    bad_epochs = 0\n",
    "\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        model.train()\n",
    "        losses = []\n",
    "\n",
    "        for x, _y_norm, _name, _s, y_cycles, rul0 in train_loader:\n",
    "            x = x.to(device)\n",
    "            y_cycles = y_cycles.to(device).view(-1, 1)\n",
    "            rul0 = rul0.to(device).view(-1, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_norm = model(x)\n",
    "            pred_cycles = pred_norm * rul0\n",
    "\n",
    "            # ============================\n",
    "            # Trial11 핵심: weighted cycle-loss\n",
    "            # loss = mean( ((pred_cycles - y_cycles)/rul0)^2 )\n",
    "            # ============================\n",
    "            denom = torch.clamp(rul0, min=cfg.eps_rul0)\n",
    "            err_norm_like = (pred_cycles - y_cycles) / denom\n",
    "            loss = torch.mean(err_norm_like ** 2)\n",
    "\n",
    "            loss.backward()\n",
    "            if cfg.grad_clip and cfg.grad_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        train_weighted_mse = float(np.mean(losses)) if losses else float(\"nan\")\n",
    "        val_metrics = evaluate_basic(model, val_loader, device)\n",
    "\n",
    "        history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_weighted_mse\": train_weighted_mse,\n",
    "            \"val_rmse_cycles\": val_metrics[\"rmse_cycles\"],\n",
    "            \"val_mae_cycles\": val_metrics[\"mae_cycles\"],\n",
    "            \"val_rmse_norm\": val_metrics[\"rmse_norm\"],\n",
    "            \"val_mae_norm\": val_metrics[\"mae_norm\"],\n",
    "        })\n",
    "\n",
    "        # best 기준: val_rmse_cycles\n",
    "        if val_metrics[\"rmse_cycles\"] < best_by_val_cycles:\n",
    "            best_by_val_cycles = val_metrics[\"rmse_cycles\"]\n",
    "            bad_epochs = 0\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(\n",
    "                f\"[SEED {seed}] [{epoch:03d}/{cfg.epochs}] \"\n",
    "                f\"train_weighted_mse={train_weighted_mse:.6f} | \"\n",
    "                f\"val_rmse_cycles={val_metrics['rmse_cycles']:.3f} | \"\n",
    "                f\"val_mae_cycles={val_metrics['mae_cycles']:.3f} | \"\n",
    "                f\"best_val_rmse_cycles={best_by_val_cycles:.3f}\"\n",
    "            )\n",
    "\n",
    "        if bad_epochs >= cfg.patience:\n",
    "            print(f\"[SEED {seed}] Early stopping at epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "    pd.DataFrame(history).to_csv(os.path.join(seed_dir, \"history.csv\"), index=False)\n",
    "    torch.save(model.state_dict(), last_path)\n",
    "\n",
    "    def export_ckpt(tag: str, ckpt_path: str) -> Dict[str, Any]:\n",
    "        sub_dir = os.path.join(seed_dir, tag)\n",
    "        os.makedirs(sub_dir, exist_ok=True)\n",
    "\n",
    "        model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        tr = evaluate_basic(model, train_eval, device)\n",
    "        va = evaluate_basic(model, val_eval, device)\n",
    "        te = evaluate_basic(model, test_eval, device)\n",
    "\n",
    "        # save preds + metrics/figures\n",
    "        for split_name, loader in [(\"train\", train_eval), (\"val\", val_eval), (\"test\", test_eval)]:\n",
    "            win_csv = os.path.join(sub_dir, f\"{split_name}_predictions_windows.csv\")\n",
    "            save_predictions_windows_csv(model, loader, device, win_csv, seq_len=cfg.seq_len)\n",
    "\n",
    "            seq_csv, metrics_csv = compute_metrics_from_windows_csv(\n",
    "                windows_csv=win_csv,\n",
    "                seq_len=cfg.seq_len,\n",
    "                alpha=cfg.alpha,\n",
    "                ph_consecutive_m=cfg.ph_consecutive_m,\n",
    "                lambdas=cfg.lambdas,\n",
    "                eps_rul=cfg.eps_rul,\n",
    "                out_dir=sub_dir,\n",
    "                split_name=split_name,\n",
    "            )\n",
    "\n",
    "            if cfg.save_figures:\n",
    "                fig_dir = os.path.join(sub_dir, \"paper_figures\", split_name)\n",
    "                make_paper_figures_for_split(\n",
    "                    cycle_seq_csv=seq_csv,\n",
    "                    metrics_per_file_csv=metrics_csv,\n",
    "                    out_fig_dir=fig_dir,\n",
    "                    title_prefix=f\"SEED {seed} | {tag.upper()} | {split_name}\",\n",
    "                    alpha=cfg.alpha,\n",
    "                    lambda_to_plot=cfg.lambda_to_plot,\n",
    "                    max_files=cfg.max_files_to_plot,\n",
    "                )\n",
    "\n",
    "        ms = {\n",
    "            \"seed\": seed,\n",
    "            \"checkpoint\": tag,\n",
    "\n",
    "            \"train_rmse_cycles\": tr[\"rmse_cycles\"],\n",
    "            \"train_mae_cycles\": tr[\"mae_cycles\"],\n",
    "            \"train_rmse_norm\": tr[\"rmse_norm\"],\n",
    "            \"train_mae_norm\": tr[\"mae_norm\"],\n",
    "\n",
    "            \"val_rmse_cycles\": va[\"rmse_cycles\"],\n",
    "            \"val_mae_cycles\": va[\"mae_cycles\"],\n",
    "            \"val_rmse_norm\": va[\"rmse_norm\"],\n",
    "            \"val_mae_norm\": va[\"mae_norm\"],\n",
    "\n",
    "            \"test_rmse_cycles\": te[\"rmse_cycles\"],\n",
    "            \"test_mae_cycles\": te[\"mae_cycles\"],\n",
    "            \"test_rmse_norm\": te[\"rmse_norm\"],\n",
    "            \"test_mae_norm\": te[\"mae_norm\"],\n",
    "\n",
    "            \"stopped_epoch\": history[-1][\"epoch\"] if len(history) else None,\n",
    "            \"best_val_rmse_cycles\": best_by_val_cycles,\n",
    "\n",
    "            \"alpha\": cfg.alpha,\n",
    "            \"ph_consecutive_m\": cfg.ph_consecutive_m,\n",
    "            \"rep_method\": cfg.rep_method,\n",
    "            \"lambdas\": str(cfg.lambdas),\n",
    "            \"lambda_to_plot\": cfg.lambda_to_plot,\n",
    "        }\n",
    "        pd.DataFrame([ms]).to_csv(os.path.join(sub_dir, \"metrics_summary.csv\"), index=False)\n",
    "\n",
    "        print(\n",
    "            f\"[SEED {seed}] {tag}: \"\n",
    "            f\"VAL rmse_cycles={va['rmse_cycles']:.3f}, mae_cycles={va['mae_cycles']:.3f} | \"\n",
    "            f\"TEST rmse_cycles={te['rmse_cycles']:.3f}, mae_cycles={te['mae_cycles']:.3f}\"\n",
    "        )\n",
    "        return ms\n",
    "\n",
    "    ms_best = export_ckpt(\"best_by_val_cycles\", best_path)\n",
    "    ms_last = export_ckpt(\"last_epoch\", last_path)\n",
    "\n",
    "    return {\"seed\": seed, \"seed_dir\": seed_dir, \"best\": ms_best, \"last\": ms_last}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10) Seed sweep + global comparison\n",
    "# ============================================================\n",
    "def summarize_across_seeds(cfg: Config, results: List[Dict[str, Any]]) -> None:\n",
    "    rows = []\n",
    "    for r in results:\n",
    "        rows.append(r[\"best\"])\n",
    "        rows.append(r[\"last\"])\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(os.path.join(cfg.out_dir, \"summary_across_seeds.csv\"), index=False)\n",
    "\n",
    "    def _isfinite(x: Any) -> bool:\n",
    "        try:\n",
    "            return bool(np.isfinite(float(x)))\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def win_rate(metric: str) -> Dict[str, Any]:\n",
    "        wins_last = 0\n",
    "        wins_best = 0\n",
    "        ties = 0\n",
    "        diffs = []\n",
    "\n",
    "        for r in results:\n",
    "            b = r[\"best\"][metric]\n",
    "            l = r[\"last\"][metric]\n",
    "            if _isfinite(b) and _isfinite(l):\n",
    "                diffs.append(float(l) - float(b))\n",
    "                if float(l) < float(b):\n",
    "                    wins_last += 1\n",
    "                elif float(b) < float(l):\n",
    "                    wins_best += 1\n",
    "                else:\n",
    "                    ties += 1\n",
    "\n",
    "        return {\n",
    "            \"metric\": metric,\n",
    "            \"wins_last\": wins_last,\n",
    "            \"wins_best\": wins_best,\n",
    "            \"ties\": ties,\n",
    "            \"mean(last-best)\": float(np.mean(diffs)) if diffs else float(\"nan\"),\n",
    "            \"std(last-best)\": float(np.std(diffs)) if diffs else float(\"nan\"),\n",
    "        }\n",
    "\n",
    "    metrics = [\"test_mae_cycles\", \"test_rmse_cycles\", \"test_mae_norm\", \"test_rmse_norm\"]\n",
    "    wr = [win_rate(m) for m in metrics]\n",
    "    pd.DataFrame(wr).to_csv(os.path.join(cfg.out_dir, \"win_rate_summary.csv\"), index=False)\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"=== WIN-RATE SUMMARY (TEST; lower is better) ===\")\n",
    "    for row in wr:\n",
    "        lines.append(\n",
    "            f\"- {row['metric']}: last wins={row['wins_last']}, best wins={row['wins_best']}, ties={row['ties']} | \"\n",
    "            f\"mean(last-best)={row['mean(last-best)']:.6f}, std(last-best)={row['std(last-best)']:.6f}\"\n",
    "        )\n",
    "\n",
    "    agg = df.groupby(\"checkpoint\")[metrics].agg([\"mean\", \"std\"])\n",
    "    lines.append(\"\\n=== MEAN ± STD across seeds (TEST) ===\")\n",
    "    lines.append(str(agg))\n",
    "\n",
    "    with open(os.path.join(cfg.out_dir, \"win_rate_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nSaved:\")\n",
    "    print(\" -\", os.path.join(cfg.out_dir, \"summary_across_seeds.csv\"))\n",
    "    print(\" -\", os.path.join(cfg.out_dir, \"win_rate_summary.csv\"))\n",
    "    print(\" -\", os.path.join(cfg.out_dir, \"win_rate_summary.txt\"))\n",
    "\n",
    "\n",
    "def run_trial11_seed_sweep(cfg: Config) -> None:\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    for seed in cfg.seeds:\n",
    "        res = run_one_seed(cfg, seed)\n",
    "        results.append(res)\n",
    "\n",
    "    summarize_across_seeds(cfg, results)\n",
    "\n",
    "    print(\"\\nDONE. Check Trial11 folder:\")\n",
    "    print(\" - per seed results: Trial11/seed_<seed>/...\")\n",
    "    print(\" - paper figures: seed_<seed>/<ckpt>/paper_figures/<split>/\")\n",
    "    print(\" - cycle seq mean: <ckpt>/<split>_cycle_sequence_mean.csv\")\n",
    "    print(\" - PH/α–λ metrics: <ckpt>/<split>_prognostics_metrics_per_file.csv\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 11) Run\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config(\n",
    "        data_dir=r\"C:\\Users\\11HOME_AHCI\\Desktop\\PoF\\Winter 2026\\Ref Data4\\100\",\n",
    "        out_dir=r\"./Trial11\",\n",
    "\n",
    "        seeds=(9819123, 111, 222, 333, 444),\n",
    "\n",
    "        seq_len=100,\n",
    "        stride=5,\n",
    "        pred_horizon=0,\n",
    "\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.2,\n",
    "        test_ratio=0.1,\n",
    "\n",
    "        batch_size=512,\n",
    "        epochs=300,\n",
    "        lr=1e-3,\n",
    "        weight_decay=0.0,\n",
    "        patience=30,\n",
    "        grad_clip=1.0,\n",
    "\n",
    "        hidden_size=512,\n",
    "        num_layers=2,\n",
    "        dropout=0.2,\n",
    "\n",
    "        save_figures=True,\n",
    "        max_files_to_plot=None,\n",
    "        num_workers=0,\n",
    "\n",
    "        eps_rul0=1e-8,\n",
    "\n",
    "        # eval settings\n",
    "        alpha=0.20,\n",
    "        ph_consecutive_m=5,\n",
    "        rep_method=\"mean\",\n",
    "        lambdas=(0.2, 0.4, 0.6, 0.8),\n",
    "        lambda_to_plot=0.6,\n",
    "    )\n",
    "\n",
    "    run_trial11_seed_sweep(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9528af04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ BEST MODEL (Trial11) ================\n",
      "[SELECTED BY VAL]  (recommended for model selection)\n",
      "  Seed             : 333\n",
      "  Checkpoint       : best_by_val_cycles\n",
      "  VAL  RMSE (cyc)   : 2254.316\n",
      "  VAL  MAE  (cyc)   : 1569.147\n",
      "  VAL  RMSE (norm)  : 0.139227\n",
      "  VAL  MAE  (norm)  : 0.108803\n",
      "  TEST RMSE (cyc)   : 1827.847\n",
      "  TEST MAE  (cyc)   : 1161.938\n",
      "  TEST RMSE (norm)  : 0.175635\n",
      "  TEST MAE  (norm)  : 0.142204\n",
      "\n",
      "[SELECTED BY TEST] (for reporting only; not for tuning)\n",
      "  Seed             : 9819123\n",
      "  Checkpoint       : best_by_val_cycles\n",
      "  TEST RMSE (cyc)   : 1647.133\n",
      "  TEST MAE  (cyc)   : 1133.475\n",
      "  TEST RMSE (norm)  : 0.121155\n",
      "  TEST MAE  (norm)  : 0.094147\n",
      "  VAL  RMSE (cyc)   : 3091.084\n",
      "  VAL  MAE  (cyc)   : 2288.161\n",
      "  VAL  RMSE (norm)  : 0.174583\n",
      "  VAL  MAE  (norm)  : 0.144971\n",
      "\n",
      "---------------- WIN-RATE (last_epoch vs best_by_val_cycles) ----------------\n",
      "- val_rmse_cycles: last wins=0, best wins=5, ties=0 | mean(last-best)=577.701816\n",
      "- test_rmse_cycles: last wins=2, best wins=3, ties=0 | mean(last-best)=59.137110\n",
      "- val_rmse_norm: last wins=1, best wins=4, ties=0 | mean(last-best)=0.014971\n",
      "- test_rmse_norm: last wins=2, best wins=3, ties=0 | mean(last-best)=-0.000548\n",
      "- val_mae_cycles: last wins=0, best wins=5, ties=0 | mean(last-best)=294.944549\n",
      "- test_mae_cycles: last wins=2, best wins=3, ties=0 | mean(last-best)=25.073159\n",
      "- val_mae_norm: last wins=1, best wins=4, ties=0 | mean(last-best)=0.008350\n",
      "- test_mae_norm: last wins=3, best wins=2, ties=0 | mean(last-best)=-0.002238\n",
      "=====================================================\n",
      "\n",
      "Saved -> ./Trial11\\BEST_MODEL_BY_VAL.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================\n",
    "# Trial11 paths\n",
    "# ============================\n",
    "TRIAL11_DIR = \"./Trial11\"\n",
    "SUMMARY_CSV = os.path.join(TRIAL11_DIR, \"summary_across_seeds.csv\")\n",
    "\n",
    "# Trial11 checkpoint tags (same as Trial10)\n",
    "BEST_TAG = \"best_by_val_cycles\"\n",
    "LAST_TAG = \"last_epoch\"\n",
    "\n",
    "\n",
    "def _require_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in summary CSV: {missing}\")\n",
    "\n",
    "\n",
    "def pick_best_row(df: pd.DataFrame, metric_prefix: str = \"val\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    metric_prefix: \"val\" or \"test\"\n",
    "    Sort rule (lower is better):\n",
    "      1) <prefix>_rmse_cycles ascending\n",
    "      2) <prefix>_mae_cycles  ascending\n",
    "    \"\"\"\n",
    "    rmse_col = f\"{metric_prefix}_rmse_cycles\"\n",
    "    mae_col = f\"{metric_prefix}_mae_cycles\"\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", rmse_col, mae_col])\n",
    "\n",
    "    df_sorted = df.sort_values(\n",
    "        by=[rmse_col, mae_col],\n",
    "        ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return df_sorted.iloc[0]\n",
    "\n",
    "\n",
    "def win_rate(df: pd.DataFrame, metric: str) -> dict:\n",
    "    \"\"\"\n",
    "    Compare BEST_TAG vs LAST_TAG within each seed on the given metric (lower is better).\n",
    "    Returns wins for last, wins for best, ties, and mean(last-best).\n",
    "    \"\"\"\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", metric])\n",
    "\n",
    "    wins_last = 0\n",
    "    wins_best = 0\n",
    "    ties = 0\n",
    "    diffs = []\n",
    "\n",
    "    for seed, g in df.groupby(\"seed\"):\n",
    "        ckpts = set(g[\"checkpoint\"].astype(str).values)\n",
    "        if not ({BEST_TAG, LAST_TAG} <= ckpts):\n",
    "            continue\n",
    "\n",
    "        b = float(g.loc[g[\"checkpoint\"] == BEST_TAG, metric].iloc[0])\n",
    "        l = float(g.loc[g[\"checkpoint\"] == LAST_TAG, metric].iloc[0])\n",
    "\n",
    "        if np.isfinite(b) and np.isfinite(l):\n",
    "            diffs.append(l - b)  # negative => last better\n",
    "            if l < b:\n",
    "                wins_last += 1\n",
    "            elif b < l:\n",
    "                wins_best += 1\n",
    "            else:\n",
    "                ties += 1\n",
    "\n",
    "    return {\n",
    "        \"metric\": metric,\n",
    "        \"wins_last\": wins_last,\n",
    "        \"wins_best\": wins_best,\n",
    "        \"ties\": ties,\n",
    "        \"mean(last-best)\": float(np.mean(diffs)) if diffs else float(\"nan\"),\n",
    "        \"std(last-best)\": float(np.std(diffs)) if diffs else float(\"nan\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(SUMMARY_CSV):\n",
    "        raise FileNotFoundError(f\"Not found: {SUMMARY_CSV}\")\n",
    "\n",
    "    df = pd.read_csv(SUMMARY_CSV)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) VAL 기준 best (권장)\n",
    "    # -----------------------------\n",
    "    best_val = pick_best_row(df, metric_prefix=\"val\")\n",
    "    best_val_seed = int(best_val[\"seed\"])\n",
    "    best_val_ckpt = str(best_val[\"checkpoint\"])\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2) TEST 기준 best (참고)\n",
    "    # -----------------------------\n",
    "    best_test = pick_best_row(df, metric_prefix=\"test\")\n",
    "    best_test_seed = int(best_test[\"seed\"])\n",
    "    best_test_ckpt = str(best_test[\"checkpoint\"])\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3) win-rate (seed별 last vs best 비교)\n",
    "    # -----------------------------\n",
    "    wr_val_rmse_cyc = win_rate(df, \"val_rmse_cycles\")\n",
    "    wr_test_rmse_cyc = win_rate(df, \"test_rmse_cycles\")\n",
    "\n",
    "    wr_val_rmse_norm = win_rate(df, \"val_rmse_norm\")\n",
    "    wr_test_rmse_norm = win_rate(df, \"test_rmse_norm\")\n",
    "\n",
    "    # (선택) MAE도 보고 싶으면 켜기\n",
    "    wr_val_mae_cyc = win_rate(df, \"val_mae_cycles\")\n",
    "    wr_test_mae_cyc = win_rate(df, \"test_mae_cycles\")\n",
    "    wr_val_mae_norm = win_rate(df, \"val_mae_norm\")\n",
    "    wr_test_mae_norm = win_rate(df, \"test_mae_norm\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4) 출력\n",
    "    # -----------------------------\n",
    "    print(\"\\n================ BEST MODEL (Trial11) ================\")\n",
    "    print(\"[SELECTED BY VAL]  (recommended for model selection)\")\n",
    "    print(f\"  Seed             : {best_val_seed}\")\n",
    "    print(f\"  Checkpoint       : {best_val_ckpt}\")\n",
    "    print(f\"  VAL  RMSE (cyc)   : {best_val['val_rmse_cycles']:.3f}\")\n",
    "    print(f\"  VAL  MAE  (cyc)   : {best_val['val_mae_cycles']:.3f}\")\n",
    "    print(f\"  VAL  RMSE (norm)  : {best_val['val_rmse_norm']:.6f}\")\n",
    "    print(f\"  VAL  MAE  (norm)  : {best_val['val_mae_norm']:.6f}\")\n",
    "    print(f\"  TEST RMSE (cyc)   : {best_val['test_rmse_cycles']:.3f}\")\n",
    "    print(f\"  TEST MAE  (cyc)   : {best_val['test_mae_cycles']:.3f}\")\n",
    "    print(f\"  TEST RMSE (norm)  : {best_val['test_rmse_norm']:.6f}\")\n",
    "    print(f\"  TEST MAE  (norm)  : {best_val['test_mae_norm']:.6f}\")\n",
    "\n",
    "    print(\"\\n[SELECTED BY TEST] (for reporting only; not for tuning)\")\n",
    "    print(f\"  Seed             : {best_test_seed}\")\n",
    "    print(f\"  Checkpoint       : {best_test_ckpt}\")\n",
    "    print(f\"  TEST RMSE (cyc)   : {best_test['test_rmse_cycles']:.3f}\")\n",
    "    print(f\"  TEST MAE  (cyc)   : {best_test['test_mae_cycles']:.3f}\")\n",
    "    print(f\"  TEST RMSE (norm)  : {best_test['test_rmse_norm']:.6f}\")\n",
    "    print(f\"  TEST MAE  (norm)  : {best_test['test_mae_norm']:.6f}\")\n",
    "    print(f\"  VAL  RMSE (cyc)   : {best_test['val_rmse_cycles']:.3f}\")\n",
    "    print(f\"  VAL  MAE  (cyc)   : {best_test['val_mae_cycles']:.3f}\")\n",
    "    print(f\"  VAL  RMSE (norm)  : {best_test['val_rmse_norm']:.6f}\")\n",
    "    print(f\"  VAL  MAE  (norm)  : {best_test['val_mae_norm']:.6f}\")\n",
    "\n",
    "    print(\"\\n---------------- WIN-RATE (last_epoch vs best_by_val_cycles) ----------------\")\n",
    "    def _print_wr(wr):\n",
    "        print(f\"- {wr['metric']}: last wins={wr['wins_last']}, \"\n",
    "              f\"best wins={wr['wins_best']}, ties={wr['ties']} | \"\n",
    "              f\"mean(last-best)={wr['mean(last-best)']:.6f}\")\n",
    "\n",
    "    _print_wr(wr_val_rmse_cyc)\n",
    "    _print_wr(wr_test_rmse_cyc)\n",
    "    _print_wr(wr_val_rmse_norm)\n",
    "    _print_wr(wr_test_rmse_norm)\n",
    "\n",
    "    # MAE win-rate도 참고로 출력\n",
    "    _print_wr(wr_val_mae_cyc)\n",
    "    _print_wr(wr_test_mae_cyc)\n",
    "    _print_wr(wr_val_mae_norm)\n",
    "    _print_wr(wr_test_mae_norm)\n",
    "\n",
    "    print(\"=====================================================\\n\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5) 기록 저장 (VAL 기준 best)\n",
    "    # -----------------------------\n",
    "    out_txt = os.path.join(TRIAL11_DIR, \"BEST_MODEL_BY_VAL.txt\")\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"BEST MODEL (Trial11) - Selected by VAL (rmse_cycles then mae_cycles)\\n\")\n",
    "        f.write(f\"seed={best_val_seed}\\n\")\n",
    "        f.write(f\"checkpoint={best_val_ckpt}\\n\")\n",
    "        f.write(f\"val_rmse_cycles={best_val['val_rmse_cycles']}\\n\")\n",
    "        f.write(f\"val_mae_cycles={best_val['val_mae_cycles']}\\n\")\n",
    "        f.write(f\"val_rmse_norm={best_val['val_rmse_norm']}\\n\")\n",
    "        f.write(f\"val_mae_norm={best_val['val_mae_norm']}\\n\")\n",
    "        f.write(f\"test_rmse_cycles={best_val['test_rmse_cycles']}\\n\")\n",
    "        f.write(f\"test_mae_cycles={best_val['test_mae_cycles']}\\n\")\n",
    "        f.write(f\"test_rmse_norm={best_val['test_rmse_norm']}\\n\")\n",
    "        f.write(f\"test_mae_norm={best_val['test_mae_norm']}\\n\")\n",
    "\n",
    "        # Trial11 summary에는 eval meta도 같이 들어감 (있으면 저장)\n",
    "        for k in [\"alpha\", \"ph_consecutive_m\", \"rep_method\", \"lambdas\", \"lambda_to_plot\", \"best_val_rmse_cycles\", \"stopped_epoch\"]:\n",
    "            if k in best_val.index:\n",
    "                f.write(f\"{k}={best_val[k]}\\n\")\n",
    "\n",
    "    print(f\"Saved -> {out_txt}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "979208ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] train: λ=0.20:0.729, λ=0.40:0.429, λ=0.60:0.243, λ=0.80:0.229, overall:0.407\n",
      "[OK] val: λ=0.20:0.600, λ=0.40:0.650, λ=0.60:0.350, λ=0.80:0.200, overall:0.450\n",
      "[OK] test: λ=0.20:0.700, λ=0.40:0.600, λ=0.60:0.200, λ=0.80:0.300, overall:0.450\n",
      "\n",
      "==================== DONE ====================\n",
      "Saved:\n",
      " - ./Trial11\\seed_333\\best_by_val_cycles\\alpha_lambda_eval\\alpha_lambda_summary_seed333_best_by_val_cycles.csv\n",
      " - ./Trial11\\seed_333\\best_by_val_cycles\\alpha_lambda_eval\\alpha_lambda_per_file_seed333_best_by_val_cycles.csv\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# USER CONFIG (Trial11)\n",
    "# =========================\n",
    "TRIAL_DIR = r\"./Trial11\"            # Trial11 루트 폴더\n",
    "SEED = 333                          # 선택된 seed\n",
    "\n",
    "# Trial11 checkpoint tag:\n",
    "#  - \"best_by_val_cycles\"  (recommended)\n",
    "#  - \"last_epoch\"\n",
    "CKPT = \"best_by_val_cycles\"\n",
    "\n",
    "SPLITS = [\"train\", \"val\", \"test\"]   # 평가할 split\n",
    "LAM_STRS = [\"0.20\", \"0.40\", \"0.60\", \"0.80\"]\n",
    "\n",
    "# (선택) 후반 λ를 더 중요하게 보고 싶으면 가중치 사용 (기본 None이면 단순 평균)\n",
    "# 예: λ=0.2,0.4,0.6,0.8 가중치 = 1,1,2,3\n",
    "LAMBDA_WEIGHTS = None  # 또는 {\"0.20\": 1, \"0.40\": 1, \"0.60\": 2, \"0.80\": 3}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _require_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "\n",
    "def compute_alpha_lambda_rates(dfm: pd.DataFrame, lam_strs, weights=None) -> dict:\n",
    "    \"\"\"\n",
    "    dfm: <split>_prognostics_metrics_per_file.csv\n",
    "    Returns:\n",
    "      - per-lambda success rate (mean of alpha_lambda_ok_{lam})\n",
    "      - overall mean rate (simple mean or weighted mean)\n",
    "    \"\"\"\n",
    "    rates = {}\n",
    "\n",
    "    # per-lambda\n",
    "    for ls in lam_strs:\n",
    "        col = f\"alpha_lambda_ok_{ls}\"\n",
    "        rates[f\"rate_{ls}\"] = float(dfm[col].mean()) if col in dfm.columns else np.nan\n",
    "\n",
    "    # overall\n",
    "    if weights is None:\n",
    "        vals = [rates[f\"rate_{ls}\"] for ls in lam_strs if np.isfinite(rates[f\"rate_{ls}\"])]\n",
    "        rates[\"rate_mean_all\"] = float(np.mean(vals)) if vals else np.nan\n",
    "    else:\n",
    "        num, den = 0.0, 0.0\n",
    "        for ls in lam_strs:\n",
    "            v = rates[f\"rate_{ls}\"]\n",
    "            w = float(weights.get(ls, 0.0))\n",
    "            if np.isfinite(v) and w > 0:\n",
    "                num += w * v\n",
    "                den += w\n",
    "        rates[\"rate_weighted_all\"] = (num / den) if den > 0 else np.nan\n",
    "\n",
    "    return rates\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Trial11 폴더 구조:\n",
    "    #   ./Trial11/seed_<seed>/<CKPT>/\n",
    "    #   예) ./Trial11/seed_333/best_by_val_cycles/\n",
    "    ckpt_dir = os.path.join(TRIAL_DIR, f\"seed_{SEED}\", CKPT)\n",
    "    if not os.path.isdir(ckpt_dir):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Not found: {ckpt_dir}\\n\"\n",
    "            f\"Check TRIAL_DIR/SEED/CKPT.\\n\"\n",
    "            f\"CKPT should be 'best_by_val_cycles' or 'last_epoch'.\"\n",
    "        )\n",
    "\n",
    "    out_dir = os.path.join(ckpt_dir, \"alpha_lambda_eval\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    summary_rows = []\n",
    "    per_file_rows = []\n",
    "\n",
    "    for split in SPLITS:\n",
    "        # Trial11 export 위치: <ckpt_dir>/<split>_prognostics_metrics_per_file.csv\n",
    "        mpath = os.path.join(ckpt_dir, f\"{split}_prognostics_metrics_per_file.csv\")\n",
    "        if not os.path.exists(mpath):\n",
    "            print(f\"[SKIP] Missing: {mpath}\")\n",
    "            continue\n",
    "\n",
    "        dfm = pd.read_csv(mpath)\n",
    "        _require_cols(dfm, [\"file\"])  # 최소 file은 있어야 함\n",
    "\n",
    "        # split 요약(성공률)\n",
    "        rates = compute_alpha_lambda_rates(dfm, LAM_STRS, weights=LAMBDA_WEIGHTS)\n",
    "        row = {\n",
    "            \"trial_dir\": TRIAL_DIR,\n",
    "            \"seed\": SEED,\n",
    "            \"checkpoint\": CKPT,\n",
    "            \"split\": split,\n",
    "            \"n_files\": int(len(dfm)),\n",
    "            **rates\n",
    "        }\n",
    "        summary_rows.append(row)\n",
    "\n",
    "        # (선택) 파일별 pass/fail 저장\n",
    "        keep_cols = [\"file\"]\n",
    "        for ls in LAM_STRS:\n",
    "            c_ok = f\"alpha_lambda_ok_{ls}\"\n",
    "            c_tl = f\"t_lambda_{ls}\"\n",
    "            if c_ok in dfm.columns:\n",
    "                keep_cols.append(c_ok)\n",
    "            if c_tl in dfm.columns:\n",
    "                keep_cols.append(c_tl)\n",
    "\n",
    "        sub = dfm[keep_cols].copy()\n",
    "        sub.insert(0, \"split\", split)\n",
    "        sub.insert(0, \"checkpoint\", CKPT)\n",
    "        sub.insert(0, \"seed\", SEED)\n",
    "        per_file_rows.append(sub)\n",
    "\n",
    "        # 콘솔 출력\n",
    "        parts = []\n",
    "        for ls in LAM_STRS:\n",
    "            v = row.get(f\"rate_{ls}\", np.nan)\n",
    "            if np.isfinite(v):\n",
    "                parts.append(f\"λ={ls}:{v:.3f}\")\n",
    "        overall_key = \"rate_weighted_all\" if LAMBDA_WEIGHTS is not None else \"rate_mean_all\"\n",
    "        overall = row.get(overall_key, np.nan)\n",
    "        if np.isfinite(overall):\n",
    "            parts.append(f\"overall:{overall:.3f}\")\n",
    "        print(f\"[OK] {split}: \" + \", \".join(parts))\n",
    "\n",
    "    # 저장: split별 요약\n",
    "    df_summary = pd.DataFrame(summary_rows)\n",
    "    out_summary = os.path.join(out_dir, f\"alpha_lambda_summary_seed{SEED}_{CKPT}.csv\")\n",
    "    df_summary.to_csv(out_summary, index=False)\n",
    "\n",
    "    # 저장: 파일별 pass/fail (선택)\n",
    "    out_pf = None\n",
    "    if per_file_rows:\n",
    "        df_pf = pd.concat(per_file_rows, axis=0, ignore_index=True)\n",
    "        out_pf = os.path.join(out_dir, f\"alpha_lambda_per_file_seed{SEED}_{CKPT}.csv\")\n",
    "        df_pf.to_csv(out_pf, index=False)\n",
    "\n",
    "    print(\"\\n==================== DONE ====================\")\n",
    "    print(\"Saved:\")\n",
    "    print(\" -\", out_summary)\n",
    "    if out_pf:\n",
    "        print(\" -\", out_pf)\n",
    "    print(\"==============================================\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e6a0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] selected by VAL (val_rmse_cycles, val_mae_cycles)\n",
      "  seed=333, checkpoint=best_by_val_cycles\n",
      "[READ] ./Trial11\\seed_333\\best_by_val_cycles\\alpha_lambda_eval\\alpha_lambda_summary_seed333_best_by_val_cycles.csv\n",
      "[SAVE] ./alpha_lambda_curve_best_trial11.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# USER CONFIG (Trial11)\n",
    "# =========================\n",
    "TRIAL11_DIR = r\"./Trial11\"  # 또는 r\"C:\\...\\Trial11\"\n",
    "OUT_PNG = r\"./alpha_lambda_curve_best_trial11.png\"\n",
    "\n",
    "LAM_STRS = [\"0.20\", \"0.40\", \"0.60\", \"0.80\"]\n",
    "LAM = [float(x) for x in LAM_STRS]\n",
    "SPLITS_ORDER = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _require_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "def pick_best_row_by_val_cycles(summary_csv: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Trial11 summary_across_seeds.csv에서\n",
    "    VAL 기준 best 모델 1개 선택:\n",
    "      1) val_rmse_cycles 최소\n",
    "      2) val_mae_cycles 최소 (tie-break)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(summary_csv):\n",
    "        raise FileNotFoundError(f\"Not found: {summary_csv}\")\n",
    "\n",
    "    df = pd.read_csv(summary_csv)\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", \"val_rmse_cycles\", \"val_mae_cycles\"])\n",
    "\n",
    "    df_sorted = df.sort_values(\n",
    "        by=[\"val_rmse_cycles\", \"val_mae_cycles\"],\n",
    "        ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return df_sorted.iloc[0]\n",
    "\n",
    "def find_alpha_lambda_summary_csv(trial_dir: str, seed: int, ckpt: str) -> str:\n",
    "    \"\"\"\n",
    "    Trial11 구조 기준:\n",
    "      <trial_dir>/seed_<seed>/<ckpt>/alpha_lambda_eval/alpha_lambda_summary_seed<seed>_<ckpt>.csv\n",
    "    \"\"\"\n",
    "    cand = os.path.join(\n",
    "        trial_dir,\n",
    "        f\"seed_{seed}\",\n",
    "        ckpt,\n",
    "        \"alpha_lambda_eval\",\n",
    "        f\"alpha_lambda_summary_seed{seed}_{ckpt}.csv\"\n",
    "    )\n",
    "    if os.path.exists(cand):\n",
    "        return cand\n",
    "\n",
    "    # fallback: alpha_lambda_eval 폴더 내 summary csv 아무거나 찾기\n",
    "    alt_dir = os.path.join(trial_dir, f\"seed_{seed}\", ckpt, \"alpha_lambda_eval\")\n",
    "    if os.path.isdir(alt_dir):\n",
    "        for fn in os.listdir(alt_dir):\n",
    "            fn_low = fn.lower()\n",
    "            if fn_low.startswith(\"alpha_lambda_summary\") and fn_low.endswith(\".csv\"):\n",
    "                return os.path.join(alt_dir, fn)\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        \"alpha-lambda summary csv not found.\\n\"\n",
    "        f\"Expected: {cand}\\n\"\n",
    "        f\"Also checked: {alt_dir}\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    summary_csv = os.path.join(TRIAL11_DIR, \"summary_across_seeds.csv\")\n",
    "\n",
    "    best = pick_best_row_by_val_cycles(summary_csv)\n",
    "    best_seed = int(best[\"seed\"])\n",
    "    best_ckpt = str(best[\"checkpoint\"])\n",
    "\n",
    "    summary_path = find_alpha_lambda_summary_csv(TRIAL11_DIR, best_seed, best_ckpt)\n",
    "    df = pd.read_csv(summary_path)\n",
    "    _require_cols(df, [\"split\"] + [f\"rate_{ls}\" for ls in LAM_STRS])\n",
    "\n",
    "    # plot\n",
    "    plt.figure()\n",
    "    for split in SPLITS_ORDER:\n",
    "        sub = df[df[\"split\"] == split]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        row = sub.iloc[0]\n",
    "        rates = [float(row.get(f\"rate_{ls}\", np.nan)) for ls in LAM_STRS]\n",
    "        plt.plot(LAM, rates, marker=\"o\", label=split)\n",
    "\n",
    "    plt.xticks(LAM, [f\"{x:.2f}\" for x in LAM])\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.xlabel(\"λ (life fraction)\")\n",
    "    plt.ylabel(\"α–λ success rate\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.title(f\"Trial11 BEST (VAL) | seed={best_seed} | ckpt={best_ckpt}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(OUT_PNG, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"[BEST] selected by VAL (val_rmse_cycles, val_mae_cycles)\")\n",
    "    print(f\"  seed={best_seed}, checkpoint={best_ckpt}\")\n",
    "    print(f\"[READ] {summary_path}\")\n",
    "    print(f\"[SAVE] {OUT_PNG}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc8bed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] DONE -> ./Trial11\\seed_333\\best_by_val_cycles\\paper_figures_bookstyle\\train\n",
      "[val] DONE -> ./Trial11\\seed_333\\best_by_val_cycles\\paper_figures_bookstyle\\val\n",
      "[test] DONE -> ./Trial11\\seed_333\\best_by_val_cycles\\paper_figures_bookstyle\\test\n",
      "\n",
      "ALL DONE.\n",
      "Saved under: ./Trial11\\seed_333\\best_by_val_cycles\\paper_figures_bookstyle\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# USER CONFIG (Trial11)\n",
    "# ============================================================\n",
    "TRIAL_DIR = r\"./Trial11\"              # ✅ Trial11 폴더\n",
    "SEED = 333                            # 선택된 seed\n",
    "CKPT = \"best_by_val_cycles\"           # ✅ Trial11 checkpoint: \"best_by_val_cycles\" or \"last_epoch\"\n",
    "\n",
    "SPLITS = [\"train\", \"val\", \"test\"]     # 여러 split 한번에\n",
    "\n",
    "ALPHA = 0.20\n",
    "LAMBDA_TO_PLOT = 0.60                 # α–λ 그림에 표시할 λ\n",
    "\n",
    "MAX_FILES = None                      # None=모두, 아니면 예: 10\n",
    "\n",
    "# 저장 폴더 루트 (Trial11 구조: seed_<seed>/<ckpt>/ 아래에 저장)\n",
    "OUT_ROOT = os.path.join(TRIAL_DIR, f\"seed_{SEED}\", CKPT, \"paper_figures_bookstyle\")\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "def safe_name(s: str) -> str:\n",
    "    return s.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "def load_cycle_seq_and_metrics(ckpt_dir: str, split: str):\n",
    "    \"\"\"\n",
    "    Trial11 export 단계가 만들어 둔 파일들:\n",
    "      - <split>_cycle_sequence_mean.csv\n",
    "      - <split>_prognostics_metrics_per_file.csv\n",
    "    위치: ./Trial11/seed_<seed>/<ckpt>/\n",
    "    \"\"\"\n",
    "    seq_csv = os.path.join(ckpt_dir, f\"{split}_cycle_sequence_mean.csv\")\n",
    "    met_csv = os.path.join(ckpt_dir, f\"{split}_prognostics_metrics_per_file.csv\")\n",
    "\n",
    "    if not os.path.exists(seq_csv):\n",
    "        raise FileNotFoundError(f\"Missing: {seq_csv}\")\n",
    "    if not os.path.exists(met_csv):\n",
    "        raise FileNotFoundError(f\"Missing: {met_csv}\")\n",
    "\n",
    "    df_seq = pd.read_csv(seq_csv)\n",
    "    df_met = pd.read_csv(met_csv)\n",
    "    return df_seq, df_met\n",
    "\n",
    "def get_eval_segment(df_one_file: pd.DataFrame, t_s: int, t_e: int) -> pd.DataFrame:\n",
    "    df = df_one_file.sort_values(\"cycle\").copy()\n",
    "    df = df[(df[\"cycle\"] >= t_s) & (df[\"cycle\"] <= t_e)].copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# Plotters\n",
    "# ============================================================\n",
    "def plot_ph_alpha_absolute_band(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    alpha: float,\n",
    "    out_path: str,\n",
    "    ph_start: Optional[float] = None,\n",
    "    title_prefix: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    BOOK Fig.2.9(a) 스타일:\n",
    "    - PH용 α-zone = '절대 폭(평행 밴드)'\n",
    "      alphaZone = alpha * EOL_true\n",
    "      zone = RUL_true ± alphaZone\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].to_numpy()\n",
    "    y_true = df_eval[\"RUL_true\"].to_numpy()\n",
    "    y_pred = df_eval[\"RUL_pred\"].to_numpy()\n",
    "\n",
    "    last_cycle = int(df_eval[\"cycle\"].max())\n",
    "    eol_true = last_cycle + 1\n",
    "\n",
    "    alpha_zone = alpha * float(eol_true)  # 평행 밴드 폭\n",
    "    upper = y_true + alpha_zone\n",
    "    lower = y_true - alpha_zone\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, \"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, \"r\", label=\"Prediction (cycles)\")\n",
    "    plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α-zone (±α·EOL)\")\n",
    "    plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α-zone (±α·EOL)\")\n",
    "\n",
    "    if ph_start is not None and np.isfinite(ph_start):\n",
    "        plt.axvline(int(ph_start), color=\"g\", linestyle=\"-.\", label=\"PH start\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title_prefix} | BOOK-STYLE α+PH (absolute band)\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_alpha_lambda_relative_band(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    t_lambda: Optional[int],\n",
    "    out_path: str,\n",
    "    title_prefix: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    BOOK Fig.2.9(b) 스타일:\n",
    "    - α–λ는 '상대 폭(수렴 밴드)'\n",
    "      zone = RUL_true*(1±alpha), 그리고 t >= t_lambda 구간만 표시\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].to_numpy()\n",
    "    y_true = df_eval[\"RUL_true\"].to_numpy()\n",
    "    y_pred = df_eval[\"RUL_pred\"].to_numpy()\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, \"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, \"r\", label=\"Prediction (cycles)\")\n",
    "\n",
    "    if t_lambda is not None and np.isfinite(t_lambda):\n",
    "        t_lambda = int(t_lambda)\n",
    "        plt.axvline(t_lambda, color=\"g\", linestyle=\":\", label=f\"t_λ (λ={lambda_to_plot:.2f})\")\n",
    "\n",
    "        mask = x >= t_lambda\n",
    "        if np.any(mask):\n",
    "            plt.plot(x[mask], upper[mask], \"b--\", label=f\"+{alpha:.2f} α–λ zone\")\n",
    "            plt.plot(x[mask], lower[mask], \"b--\", label=f\"-{alpha:.2f} α–λ zone\")\n",
    "        else:\n",
    "            plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α zone\")\n",
    "            plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α zone\")\n",
    "    else:\n",
    "        plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α zone\")\n",
    "        plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α zone\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title_prefix} | BOOK-STYLE α–λ (relative band)\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# Main (multi-split)\n",
    "# ============================================================\n",
    "def run_for_one_split(ckpt_dir: str, split: str):\n",
    "    df_seq, df_met = load_cycle_seq_and_metrics(ckpt_dir, split)\n",
    "\n",
    "    files = df_seq[\"file\"].unique().tolist()\n",
    "    if MAX_FILES is not None:\n",
    "        files = files[:MAX_FILES]\n",
    "\n",
    "    out_dir = os.path.join(OUT_ROOT, split)  # split별 폴더\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    lam_key = f\"t_lambda_{LAMBDA_TO_PLOT:.2f}\"\n",
    "    title_prefix = f\"SEED {SEED} | {CKPT.upper()} | {split}\"\n",
    "\n",
    "    for f in files:\n",
    "        sub = df_seq[df_seq[\"file\"] == f].copy()\n",
    "        mrow = df_met[df_met[\"file\"] == f]\n",
    "        if mrow.empty:\n",
    "            continue\n",
    "        mrow = mrow.iloc[0].to_dict()\n",
    "\n",
    "        t_s = int(mrow[\"t_s\"])\n",
    "        t_e = int(mrow[\"t_e\"])\n",
    "        ph_start = mrow.get(\"t_PH_start\", np.nan)\n",
    "        t_lambda = mrow.get(lam_key, np.nan)\n",
    "\n",
    "        df_eval = get_eval_segment(sub, t_s, t_e)\n",
    "        if df_eval.empty:\n",
    "            continue\n",
    "\n",
    "        sname = safe_name(f)\n",
    "\n",
    "        out_a = os.path.join(out_dir, f\"FIG_A_BOOKSTYLE_alpha_PH__{sname}.png\")\n",
    "        plot_ph_alpha_absolute_band(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            alpha=ALPHA,\n",
    "            out_path=out_a,\n",
    "            ph_start=ph_start if np.isfinite(ph_start) else None,\n",
    "            title_prefix=title_prefix,\n",
    "        )\n",
    "\n",
    "        out_b = os.path.join(out_dir, f\"FIG_B_BOOKSTYLE_alpha_lambda__lam{LAMBDA_TO_PLOT:.2f}__{sname}.png\")\n",
    "        plot_alpha_lambda_relative_band(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            alpha=ALPHA,\n",
    "            lambda_to_plot=LAMBDA_TO_PLOT,\n",
    "            t_lambda=int(t_lambda) if np.isfinite(t_lambda) else None,\n",
    "            out_path=out_b,\n",
    "            title_prefix=title_prefix,\n",
    "        )\n",
    "\n",
    "    print(f\"[{split}] DONE -> {out_dir}\")\n",
    "\n",
    "def main():\n",
    "    # Trial11 구조: ./Trial11/seed_<seed>/<ckpt>/\n",
    "    ckpt_dir = os.path.join(TRIAL_DIR, f\"seed_{SEED}\", CKPT)\n",
    "    if not os.path.isdir(ckpt_dir):\n",
    "        raise FileNotFoundError(f\"Not found: {ckpt_dir}\")\n",
    "\n",
    "    for split in SPLITS:\n",
    "        run_for_one_split(ckpt_dir, split)\n",
    "\n",
    "    print(\"\\nALL DONE.\")\n",
    "    print(\"Saved under:\", OUT_ROOT)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igbt_rnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
