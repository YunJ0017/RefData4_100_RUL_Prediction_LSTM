{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1690c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "[SEED 9819123] device=cuda\n",
      "[SEED 9819123] out=./Trial16\\seed_9819123\n",
      "==============================\n",
      "[SEED 9819123] [001/300] train_loss=0.012653 | val_rmse_norm=0.056517 | val_mae_cycles=492.268 | best_val_rmse_norm=0.056517\n",
      "[SEED 9819123] [010/300] train_loss=0.000871 | val_rmse_norm=0.048573 | val_mae_cycles=547.900 | best_val_rmse_norm=0.037098\n",
      "[SEED 9819123] [020/300] train_loss=0.000527 | val_rmse_norm=0.050891 | val_mae_cycles=599.562 | best_val_rmse_norm=0.037098\n",
      "[SEED 9819123] [030/300] train_loss=0.000331 | val_rmse_norm=0.046933 | val_mae_cycles=520.247 | best_val_rmse_norm=0.037098\n",
      "[SEED 9819123] Early stopping at epoch 32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_81736\\2260367434.py:1045: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 9819123] best_by_val_norm: TEST mae_cycles=249.853 | rmse_cycles=342.339 | rmse_norm=0.026770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_81736\\2260367434.py:1045: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 9819123] last_epoch: TEST mae_cycles=247.846 | rmse_cycles=359.836 | rmse_norm=0.032369\n",
      "\n",
      "==============================\n",
      "[SEED 111] device=cuda\n",
      "[SEED 111] out=./Trial16\\seed_111\n",
      "==============================\n",
      "[SEED 111] [001/300] train_loss=0.012995 | val_rmse_norm=0.079930 | val_mae_cycles=1825.056 | best_val_rmse_norm=0.079930\n",
      "[SEED 111] [010/300] train_loss=0.000848 | val_rmse_norm=0.058286 | val_mae_cycles=1260.192 | best_val_rmse_norm=0.045446\n",
      "[SEED 111] [020/300] train_loss=0.001044 | val_rmse_norm=0.058236 | val_mae_cycles=1297.952 | best_val_rmse_norm=0.045446\n",
      "[SEED 111] [030/300] train_loss=0.000503 | val_rmse_norm=0.061000 | val_mae_cycles=1208.225 | best_val_rmse_norm=0.045446\n",
      "[SEED 111] Early stopping at epoch 37.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_81736\\2260367434.py:1045: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 111] best_by_val_norm: TEST mae_cycles=355.973 | rmse_cycles=543.241 | rmse_norm=0.032696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_81736\\2260367434.py:1045: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 111] last_epoch: TEST mae_cycles=519.697 | rmse_cycles=940.499 | rmse_norm=0.045939\n",
      "\n",
      "==============================\n",
      "[SEED 222] device=cuda\n",
      "[SEED 222] out=./Trial16\\seed_222\n",
      "==============================\n",
      "[SEED 222] [001/300] train_loss=0.010301 | val_rmse_norm=0.033235 | val_mae_cycles=347.663 | best_val_rmse_norm=0.033235\n",
      "[SEED 222] [010/300] train_loss=0.000872 | val_rmse_norm=0.029040 | val_mae_cycles=301.285 | best_val_rmse_norm=0.027871\n",
      "[SEED 222] [020/300] train_loss=0.000412 | val_rmse_norm=0.030763 | val_mae_cycles=331.710 | best_val_rmse_norm=0.027871\n",
      "[SEED 222] [030/300] train_loss=0.000320 | val_rmse_norm=0.036835 | val_mae_cycles=399.311 | best_val_rmse_norm=0.027871\n",
      "[SEED 222] Early stopping at epoch 36.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_81736\\2260367434.py:1045: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 222] best_by_val_norm: TEST mae_cycles=376.225 | rmse_cycles=565.104 | rmse_norm=0.025971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_81736\\2260367434.py:1045: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 222] last_epoch: TEST mae_cycles=468.531 | rmse_cycles=843.380 | rmse_norm=0.032845\n",
      "\n",
      "==============================\n",
      "[SEED 333] device=cuda\n",
      "[SEED 333] out=./Trial16\\seed_333\n",
      "==============================\n",
      "[SEED 333] [001/300] train_loss=0.014326 | val_rmse_norm=0.045298 | val_mae_cycles=442.634 | best_val_rmse_norm=0.045298\n",
      "[SEED 333] [010/300] train_loss=0.000986 | val_rmse_norm=0.043422 | val_mae_cycles=411.594 | best_val_rmse_norm=0.037635\n",
      "[SEED 333] [020/300] train_loss=0.000460 | val_rmse_norm=0.048589 | val_mae_cycles=506.797 | best_val_rmse_norm=0.037635\n",
      "[SEED 333] [030/300] train_loss=0.000581 | val_rmse_norm=0.047915 | val_mae_cycles=464.439 | best_val_rmse_norm=0.037635\n",
      "[SEED 333] Early stopping at epoch 32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_81736\\2260367434.py:1045: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 333] best_by_val_norm: TEST mae_cycles=119.948 | rmse_cycles=157.840 | rmse_norm=0.029590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_81736\\2260367434.py:1045: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 333] last_epoch: TEST mae_cycles=150.237 | rmse_cycles=213.435 | rmse_norm=0.033718\n",
      "\n",
      "==============================\n",
      "[SEED 444] device=cuda\n",
      "[SEED 444] out=./Trial16\\seed_444\n",
      "==============================\n",
      "[SEED 444] [001/300] train_loss=0.010731 | val_rmse_norm=0.053908 | val_mae_cycles=840.823 | best_val_rmse_norm=0.053908\n",
      "[SEED 444] [010/300] train_loss=0.000787 | val_rmse_norm=0.044716 | val_mae_cycles=719.641 | best_val_rmse_norm=0.031433\n",
      "[SEED 444] [020/300] train_loss=0.000416 | val_rmse_norm=0.044502 | val_mae_cycles=641.932 | best_val_rmse_norm=0.031433\n",
      "[SEED 444] [030/300] train_loss=0.000310 | val_rmse_norm=0.046460 | val_mae_cycles=667.217 | best_val_rmse_norm=0.031433\n",
      "[SEED 444] Early stopping at epoch 34.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_81736\\2260367434.py:1045: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 444] best_by_val_norm: TEST mae_cycles=381.546 | rmse_cycles=581.165 | rmse_norm=0.031754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_81736\\2260367434.py:1045: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 444] last_epoch: TEST mae_cycles=471.214 | rmse_cycles=663.660 | rmse_norm=0.038211\n",
      "=== WIN-RATE SUMMARY (TEST; lower is better) ===\n",
      "- test_mae_cycles: last wins=1, best wins=4, ties=0 | mean(last-best)=74.796040, std(last-best)=57.123585\n",
      "- test_rmse_cycles: last wins=0, best wins=5, ties=0 | mean(last-best)=166.224092, std(last-best)=146.493403\n",
      "- test_mae_norm: last wins=0, best wins=5, ties=0 | mean(last-best)=0.003811, std(last-best)=0.001595\n",
      "- test_rmse_norm: last wins=0, best wins=5, ties=0 | mean(last-best)=0.007260, std(last-best)=0.003135\n",
      "\n",
      "=== MEAN ± STD across seeds (TEST) ===\n",
      "                 test_mae_cycles             test_rmse_cycles              \\\n",
      "                            mean         std             mean         std   \n",
      "checkpoint                                                                  \n",
      "best_by_val_norm      296.708789  112.330235       437.937941  183.961977   \n",
      "last_epoch            371.504829  162.455862       604.162033  310.745625   \n",
      "\n",
      "                 test_mae_norm           test_rmse_norm            \n",
      "                          mean       std           mean       std  \n",
      "checkpoint                                                         \n",
      "best_by_val_norm      0.022986  0.002743       0.029356  0.002962  \n",
      "last_epoch            0.026797  0.004175       0.036617  0.005703  \n",
      "\n",
      "Saved:\n",
      " - ./Trial16\\summary_across_seeds.csv\n",
      " - ./Trial16\\win_rate_summary.csv\n",
      " - ./Trial16\\win_rate_summary.txt\n",
      "\n",
      "DONE. Check Trial16 folder:\n",
      " - per seed results: Trial16/seed_<seed>/...\n",
      " - figures (paper-style): seed_<seed>/<ckpt>/paper_figures/<split>/\n",
      " - cycle sequence mean CSV: <ckpt>/<split>_cycle_sequence_mean.csv\n",
      " - PH/α–λ metrics CSV: <ckpt>/<split>_prognostics_metrics_per_file.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Trial16: Trial15 + (3) Tail-weighted loss (y_norm-based)\n",
    "#\n",
    "# 핵심 아이디어:\n",
    "# - Trial15: (1) damage-proxy features + (2) tail-robust training\n",
    "# - Trial16: (3) Tail-weighted loss 추가 -> 고장 근처(y_norm↓) 오차를 더 강하게 벌점\n",
    "#\n",
    "#   w = 1 + gamma * (1 - y_norm)^p   (tail일수록 w↑)\n",
    "#   loss = mean( w * (pred_norm - y_norm)^2 )\n",
    "#\n",
    "# Keeps Trial9 evaluation pack: PH / α–λ / CRA / convergence + paper figures\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0) Reproducibility\n",
    "# ============================================================\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Config\n",
    "# ============================================================\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_dir: str = r\"C:\\Users\\11HOME_AHCI\\Desktop\\PoF\\Winter 2026\\Ref Data4\\100\"\n",
    "    out_dir: str = r\"./Trial16\"  \n",
    "\n",
    "    # seeds to sweep\n",
    "    seeds: Tuple[int, ...] = (9819123, 111, 222, 333, 444)\n",
    "\n",
    "    # sliding window\n",
    "    seq_len: int = 100\n",
    "    stride: int = 5 \n",
    "    pred_horizon: int = 0\n",
    "\n",
    "    # split by FILE\n",
    "    train_ratio: float = 0.7\n",
    "    val_ratio: float = 0.2\n",
    "    test_ratio: float = 0.1\n",
    "\n",
    "    # training\n",
    "    batch_size: int = 512 \n",
    "    epochs: int = 300\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 0.0\n",
    "    patience: int = 30\n",
    "    grad_clip: float = 1.0\n",
    "\n",
    "    # model\n",
    "    hidden_size: int = 512\n",
    "    num_layers: int = 2\n",
    "    dropout: float = 0.2\n",
    "\n",
    "    # data loading\n",
    "    num_workers: int = 0\n",
    "\n",
    "    # output controls\n",
    "    save_figures: bool = True\n",
    "    max_files_to_plot: Optional[int] = None  # None=all\n",
    "\n",
    "    # ===========================\n",
    "    # Trial9-style Evaluation settings\n",
    "    # ===========================\n",
    "    alpha: float = 0.20\n",
    "    ph_consecutive_m: int = 5\n",
    "    rep_method: str = \"mean\" \n",
    "    lambdas: Tuple[float, ...] = (0.2, 0.4, 0.6, 0.8)\n",
    "    lambda_to_plot: float = 0.6\n",
    "    eps_rul: float = 1e-8\n",
    "\n",
    "    # ===========================\n",
    "    # Trial13 base features (min_vce only)\n",
    "    # ===========================\n",
    "    delta_steps: Tuple[int, ...] = (1, 5, 20, 50)\n",
    "    ema_spans: Tuple[int, ...] = (10, 50) \n",
    "    roll_std_window: int = 10 \n",
    "    add_window_stats: bool = True\n",
    "\n",
    "    # ===========================\n",
    "    # Trial15-1: Damage-proxy features (min_vce only)\n",
    "    # ===========================\n",
    "    add_damage_proxy: bool = True\n",
    "    # vce_rel = vce - vce0\n",
    "    # cum_pos = cumsum(max(delta_1,0))\n",
    "    # cum_abs = cumsum(abs(delta_1))\n",
    "    # cum_inc = cumsum(max(vce - vce0,0))\n",
    "    # cum_acc = cumsum(abs(d(delta_1)))  (2차 변화량 누적)\n",
    "\n",
    "    # ===========================\n",
    "    # Temporal Pooling (Trial14 유지)\n",
    "    # ===========================\n",
    "    pooling: str = \"mean_last_k\"   # \"last\" | \"mean_last_k\" | \"attn\"\n",
    "    pool_last_k: int = 10\n",
    "    attn_dim: int = 128\n",
    "\n",
    "    # ===========================\n",
    "    # Trial15-2: Tail-robust training (shortcut 방지)\n",
    "    # ===========================\n",
    "    tail_robust_enable: bool = True\n",
    "    tail_k_max: int = 10\n",
    "    tail_apply_p: float = 1.0\n",
    "    tail_mode: str = \"mask\"             # \"mask\" | \"shuffle\"\n",
    "    tail_mask_value: float = 0.0\n",
    "\n",
    "    # ===========================\n",
    "    # Trial16: Tail-weighted loss (NEW)\n",
    "    # ===========================\n",
    "    tail_weight_enable: bool = True\n",
    "    tail_weight_gamma: float = 5.0      # 추천 시작: 5\n",
    "    tail_weight_p: float = 2.0          # 추천 시작: 2\n",
    "    tail_weight_max: float = 20.0       # 안정화(상한)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Data utils\n",
    "# ============================================================\n",
    "def list_csv_files(data_dir: str) -> List[Path]:\n",
    "    p = Path(data_dir)\n",
    "    files = sorted([f for f in p.glob(\"*.csv\") if f.is_file()])\n",
    "    if len(files) == 0:\n",
    "        raise FileNotFoundError(f\"No CSV files found in: {data_dir}\")\n",
    "    return files\n",
    "\n",
    "\n",
    "def read_one_csv(csv_path: Path) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    df = pd.read_csv(csv_path, header=None)\n",
    "    if df.shape[1] < 2:\n",
    "        raise ValueError(f\"{csv_path.name}: expected at least 2 columns, got {df.shape[1]}\")\n",
    "    vce = df.iloc[:, 0].astype(np.float32).to_numpy()\n",
    "    rul = df.iloc[:, 1].astype(np.float32).to_numpy()\n",
    "\n",
    "    if len(vce) != len(rul):\n",
    "        raise ValueError(f\"{csv_path.name}: length mismatch vce={len(vce)}, rul={len(rul)}\")\n",
    "    if len(vce) < 5:\n",
    "        raise ValueError(f\"{csv_path.name}: too short sequence length={len(vce)}\")\n",
    "    return vce, rul\n",
    "\n",
    "\n",
    "def split_files(\n",
    "    files: List[Path],\n",
    "    train_ratio: float,\n",
    "    val_ratio: float,\n",
    "    test_ratio: float,\n",
    "    seed: int\n",
    ") -> Dict[str, List[Path]]:\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-9\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "    files_shuffled = files[:]\n",
    "    rng.shuffle(files_shuffled)\n",
    "\n",
    "    n = len(files_shuffled)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "\n",
    "    train_files = files_shuffled[:n_train]\n",
    "    val_files = files_shuffled[n_train:n_train + n_val]\n",
    "    test_files = files_shuffled[n_train + n_val:]\n",
    "\n",
    "    return {\"train\": train_files, \"val\": val_files, \"test\": test_files}\n",
    "\n",
    "\n",
    "def delta_k(v: np.ndarray, k: int) -> np.ndarray:\n",
    "    out = np.zeros_like(v, dtype=np.float32)\n",
    "    if k <= 0:\n",
    "        return out\n",
    "    out[k:] = v[k:] - v[:-k]\n",
    "    return out\n",
    "\n",
    "\n",
    "def ema(v: np.ndarray, span: int) -> np.ndarray:\n",
    "    if span <= 1:\n",
    "        return v.astype(np.float32).copy()\n",
    "    a = 2.0 / (float(span) + 1.0)\n",
    "    out = np.zeros_like(v, dtype=np.float32)\n",
    "    out[0] = v[0]\n",
    "    for i in range(1, len(v)):\n",
    "        out[i] = a * v[i] + (1.0 - a) * out[i - 1]\n",
    "    return out\n",
    "\n",
    "\n",
    "def rolling_std(v: np.ndarray, w: int) -> np.ndarray:\n",
    "    w = int(w)\n",
    "    out = np.zeros_like(v, dtype=np.float32)\n",
    "    for i in range(len(v)):\n",
    "        j0 = max(0, i - w + 1)\n",
    "        out[i] = float(np.std(v[j0:i + 1], ddof=0))\n",
    "    return out\n",
    "\n",
    "\n",
    "def _window_slope(seg: np.ndarray) -> float:\n",
    "    L = len(seg)\n",
    "    if L <= 1:\n",
    "        return 0.0\n",
    "    t = np.arange(L, dtype=np.float32)\n",
    "    denom = float(np.var(t) + 1e-12)\n",
    "    if denom <= 0:\n",
    "        return 0.0\n",
    "    return float(np.cov(t, seg, ddof=0)[0, 1] / denom)\n",
    "\n",
    "\n",
    "def feature_names(cfg: Config) -> List[str]:\n",
    "    names = [\"min_vce\"]\n",
    "    for k in cfg.delta_steps:\n",
    "        names.append(f\"delta_{k}\")\n",
    "    for s in cfg.ema_spans:\n",
    "        names.append(f\"ema_{s}\")\n",
    "    if cfg.roll_std_window and cfg.roll_std_window > 1:\n",
    "        names.append(f\"rollstd_{cfg.roll_std_window}\")\n",
    "\n",
    "    if cfg.add_damage_proxy:\n",
    "        names += [\"vce_rel\", \"cum_pos\", \"cum_abs\", \"cum_inc\", \"cum_acc\"]\n",
    "\n",
    "    if cfg.add_window_stats:\n",
    "        names += [\"win_mean\", \"win_std\", \"win_slope\"]\n",
    "    return names\n",
    "\n",
    "\n",
    "def build_features_from_min_vce(vce: np.ndarray, cfg: Config) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return X(T,F) features derived ONLY from min_vce.\n",
    "    (window_stats는 Dataset __getitem__에서 window segment 기준으로 append)\n",
    "    \"\"\"\n",
    "    vce = vce.astype(np.float32)\n",
    "    feats = [vce]  # min_vce\n",
    "\n",
    "    # multi-scale deltas\n",
    "    d1 = None\n",
    "    for k in cfg.delta_steps:\n",
    "        dk = delta_k(vce, int(k))\n",
    "        feats.append(dk)\n",
    "        if int(k) == 1:\n",
    "            d1 = dk\n",
    "\n",
    "    # EMA trends\n",
    "    for s in cfg.ema_spans:\n",
    "        feats.append(ema(vce, int(s)))\n",
    "\n",
    "    # rolling std\n",
    "    if cfg.roll_std_window and cfg.roll_std_window > 1:\n",
    "        feats.append(rolling_std(vce, int(cfg.roll_std_window)))\n",
    "\n",
    "    # damage-proxy features\n",
    "    if cfg.add_damage_proxy:\n",
    "        v0 = float(vce[0])\n",
    "        vce_rel = vce - v0\n",
    "\n",
    "        if d1 is None:\n",
    "            d1 = delta_k(vce, 1)\n",
    "\n",
    "        cum_pos = np.cumsum(np.maximum(d1, 0.0)).astype(np.float32)\n",
    "        cum_abs = np.cumsum(np.abs(d1)).astype(np.float32)\n",
    "        cum_inc = np.cumsum(np.maximum(vce - v0, 0.0)).astype(np.float32)\n",
    "\n",
    "        dd1 = np.zeros_like(d1, dtype=np.float32)\n",
    "        dd1[1:] = d1[1:] - d1[:-1]\n",
    "        cum_acc = np.cumsum(np.abs(dd1)).astype(np.float32)\n",
    "\n",
    "        feats += [vce_rel.astype(np.float32), cum_pos, cum_abs, cum_inc, cum_acc]\n",
    "\n",
    "    X = np.stack(feats, axis=1).astype(np.float32)  # (T, F_base(+damage))\n",
    "    return X\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Tail-robust augmentation (TRAIN only)\n",
    "# ============================================================\n",
    "def apply_tail_robust(x_scaled: np.ndarray, cfg: Config, rng: np.random.RandomState) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    x_scaled: (L, F) already scaled (StandardScaler)\n",
    "    Randomly perturb the last tail_k timesteps.\n",
    "    \"\"\"\n",
    "    if (not cfg.tail_robust_enable) or cfg.tail_k_max <= 0:\n",
    "        return x_scaled\n",
    "    if rng.rand() > float(cfg.tail_apply_p):\n",
    "        return x_scaled\n",
    "\n",
    "    L, F = x_scaled.shape\n",
    "    if L <= 1:\n",
    "        return x_scaled\n",
    "\n",
    "    k = int(rng.randint(0, int(cfg.tail_k_max) + 1))\n",
    "    if k <= 0:\n",
    "        return x_scaled\n",
    "\n",
    "    x2 = x_scaled.copy()\n",
    "    tail = slice(max(0, L - k), L)\n",
    "\n",
    "    if cfg.tail_mode == \"mask\":\n",
    "        x2[tail, :] = float(cfg.tail_mask_value)\n",
    "    elif cfg.tail_mode == \"shuffle\":\n",
    "        perm = rng.permutation(np.arange(tail.start, tail.stop))\n",
    "        x2[tail, :] = x2[perm, :]\n",
    "    else:\n",
    "        x2[tail, :] = float(cfg.tail_mask_value)\n",
    "\n",
    "    return x2\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3.5) Tail-weighted loss (NEW)\n",
    "# ============================================================\n",
    "def tail_weighted_mse(pred_norm: torch.Tensor, y_norm: torch.Tensor, cfg: Config) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    pred_norm, y_norm: (B,1)\n",
    "    w = 1 + gamma*(1-y)^p (clipped)\n",
    "    loss = mean(w * (pred - y)^2)\n",
    "    \"\"\"\n",
    "    if not cfg.tail_weight_enable:\n",
    "        return torch.mean((pred_norm - y_norm) ** 2)\n",
    "\n",
    "    y = y_norm.detach()\n",
    "    one_minus = torch.clamp(1.0 - y, 0.0, 1.0)\n",
    "    w = 1.0 + float(cfg.tail_weight_gamma) * torch.pow(one_minus, float(cfg.tail_weight_p))\n",
    "    if cfg.tail_weight_max is not None and float(cfg.tail_weight_max) > 0:\n",
    "        w = torch.clamp(w, max=float(cfg.tail_weight_max))\n",
    "\n",
    "    return torch.mean(w * (pred_norm - y_norm) ** 2)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Dataset\n",
    "# ============================================================\n",
    "class WindowedRULDatasetNormMinVCE_Trial16(Dataset):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      x: (seq_len, F)\n",
    "      y_norm: (1,)\n",
    "      name, start_idx, y_cycles, rul0\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_list: List[Path],\n",
    "        cfg: Config,\n",
    "        scaler_x: StandardScaler = None,\n",
    "        fit_scaler: bool = False,\n",
    "        is_train: bool = False,\n",
    "    ):\n",
    "        self.file_list = file_list\n",
    "        self.cfg = cfg\n",
    "        self.seq_len = cfg.seq_len\n",
    "        self.stride = cfg.stride\n",
    "        self.pred_horizon = cfg.pred_horizon\n",
    "        self.scaler_x = scaler_x if scaler_x is not None else StandardScaler()\n",
    "        self.is_train = bool(is_train)\n",
    "\n",
    "        # deterministic rng per dataset instance (for tail augment)\n",
    "        self._rng = np.random.RandomState(1234 if self.is_train else 4321)\n",
    "\n",
    "        # store: (name, Xbase(T,Fbase), vce(T,), rul(T,), rul0)\n",
    "        self.series: List[Tuple[str, np.ndarray, np.ndarray, np.ndarray, float]] = []\n",
    "        for fp in self.file_list:\n",
    "            vce, rul = read_one_csv(fp)\n",
    "            rul0 = float(rul[0])\n",
    "            if rul0 <= 0:\n",
    "                raise ValueError(f\"{fp.name}: RUL0 must be > 0, got {rul0}\")\n",
    "\n",
    "            Xbase = build_features_from_min_vce(vce, cfg).astype(np.float32)\n",
    "            self.series.append((fp.name, Xbase, vce.astype(np.float32), rul.astype(np.float32), rul0))\n",
    "\n",
    "        # Fit scaler (train only)\n",
    "        if fit_scaler:\n",
    "            if not cfg.add_window_stats:\n",
    "                all_x = np.concatenate([Xbase for _, Xbase, _, _, _ in self.series], axis=0)\n",
    "                self.scaler_x.fit(all_x)\n",
    "            else:\n",
    "                rng = np.random.RandomState(0)\n",
    "                rows = []\n",
    "                max_windows_for_scaler = 5000\n",
    "                for (_name, Xbase, vce_raw, _rul, _rul0) in self.series:\n",
    "                    T = Xbase.shape[0]\n",
    "                    last_start = T - (self.seq_len + self.pred_horizon)\n",
    "                    if last_start < 0:\n",
    "                        continue\n",
    "                    starts = list(range(0, last_start + 1, self.stride))\n",
    "                    if len(starts) == 0:\n",
    "                        continue\n",
    "                    if len(starts) > 200:\n",
    "                        starts = rng.choice(starts, size=200, replace=False).tolist()\n",
    "                    for s in starts:\n",
    "                        xw = Xbase[s:s + self.seq_len, :]  # (L,Fbase)\n",
    "                        seg = vce_raw[s:s + self.seq_len]\n",
    "                        wmean = float(np.mean(seg))\n",
    "                        wstd = float(np.std(seg, ddof=0))\n",
    "                        slope = _window_slope(seg)\n",
    "                        stats = np.array([wmean, wstd, slope], dtype=np.float32).reshape(1, 3)\n",
    "                        stats_rep = np.repeat(stats, repeats=self.seq_len, axis=0)\n",
    "                        xfull = np.concatenate([xw, stats_rep], axis=1)  # (L,F)\n",
    "                        rows.append(xfull)\n",
    "                        if len(rows) >= max_windows_for_scaler:\n",
    "                            break\n",
    "                    if len(rows) >= max_windows_for_scaler:\n",
    "                        break\n",
    "                if len(rows) == 0:\n",
    "                    raise ValueError(\"Scaler fitting failed: no windows sampled. Check seq_len/stride.\")\n",
    "                fit_mat = np.concatenate(rows, axis=0)\n",
    "                self.scaler_x.fit(fit_mat)\n",
    "\n",
    "        # window index\n",
    "        self.index: List[Tuple[int, int]] = []\n",
    "        for fi, (_name, Xbase, _vce, _rul, _rul0) in enumerate(self.series):\n",
    "            T = Xbase.shape[0]\n",
    "            last_start = T - (self.seq_len + self.pred_horizon)\n",
    "            if last_start < 0:\n",
    "                continue\n",
    "            for s in range(0, last_start + 1, self.stride):\n",
    "                self.index.append((fi, s))\n",
    "\n",
    "        if len(self.index) == 0:\n",
    "            raise ValueError(\"No windows were created. Check seq_len/pred_horizon vs file lengths.\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        fi, s = self.index[idx]\n",
    "        name, Xbase, vce_raw, rul, rul0 = self.series[fi]\n",
    "\n",
    "        x = Xbase[s:s + self.seq_len, :]  # (L,Fbase)\n",
    "\n",
    "        if self.cfg.add_window_stats:\n",
    "            seg = vce_raw[s:s + self.seq_len]\n",
    "            wmean = float(np.mean(seg))\n",
    "            wstd = float(np.std(seg, ddof=0))\n",
    "            slope = _window_slope(seg)\n",
    "            stats = np.array([wmean, wstd, slope], dtype=np.float32).reshape(1, 3)\n",
    "            stats_rep = np.repeat(stats, repeats=self.seq_len, axis=0)\n",
    "            x = np.concatenate([x, stats_rep], axis=1).astype(np.float32)  # (L,F)\n",
    "\n",
    "        y_idx = s + self.seq_len - 1 + self.pred_horizon\n",
    "        y_cycles = float(rul[y_idx])\n",
    "        y_norm = np.array([y_cycles / rul0], dtype=np.float32)\n",
    "\n",
    "        # scale first\n",
    "        x = self.scaler_x.transform(x).astype(np.float32)\n",
    "\n",
    "        # TRAIN only: tail-robust\n",
    "        if self.is_train and self.cfg.tail_robust_enable:\n",
    "            x = apply_tail_robust(x, self.cfg, self._rng).astype(np.float32)\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x),\n",
    "            torch.from_numpy(y_norm),\n",
    "            name,\n",
    "            torch.tensor(s, dtype=torch.long),\n",
    "            torch.tensor(y_cycles, dtype=torch.float32),\n",
    "            torch.tensor(rul0, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Model (Temporal pooling 유지)\n",
    "# ============================================================\n",
    "class TemporalPool(nn.Module):\n",
    "    def __init__(self, mode: str, hidden_size: int, last_k: int = 10, attn_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.mode = str(mode)\n",
    "        self.last_k = int(last_k)\n",
    "        self.attn_dim = int(attn_dim)\n",
    "\n",
    "        if self.mode == \"attn\":\n",
    "            self.proj = nn.Sequential(\n",
    "                nn.Linear(hidden_size, self.attn_dim),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(self.attn_dim, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, h: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        h: (B, L, H)\n",
    "        returns pooled: (B, H)\n",
    "        \"\"\"\n",
    "        if self.mode == \"last\":\n",
    "            return h[:, -1, :]\n",
    "\n",
    "        if self.mode == \"mean_last_k\":\n",
    "            L = h.size(1)\n",
    "            k = min(self.last_k, L)\n",
    "            return torch.mean(h[:, -k:, :], dim=1)\n",
    "\n",
    "        if self.mode == \"attn\":\n",
    "            scores = self.proj(h)              # (B, L, 1)\n",
    "            w = torch.softmax(scores, dim=1)   # (B, L, 1)\n",
    "            return torch.sum(w * h, dim=1)     # (B, H)\n",
    "\n",
    "        return h[:, -1, :]\n",
    "\n",
    "\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int, dropout: float,\n",
    "                 pooling: str, pool_last_k: int, attn_dim: int):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.pool = TemporalPool(pooling, hidden_size, last_k=pool_last_k, attn_dim=attn_dim)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 2, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, _ = self.lstm(x)     # (B, L, H)\n",
    "        z = self.pool(h)        # (B, H)\n",
    "        return self.head(z)     # (B, 1) norm-scale\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Basic Eval + Save window-level predictions\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def evaluate_basic(model, loader, device) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "\n",
    "    mae_norm_list, mse_norm_list = [], []\n",
    "    mae_cyc_list, mse_cyc_list = [], []\n",
    "\n",
    "    for x, y_norm, _name, _s, y_cycles, rul0 in loader:\n",
    "        x = x.to(device)\n",
    "        y_norm = y_norm.to(device)\n",
    "        y_cycles = y_cycles.to(device).view(-1, 1)\n",
    "        rul0 = rul0.to(device).view(-1, 1)\n",
    "\n",
    "        pred_norm = model(x)\n",
    "\n",
    "        err_norm = pred_norm - y_norm\n",
    "        mae_norm_list.append(torch.mean(torch.abs(err_norm)).item())\n",
    "        mse_norm_list.append(torch.mean(err_norm ** 2).item())\n",
    "\n",
    "        pred_cycles = pred_norm * rul0\n",
    "        err_cyc = pred_cycles - y_cycles\n",
    "        mae_cyc_list.append(torch.mean(torch.abs(err_cyc)).item())\n",
    "        mse_cyc_list.append(torch.mean(err_cyc ** 2).item())\n",
    "\n",
    "    return {\n",
    "        \"mae_norm\": float(np.mean(mae_norm_list)) if mae_norm_list else float(\"nan\"),\n",
    "        \"rmse_norm\": float(np.sqrt(np.mean(mse_norm_list))) if mse_norm_list else float(\"nan\"),\n",
    "        \"mae_cycles\": float(np.mean(mae_cyc_list)) if mae_cyc_list else float(\"nan\"),\n",
    "        \"rmse_cycles\": float(np.sqrt(np.mean(mse_cyc_list))) if mse_cyc_list else float(\"nan\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_predictions_windows_csv(model, loader, device, out_csv: str, seq_len: int) -> None:\n",
    "    model.eval()\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    for x, y_norm, name, s, y_cycles, rul0 in loader:\n",
    "        x = x.to(device)\n",
    "        y_norm = y_norm.to(device)\n",
    "        y_cycles = y_cycles.to(device).view(-1, 1)\n",
    "        rul0 = rul0.to(device).view(-1, 1)\n",
    "\n",
    "        pred_norm = model(x)\n",
    "        pred_cycles = pred_norm * rul0\n",
    "\n",
    "        pred_norm_np = pred_norm.cpu().numpy().reshape(-1)\n",
    "        y_norm_np = y_norm.cpu().numpy().reshape(-1)\n",
    "        pred_cyc_np = pred_cycles.cpu().numpy().reshape(-1)\n",
    "        y_cyc_np = y_cycles.cpu().numpy().reshape(-1)\n",
    "\n",
    "        rul0_np = rul0.cpu().numpy().reshape(-1)\n",
    "        s_np = s.cpu().numpy().reshape(-1)\n",
    "        name_list = list(name)\n",
    "\n",
    "        for i in range(len(pred_norm_np)):\n",
    "            rows.append({\n",
    "                \"file\": name_list[i],\n",
    "                \"start_idx\": int(s_np[i]),\n",
    "                \"cycle\": int(s_np[i] + (seq_len - 1)),\n",
    "                \"rul0\": float(rul0_np[i]),\n",
    "                \"RUL_true\": float(y_cyc_np[i]),\n",
    "                \"RUL_pred\": float(pred_cyc_np[i]),\n",
    "                \"RUL_true_norm\": float(y_norm_np[i]),\n",
    "                \"RUL_pred_norm\": float(pred_norm_np[i]),\n",
    "            })\n",
    "\n",
    "    pd.DataFrame(rows).to_csv(out_csv, index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) Window -> Cycle sequence (mean representative)\n",
    "# ============================================================\n",
    "def windows_to_cycle_sequence_mean(windows_csv: str) -> pd.DataFrame:\n",
    "    dfw = pd.read_csv(windows_csv)\n",
    "    if dfw.empty:\n",
    "        raise ValueError(f\"Empty windows csv: {windows_csv}\")\n",
    "\n",
    "    g = dfw.groupby([\"file\", \"cycle\"], as_index=False).agg(\n",
    "        rul0=(\"rul0\", \"first\"),\n",
    "        RUL_true=(\"RUL_true\", \"mean\"),\n",
    "        RUL_pred=(\"RUL_pred\", \"mean\"),\n",
    "        n_windows=(\"RUL_pred\", \"count\"),\n",
    "    )\n",
    "    return g\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) Prognostics metrics (same as Trial9)\n",
    "# ============================================================\n",
    "def compute_metrics_for_one_file(\n",
    "    df_seq_one_file: pd.DataFrame,\n",
    "    seq_len: int,\n",
    "    alpha: float,\n",
    "    ph_consecutive_m: int,\n",
    "    lambdas: Tuple[float, ...],\n",
    "    eps_rul: float,\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "\n",
    "    df = df_seq_one_file.sort_values(\"cycle\").reset_index(drop=True).copy()\n",
    "\n",
    "    t_s = seq_len - 1\n",
    "    last_cycle = int(df[\"cycle\"].max())\n",
    "    EOL_true = last_cycle + 1\n",
    "    t_e = EOL_true - 1\n",
    "\n",
    "    df_eval = df[(df[\"cycle\"] >= t_s) & (df[\"cycle\"] <= t_e)].copy()\n",
    "    df_eval.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if df_eval.empty:\n",
    "        summary = {\n",
    "            \"t_s\": t_s, \"t_e\": t_e, \"EOL_true\": EOL_true,\n",
    "            \"PH\": np.nan, \"t_PH_start\": np.nan,\n",
    "            \"CRA\": np.nan, \"Convergence_cycles\": np.nan,\n",
    "        }\n",
    "        for lam in lambdas:\n",
    "            summary[f\"t_lambda_{lam:.2f}\"] = np.nan\n",
    "            summary[f\"alpha_lambda_ok_{lam:.2f}\"] = np.nan\n",
    "        return df_eval, summary\n",
    "\n",
    "    denom = np.maximum(np.abs(df_eval[\"RUL_true\"].values), eps_rul)\n",
    "    rel_err = np.abs(df_eval[\"RUL_true\"].values - df_eval[\"RUL_pred\"].values) / denom\n",
    "    RA = 1.0 - rel_err\n",
    "\n",
    "    df_eval[\"rel_err\"] = rel_err\n",
    "    df_eval[\"RA\"] = RA\n",
    "    df_eval[\"in_alpha\"] = df_eval[\"rel_err\"] <= alpha\n",
    "\n",
    "    CRA = float(np.mean(df_eval[\"RA\"].values))\n",
    "\n",
    "    flags = df_eval[\"in_alpha\"].values.astype(np.int32)\n",
    "    t_PH_start = np.nan\n",
    "    if len(flags) >= ph_consecutive_m:\n",
    "        run = 0\n",
    "        for i, ok in enumerate(flags):\n",
    "            if ok:\n",
    "                run += 1\n",
    "                if run >= ph_consecutive_m:\n",
    "                    start_i = i - ph_consecutive_m + 1\n",
    "                    t_PH_start = int(df_eval.loc[start_i, \"cycle\"])\n",
    "                    break\n",
    "            else:\n",
    "                run = 0\n",
    "\n",
    "    if np.isfinite(t_PH_start):\n",
    "        PH = float(EOL_true - t_PH_start)\n",
    "        Convergence_cycles = float(t_PH_start - t_s)\n",
    "    else:\n",
    "        PH = np.nan\n",
    "        Convergence_cycles = np.nan\n",
    "\n",
    "    rul0 = float(df_eval[\"rul0\"].iloc[0])\n",
    "    lam_results = {}\n",
    "    for lam in lambdas:\n",
    "        target_rul = (1.0 - float(lam)) * rul0\n",
    "        idx = int(np.argmin(np.abs(df_eval[\"RUL_true\"].values - target_rul)))\n",
    "        t_lam = int(df_eval.loc[idx, \"cycle\"])\n",
    "        ok = bool(df_eval.loc[idx, \"rel_err\"] <= alpha)\n",
    "\n",
    "        lam_results[f\"t_lambda_{lam:.2f}\"] = t_lam\n",
    "        lam_results[f\"alpha_lambda_ok_{lam:.2f}\"] = int(ok)\n",
    "\n",
    "    summary = {\n",
    "        \"t_s\": int(t_s),\n",
    "        \"t_e\": int(t_e),\n",
    "        \"EOL_true\": int(EOL_true),\n",
    "        \"alpha\": float(alpha),\n",
    "        \"ph_consecutive_m\": int(ph_consecutive_m),\n",
    "        \"CRA\": CRA,\n",
    "        \"t_PH_start\": t_PH_start if np.isfinite(t_PH_start) else np.nan,\n",
    "        \"PH\": PH,\n",
    "        \"Convergence_cycles\": Convergence_cycles,\n",
    "        **lam_results\n",
    "    }\n",
    "    return df_eval, summary\n",
    "\n",
    "\n",
    "def compute_metrics_from_windows_csv(\n",
    "    windows_csv: str,\n",
    "    seq_len: int,\n",
    "    alpha: float,\n",
    "    ph_consecutive_m: int,\n",
    "    lambdas: Tuple[float, ...],\n",
    "    eps_rul: float,\n",
    "    out_dir: str,\n",
    "    split_name: str,\n",
    ") -> Tuple[str, str]:\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    df_seq = windows_to_cycle_sequence_mean(windows_csv)\n",
    "    seq_path = os.path.join(out_dir, f\"{split_name}_cycle_sequence_mean.csv\")\n",
    "    df_seq.to_csv(seq_path, index=False)\n",
    "\n",
    "    rows = []\n",
    "    for f in df_seq[\"file\"].unique():\n",
    "        sub = df_seq[df_seq[\"file\"] == f].copy()\n",
    "        _df_eval, summary = compute_metrics_for_one_file(\n",
    "            df_seq_one_file=sub,\n",
    "            seq_len=seq_len,\n",
    "            alpha=alpha,\n",
    "            ph_consecutive_m=ph_consecutive_m,\n",
    "            lambdas=lambdas,\n",
    "            eps_rul=eps_rul,\n",
    "        )\n",
    "        summary[\"file\"] = f\n",
    "        rows.append(summary)\n",
    "\n",
    "    dfm = pd.DataFrame(rows)\n",
    "    metrics_path = os.path.join(out_dir, f\"{split_name}_prognostics_metrics_per_file.csv\")\n",
    "    dfm.to_csv(metrics_path, index=False)\n",
    "\n",
    "    return seq_path, metrics_path\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9) Plotters (same as Trial14)\n",
    "# ============================================================\n",
    "def _safe_name(s: str) -> str:\n",
    "    return s.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "\n",
    "def plot_alpha_ph(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    title: str,\n",
    "    alpha: float,\n",
    "    PH_start: Optional[float],\n",
    "    out_path: str,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.figure()\n",
    "\n",
    "    x = df_eval[\"cycle\"].values\n",
    "    y_true = df_eval[\"RUL_true\"].values\n",
    "    y_pred = df_eval[\"RUL_pred\"].values\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.plot(x, y_true, color=\"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, color=\"r\", label=\"Prediction (cycles)\")\n",
    "    plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} alpha accuracy zone\")\n",
    "    plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} alpha accuracy zone\")\n",
    "\n",
    "    if PH_start is not None and np.isfinite(PH_start):\n",
    "        plt.axvline(int(PH_start), color=\"g\", linestyle=\"-.\", label=\"PH start\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title}\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_alpha_lambda(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    title: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    t_lambda: Optional[int],\n",
    "    out_path: str,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].values\n",
    "    y_true = df_eval[\"RUL_true\"].values\n",
    "    y_pred = df_eval[\"RUL_pred\"].values\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, color=\"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, color=\"r\", label=\"Prediction (cycles)\")\n",
    "\n",
    "    if t_lambda is not None and np.isfinite(t_lambda):\n",
    "        t_lambda = int(t_lambda)\n",
    "        plt.axvline(t_lambda, linestyle=\":\", color=\"g\", label=f\"t_λ (λ={lambda_to_plot:.2f})\")\n",
    "        mask = x >= t_lambda\n",
    "        if np.any(mask):\n",
    "            plt.plot(x[mask], upper[mask], color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} alpha–lambda zone\")\n",
    "            plt.plot(x[mask], lower[mask], color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} alpha–lambda zone\")\n",
    "        else:\n",
    "            plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} α zone\")\n",
    "            plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} α zone\")\n",
    "    else:\n",
    "        plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} α zone\")\n",
    "        plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} α zone\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title}\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def make_paper_figures_for_split(\n",
    "    cycle_seq_csv: str,\n",
    "    metrics_per_file_csv: str,\n",
    "    out_fig_dir: str,\n",
    "    title_prefix: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    max_files: Optional[int] = None,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    df_seq = pd.read_csv(cycle_seq_csv)\n",
    "    dfm = pd.read_csv(metrics_per_file_csv)\n",
    "\n",
    "    files = df_seq[\"file\"].unique().tolist()\n",
    "    if max_files is not None:\n",
    "        files = files[:max_files]\n",
    "\n",
    "    os.makedirs(out_fig_dir, exist_ok=True)\n",
    "\n",
    "    lam_key = f\"t_lambda_{lambda_to_plot:.2f}\"\n",
    "\n",
    "    for f in files:\n",
    "        sub = df_seq[df_seq[\"file\"] == f].sort_values(\"cycle\").copy()\n",
    "        mrow = dfm[dfm[\"file\"] == f]\n",
    "        if mrow.empty:\n",
    "            continue\n",
    "        mrow = mrow.iloc[0].to_dict()\n",
    "\n",
    "        t_s = int(mrow[\"t_s\"])\n",
    "        t_e = int(mrow[\"t_e\"])\n",
    "        PH_start = mrow.get(\"t_PH_start\", np.nan)\n",
    "\n",
    "        df_eval = sub[(sub[\"cycle\"] >= t_s) & (sub[\"cycle\"] <= t_e)].copy()\n",
    "        if df_eval.empty:\n",
    "            continue\n",
    "\n",
    "        t_lambda = None\n",
    "        if lam_key in mrow and np.isfinite(mrow[lam_key]):\n",
    "            t_lambda = int(mrow[lam_key])\n",
    "\n",
    "        safe = _safe_name(f)\n",
    "\n",
    "        out1 = os.path.join(out_fig_dir, f\"FIG1_alpha_PH__{safe}.png\")\n",
    "        plot_alpha_ph(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            title=f\"{title_prefix} | α+PH\",\n",
    "            alpha=alpha,\n",
    "            PH_start=PH_start if np.isfinite(PH_start) else None,\n",
    "            out_path=out1,\n",
    "            dpi=dpi,\n",
    "        )\n",
    "\n",
    "        out2 = os.path.join(out_fig_dir, f\"FIG2_alpha_lambda__lam{lambda_to_plot:.2f}__{safe}.png\")\n",
    "        plot_alpha_lambda(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            title=f\"{title_prefix} | α–λ (λ={lambda_to_plot:.2f})\",\n",
    "            alpha=alpha,\n",
    "            lambda_to_plot=lambda_to_plot,\n",
    "            t_lambda=t_lambda,\n",
    "            out_path=out2,\n",
    "            dpi=dpi,\n",
    "        )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10) One seed run\n",
    "# ============================================================\n",
    "def run_one_seed(cfg: Config, seed: int) -> Dict[str, Any]:\n",
    "    set_seed(seed)\n",
    "\n",
    "    seed_dir = os.path.join(cfg.out_dir, f\"seed_{seed}\")\n",
    "    os.makedirs(seed_dir, exist_ok=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"[SEED {seed}] device={device}\")\n",
    "    print(f\"[SEED {seed}] out={seed_dir}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    # split\n",
    "    files = list_csv_files(cfg.data_dir)\n",
    "    splits = split_files(files, cfg.train_ratio, cfg.val_ratio, cfg.test_ratio, seed)\n",
    "\n",
    "    # save split lists\n",
    "    for k in [\"train\", \"val\", \"test\"]:\n",
    "        pd.Series([p.name for p in splits[k]]).to_csv(\n",
    "            os.path.join(seed_dir, f\"{k}_files.csv\"), index=False, header=False\n",
    "        )\n",
    "\n",
    "    # datasets (fit scaler on train only)\n",
    "    scaler_x = StandardScaler()\n",
    "    train_ds = WindowedRULDatasetNormMinVCE_Trial16(\n",
    "        splits[\"train\"], cfg, scaler_x=scaler_x, fit_scaler=True, is_train=True\n",
    "    )\n",
    "    val_ds = WindowedRULDatasetNormMinVCE_Trial16(\n",
    "        splits[\"val\"], cfg, scaler_x=train_ds.scaler_x, fit_scaler=False, is_train=False\n",
    "    )\n",
    "    test_ds = WindowedRULDatasetNormMinVCE_Trial16(\n",
    "        splits[\"test\"], cfg, scaler_x=train_ds.scaler_x, fit_scaler=False, is_train=False\n",
    "    )\n",
    "\n",
    "    feat_list = feature_names(cfg)\n",
    "    pd.DataFrame({\n",
    "        \"feature\": feat_list,\n",
    "        \"mean\": train_ds.scaler_x.mean_.ravel(),\n",
    "        \"std\": np.sqrt(train_ds.scaler_x.var_).ravel(),\n",
    "    }).to_csv(os.path.join(seed_dir, \"scaler_x_mean_std.csv\"), index=False)\n",
    "\n",
    "    # loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "\n",
    "    train_eval = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "    val_eval = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "    test_eval = DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "\n",
    "    # model\n",
    "    input_size = len(feat_list)\n",
    "    model = LSTMRegressor(\n",
    "        input_size=input_size,\n",
    "        hidden_size=cfg.hidden_size,\n",
    "        num_layers=cfg.num_layers,\n",
    "        dropout=cfg.dropout,\n",
    "        pooling=cfg.pooling,\n",
    "        pool_last_k=cfg.pool_last_k,\n",
    "        attn_dim=cfg.attn_dim,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "    best_by_val_norm = float(\"inf\")\n",
    "    best_path = os.path.join(seed_dir, \"best_by_val_norm.pt\")\n",
    "    last_path = os.path.join(seed_dir, \"last_epoch.pt\")\n",
    "\n",
    "    history: List[Dict[str, Any]] = []\n",
    "    bad_epochs = 0\n",
    "\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        model.train()\n",
    "        losses = []\n",
    "\n",
    "        for x, y_norm, *_ in train_loader:\n",
    "            x = x.to(device)\n",
    "            y_norm = y_norm.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_norm = model(x)\n",
    "\n",
    "            # ✅ Trial16 change: tail-weighted loss\n",
    "            loss = tail_weighted_mse(pred_norm, y_norm, cfg)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if cfg.grad_clip and cfg.grad_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        train_loss = float(np.mean(losses)) if losses else float(\"nan\")\n",
    "        val_metrics = evaluate_basic(model, val_loader, device)\n",
    "\n",
    "        history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_rmse_norm\": val_metrics[\"rmse_norm\"],\n",
    "            \"val_mae_norm\": val_metrics[\"mae_norm\"],\n",
    "            \"val_rmse_cycles\": val_metrics[\"rmse_cycles\"],\n",
    "            \"val_mae_cycles\": val_metrics[\"mae_cycles\"],\n",
    "        })\n",
    "\n",
    "        if val_metrics[\"rmse_norm\"] < best_by_val_norm:\n",
    "            best_by_val_norm = val_metrics[\"rmse_norm\"]\n",
    "            bad_epochs = 0\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(\n",
    "                f\"[SEED {seed}] [{epoch:03d}/{cfg.epochs}] \"\n",
    "                f\"train_loss={train_loss:.6f} | \"\n",
    "                f\"val_rmse_norm={val_metrics['rmse_norm']:.6f} | \"\n",
    "                f\"val_mae_cycles={val_metrics['mae_cycles']:.3f} | \"\n",
    "                f\"best_val_rmse_norm={best_by_val_norm:.6f}\"\n",
    "            )\n",
    "\n",
    "        if bad_epochs >= cfg.patience:\n",
    "            print(f\"[SEED {seed}] Early stopping at epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "    pd.DataFrame(history).to_csv(os.path.join(seed_dir, \"history.csv\"), index=False)\n",
    "    torch.save(model.state_dict(), last_path)\n",
    "\n",
    "    def export_ckpt(tag: str, ckpt_path: str) -> Dict[str, Any]:\n",
    "        sub_dir = os.path.join(seed_dir, tag)\n",
    "        os.makedirs(sub_dir, exist_ok=True)\n",
    "\n",
    "        model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        tr = evaluate_basic(model, train_eval, device)\n",
    "        va = evaluate_basic(model, val_eval, device)\n",
    "        te = evaluate_basic(model, test_eval, device)\n",
    "\n",
    "        for split_name, loader in [(\"train\", train_eval), (\"val\", val_eval), (\"test\", test_eval)]:\n",
    "            win_csv = os.path.join(sub_dir, f\"{split_name}_predictions_windows.csv\")\n",
    "            save_predictions_windows_csv(model, loader, device, win_csv, seq_len=cfg.seq_len)\n",
    "\n",
    "            seq_csv, metrics_csv = compute_metrics_from_windows_csv(\n",
    "                windows_csv=win_csv,\n",
    "                seq_len=cfg.seq_len,\n",
    "                alpha=cfg.alpha,\n",
    "                ph_consecutive_m=cfg.ph_consecutive_m,\n",
    "                lambdas=cfg.lambdas,\n",
    "                eps_rul=cfg.eps_rul,\n",
    "                out_dir=sub_dir,\n",
    "                split_name=split_name,\n",
    "            )\n",
    "\n",
    "            if cfg.save_figures:\n",
    "                fig_dir = os.path.join(sub_dir, \"paper_figures\", split_name)\n",
    "                make_paper_figures_for_split(\n",
    "                    cycle_seq_csv=seq_csv,\n",
    "                    metrics_per_file_csv=metrics_csv,\n",
    "                    out_fig_dir=fig_dir,\n",
    "                    title_prefix=f\"SEED {seed} | {tag.upper()} | {split_name}\",\n",
    "                    alpha=cfg.alpha,\n",
    "                    lambda_to_plot=cfg.lambda_to_plot,\n",
    "                    max_files=cfg.max_files_to_plot,\n",
    "                )\n",
    "\n",
    "        ms = {\n",
    "            \"seed\": seed,\n",
    "            \"checkpoint\": tag,\n",
    "\n",
    "            \"train_rmse_cycles\": tr[\"rmse_cycles\"],\n",
    "            \"train_mae_cycles\": tr[\"mae_cycles\"],\n",
    "            \"train_rmse_norm\": tr[\"rmse_norm\"],\n",
    "            \"train_mae_norm\": tr[\"mae_norm\"],\n",
    "\n",
    "            \"val_rmse_cycles\": va[\"rmse_cycles\"],\n",
    "            \"val_mae_cycles\": va[\"mae_cycles\"],\n",
    "            \"val_rmse_norm\": va[\"rmse_norm\"],\n",
    "            \"val_mae_norm\": va[\"mae_norm\"],\n",
    "\n",
    "            \"test_rmse_cycles\": te[\"rmse_cycles\"],\n",
    "            \"test_mae_cycles\": te[\"mae_cycles\"],\n",
    "            \"test_rmse_norm\": te[\"rmse_norm\"],\n",
    "            \"test_mae_norm\": te[\"mae_norm\"],\n",
    "\n",
    "            \"stopped_epoch\": history[-1][\"epoch\"] if len(history) else None,\n",
    "            \"best_val_rmse_norm\": best_by_val_norm,\n",
    "\n",
    "            \"alpha\": cfg.alpha,\n",
    "            \"ph_consecutive_m\": cfg.ph_consecutive_m,\n",
    "            \"rep_method\": cfg.rep_method,\n",
    "            \"lambdas\": str(cfg.lambdas),\n",
    "            \"lambda_to_plot\": cfg.lambda_to_plot,\n",
    "\n",
    "            \"feature_dim\": input_size,\n",
    "            \"features\": \",\".join(feature_names(cfg)),\n",
    "\n",
    "            # Trial15 extras\n",
    "            \"pooling\": cfg.pooling,\n",
    "            \"pool_last_k\": cfg.pool_last_k,\n",
    "            \"tail_robust_enable\": int(cfg.tail_robust_enable),\n",
    "            \"tail_k_max\": cfg.tail_k_max,\n",
    "            \"tail_apply_p\": cfg.tail_apply_p,\n",
    "            \"tail_mode\": cfg.tail_mode,\n",
    "\n",
    "            # Trial16 extras\n",
    "            \"tail_weight_enable\": int(cfg.tail_weight_enable),\n",
    "            \"tail_weight_gamma\": cfg.tail_weight_gamma,\n",
    "            \"tail_weight_p\": cfg.tail_weight_p,\n",
    "            \"tail_weight_max\": cfg.tail_weight_max,\n",
    "        }\n",
    "        pd.DataFrame([ms]).to_csv(os.path.join(sub_dir, \"metrics_summary.csv\"), index=False)\n",
    "\n",
    "        print(\n",
    "            f\"[SEED {seed}] {tag}: TEST mae_cycles={te['mae_cycles']:.3f} | \"\n",
    "            f\"rmse_cycles={te['rmse_cycles']:.3f} | rmse_norm={te['rmse_norm']:.6f}\"\n",
    "        )\n",
    "        return ms\n",
    "\n",
    "    ms_best = export_ckpt(\"best_by_val_norm\", best_path)\n",
    "    ms_last = export_ckpt(\"last_epoch\", last_path)\n",
    "\n",
    "    return {\"seed\": seed, \"seed_dir\": seed_dir, \"best\": ms_best, \"last\": ms_last}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 11) Seed sweep + global comparison\n",
    "# ============================================================\n",
    "def summarize_across_seeds(cfg: Config, results: List[Dict[str, Any]]) -> None:\n",
    "    rows = []\n",
    "    for r in results:\n",
    "        rows.append(r[\"best\"])\n",
    "        rows.append(r[\"last\"])\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(os.path.join(cfg.out_dir, \"summary_across_seeds.csv\"), index=False)\n",
    "\n",
    "    def _isfinite(x: Any) -> bool:\n",
    "        try:\n",
    "            return bool(np.isfinite(float(x)))\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def win_rate(metric: str) -> Dict[str, Any]:\n",
    "        wins_last = 0\n",
    "        wins_best = 0\n",
    "        ties = 0\n",
    "        diffs = []\n",
    "\n",
    "        for r in results:\n",
    "            b = r[\"best\"][metric]\n",
    "            l = r[\"last\"][metric]\n",
    "            if _isfinite(b) and _isfinite(l):\n",
    "                diffs.append(float(l) - float(b))\n",
    "                if float(l) < float(b):\n",
    "                    wins_last += 1\n",
    "                elif float(b) < float(l):\n",
    "                    wins_best += 1\n",
    "                else:\n",
    "                    ties += 1\n",
    "\n",
    "        return {\n",
    "            \"metric\": metric,\n",
    "            \"wins_last\": wins_last,\n",
    "            \"wins_best\": wins_best,\n",
    "            \"ties\": ties,\n",
    "            \"mean(last-best)\": float(np.mean(diffs)) if diffs else float(\"nan\"),\n",
    "            \"std(last-best)\": float(np.std(diffs, ddof=0)) if diffs else float(\"nan\"),\n",
    "        }\n",
    "\n",
    "    metrics = [\"test_mae_cycles\", \"test_rmse_cycles\", \"test_mae_norm\", \"test_rmse_norm\"]\n",
    "    wr = [win_rate(m) for m in metrics]\n",
    "    pd.DataFrame(wr).to_csv(os.path.join(cfg.out_dir, \"win_rate_summary.csv\"), index=False)\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"=== WIN-RATE SUMMARY (TEST; lower is better) ===\")\n",
    "    for row in wr:\n",
    "        lines.append(\n",
    "            f\"- {row['metric']}: last wins={row['wins_last']}, best wins={row['wins_best']}, ties={row['ties']} | \"\n",
    "            f\"mean(last-best)={row['mean(last-best)']:.6f}, std(last-best)={row['std(last-best)']:.6f}\"\n",
    "        )\n",
    "\n",
    "    agg = df.groupby(\"checkpoint\")[metrics].agg([\"mean\", \"std\"])\n",
    "    lines.append(\"\\n=== MEAN ± STD across seeds (TEST) ===\")\n",
    "    lines.append(str(agg))\n",
    "\n",
    "    with open(os.path.join(cfg.out_dir, \"win_rate_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nSaved:\")\n",
    "    print(\" -\", os.path.join(cfg.out_dir, \"summary_across_seeds.csv\"))\n",
    "    print(\" -\", os.path.join(cfg.out_dir, \"win_rate_summary.csv\"))\n",
    "    print(\" -\", os.path.join(cfg.out_dir, \"win_rate_summary.txt\"))\n",
    "\n",
    "\n",
    "def run_trial16_seed_sweep(cfg: Config) -> None:\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    for seed in cfg.seeds:\n",
    "        res = run_one_seed(cfg, seed)\n",
    "        results.append(res)\n",
    "\n",
    "    summarize_across_seeds(cfg, results)\n",
    "\n",
    "    print(\"\\nDONE. Check Trial16 folder:\")\n",
    "    print(\" - per seed results: Trial16/seed_<seed>/...\")\n",
    "    print(\" - figures (paper-style): seed_<seed>/<ckpt>/paper_figures/<split>/\")\n",
    "    print(\" - cycle sequence mean CSV: <ckpt>/<split>_cycle_sequence_mean.csv\")\n",
    "    print(\" - PH/α–λ metrics CSV: <ckpt>/<split>_prognostics_metrics_per_file.csv\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 12) Run\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config(\n",
    "        data_dir=r\"C:\\Users\\11HOME_AHCI\\Desktop\\PoF\\Winter 2026\\Ref Data4\\100\",\n",
    "        out_dir=r\"./Trial16\",\n",
    "\n",
    "        seeds=(9819123, 111, 222, 333, 444),\n",
    "\n",
    "        seq_len=100,\n",
    "        stride=5,\n",
    "        pred_horizon=0,\n",
    "\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.2,\n",
    "        test_ratio=0.1,\n",
    "\n",
    "        batch_size=512,\n",
    "        epochs=300,\n",
    "        lr=1e-3,\n",
    "        weight_decay=0.0,\n",
    "        patience=30,\n",
    "        grad_clip=1.0,\n",
    "\n",
    "        hidden_size=512,\n",
    "        num_layers=2,\n",
    "        dropout=0.2,\n",
    "\n",
    "        save_figures=True,\n",
    "        max_files_to_plot=None,\n",
    "        num_workers=0,\n",
    "\n",
    "        alpha=0.20,\n",
    "        ph_consecutive_m=5,\n",
    "        rep_method=\"mean\",\n",
    "        lambdas=(0.2, 0.4, 0.6, 0.8),\n",
    "        lambda_to_plot=0.6,\n",
    "\n",
    "        # base features\n",
    "        delta_steps=(1, 5, 20, 50),\n",
    "        ema_spans=(10, 50),\n",
    "        roll_std_window=10,\n",
    "        add_window_stats=True,\n",
    "\n",
    "        # Trial15-1\n",
    "        add_damage_proxy=True,\n",
    "\n",
    "        # pooling (keep Trial14 default)\n",
    "        pooling=\"mean_last_k\",\n",
    "        pool_last_k=10,\n",
    "        attn_dim=128,\n",
    "\n",
    "        # Trial15-2\n",
    "        tail_robust_enable=True,\n",
    "        tail_k_max=10,\n",
    "        tail_apply_p=1.0,\n",
    "        tail_mode=\"mask\",\n",
    "        tail_mask_value=0.0,\n",
    "\n",
    "        # Trial16 (NEW)\n",
    "        tail_weight_enable=True,\n",
    "        tail_weight_gamma=5.0,\n",
    "        tail_weight_p=2.0,\n",
    "        tail_weight_max=20.0,\n",
    "    )\n",
    "\n",
    "    run_trial16_seed_sweep(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd18d0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ BEST MODEL (Trial16) ================\n",
      "[SELECTED BY VAL]  (recommended for model selection)\n",
      "  Seed             : 222\n",
      "  Checkpoint       : best_by_val_norm\n",
      "  VAL  RMSE (cyc)   : 460.444\n",
      "  VAL  MAE  (cyc)   : 287.159\n",
      "  VAL  RMSE (norm)  : 0.027871\n",
      "  VAL  MAE  (norm)  : 0.021838\n",
      "  TEST RMSE (cyc)   : 565.104\n",
      "  TEST MAE  (cyc)   : 376.225\n",
      "  TEST RMSE (norm)  : 0.025971\n",
      "  TEST MAE  (norm)  : 0.019829\n",
      "\n",
      "[SELECTED BY TEST] (for reporting only; not for tuning)\n",
      "  Seed             : 333\n",
      "  Checkpoint       : best_by_val_norm\n",
      "  TEST RMSE (cyc)   : 157.840\n",
      "  TEST MAE  (cyc)   : 119.948\n",
      "  TEST RMSE (norm)  : 0.029590\n",
      "  TEST MAE  (norm)  : 0.022665\n",
      "  VAL  RMSE (cyc)   : 612.667\n",
      "  VAL  MAE  (cyc)   : 479.469\n",
      "  VAL  RMSE (norm)  : 0.037635\n",
      "  VAL  MAE  (norm)  : 0.030291\n",
      "\n",
      "---------------- WIN-RATE (last_epoch vs best_by_val_norm) ----------------\n",
      "- val_rmse_cycles: last wins=0, best wins=5, ties=0 | mean(last-best)=340.634458\n",
      "- test_rmse_cycles: last wins=0, best wins=5, ties=0 | mean(last-best)=166.224092\n",
      "- val_rmse_norm: last wins=0, best wins=5, ties=0 | mean(last-best)=0.013667\n",
      "- test_rmse_norm: last wins=0, best wins=5, ties=0 | mean(last-best)=0.007260\n",
      "=====================================================\n",
      "\n",
      "Saved -> ./Trial16\\BEST_MODEL_BY_VAL.txt\n",
      "(Info) Found -> ./Trial16\\win_rate_summary.csv\n",
      "(Info) Found -> ./Trial16\\win_rate_summary.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================\n",
    "# Trial16 paths\n",
    "# ============================\n",
    "TRIAL_DIR = \"./Trial16\"\n",
    "SUMMARY_CSV = os.path.join(TRIAL_DIR, \"summary_across_seeds.csv\")\n",
    "\n",
    "BEST_TAG = \"best_by_val_norm\"\n",
    "LAST_TAG = \"last_epoch\"\n",
    "\n",
    "\n",
    "def _require_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in summary CSV: {missing}\")\n",
    "\n",
    "\n",
    "def pick_best_row(df: pd.DataFrame, metric_prefix: str = \"val\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    metric_prefix: \"val\" or \"test\"\n",
    "    Sort rule:\n",
    "      1) <prefix>_rmse_cycles ascending\n",
    "      2) <prefix>_mae_cycles  ascending\n",
    "    \"\"\"\n",
    "    rmse_col = f\"{metric_prefix}_rmse_cycles\"\n",
    "    mae_col = f\"{metric_prefix}_mae_cycles\"\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", rmse_col, mae_col])\n",
    "\n",
    "    df_sorted = df.sort_values(\n",
    "        by=[rmse_col, mae_col],\n",
    "        ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return df_sorted.iloc[0]\n",
    "\n",
    "\n",
    "def win_rate(df: pd.DataFrame, metric: str) -> dict:\n",
    "    \"\"\"\n",
    "    Compare BEST_TAG vs LAST_TAG within each seed on the given metric (lower is better).\n",
    "    Returns wins for last, wins for best, ties, and mean(last-best).\n",
    "    \"\"\"\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", metric])\n",
    "\n",
    "    wins_last = 0\n",
    "    wins_best = 0\n",
    "    ties = 0\n",
    "    diffs = []\n",
    "\n",
    "    for seed, g in df.groupby(\"seed\"):\n",
    "        ckpts = set(g[\"checkpoint\"].astype(str).values)\n",
    "        if not ({BEST_TAG, LAST_TAG} <= ckpts):\n",
    "            continue\n",
    "\n",
    "        b = float(g.loc[g[\"checkpoint\"] == BEST_TAG, metric].iloc[0])\n",
    "        l = float(g.loc[g[\"checkpoint\"] == LAST_TAG, metric].iloc[0])\n",
    "\n",
    "        if np.isfinite(b) and np.isfinite(l):\n",
    "            diffs.append(l - b)  # negative => last better\n",
    "            if l < b:\n",
    "                wins_last += 1\n",
    "            elif b < l:\n",
    "                wins_best += 1\n",
    "            else:\n",
    "                ties += 1\n",
    "\n",
    "    return {\n",
    "        \"metric\": metric,\n",
    "        \"wins_last\": wins_last,\n",
    "        \"wins_best\": wins_best,\n",
    "        \"ties\": ties,\n",
    "        \"mean(last-best)\": float(np.mean(diffs)) if diffs else float(\"nan\"),\n",
    "        \"std(last-best)\": float(np.std(diffs, ddof=0)) if diffs else float(\"nan\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(SUMMARY_CSV):\n",
    "        raise FileNotFoundError(f\"Not found: {SUMMARY_CSV}\")\n",
    "\n",
    "    df = pd.read_csv(SUMMARY_CSV)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) VAL 기준 best (권장)\n",
    "    # -----------------------------\n",
    "    best_val = pick_best_row(df, metric_prefix=\"val\")\n",
    "    best_val_seed = int(best_val[\"seed\"])\n",
    "    best_val_ckpt = str(best_val[\"checkpoint\"])\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2) TEST 기준 best (참고)\n",
    "    # -----------------------------\n",
    "    best_test = pick_best_row(df, metric_prefix=\"test\")\n",
    "    best_test_seed = int(best_test[\"seed\"])\n",
    "    best_test_ckpt = str(best_test[\"checkpoint\"])\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3) win-rate (seed별 last vs best 비교)\n",
    "    # -----------------------------\n",
    "    wr_val_rmse = win_rate(df, \"val_rmse_cycles\")\n",
    "    wr_test_rmse = win_rate(df, \"test_rmse_cycles\")\n",
    "\n",
    "    # Trial 계열에서 norm 지표도 같이 확인\n",
    "    wr_val_rmse_norm = win_rate(df, \"val_rmse_norm\")\n",
    "    wr_test_rmse_norm = win_rate(df, \"test_rmse_norm\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4) 출력\n",
    "    # -----------------------------\n",
    "    print(\"\\n================ BEST MODEL (Trial16) ================\")\n",
    "    print(\"[SELECTED BY VAL]  (recommended for model selection)\")\n",
    "    print(f\"  Seed             : {best_val_seed}\")\n",
    "    print(f\"  Checkpoint       : {best_val_ckpt}\")\n",
    "    print(f\"  VAL  RMSE (cyc)   : {best_val['val_rmse_cycles']:.3f}\")\n",
    "    print(f\"  VAL  MAE  (cyc)   : {best_val['val_mae_cycles']:.3f}\")\n",
    "    print(f\"  VAL  RMSE (norm)  : {best_val['val_rmse_norm']:.6f}\")\n",
    "    print(f\"  VAL  MAE  (norm)  : {best_val['val_mae_norm']:.6f}\")\n",
    "    print(f\"  TEST RMSE (cyc)   : {best_val['test_rmse_cycles']:.3f}\")\n",
    "    print(f\"  TEST MAE  (cyc)   : {best_val['test_mae_cycles']:.3f}\")\n",
    "    print(f\"  TEST RMSE (norm)  : {best_val['test_rmse_norm']:.6f}\")\n",
    "    print(f\"  TEST MAE  (norm)  : {best_val['test_mae_norm']:.6f}\")\n",
    "\n",
    "    print(\"\\n[SELECTED BY TEST] (for reporting only; not for tuning)\")\n",
    "    print(f\"  Seed             : {best_test_seed}\")\n",
    "    print(f\"  Checkpoint       : {best_test_ckpt}\")\n",
    "    print(f\"  TEST RMSE (cyc)   : {best_test['test_rmse_cycles']:.3f}\")\n",
    "    print(f\"  TEST MAE  (cyc)   : {best_test['test_mae_cycles']:.3f}\")\n",
    "    print(f\"  TEST RMSE (norm)  : {best_test['test_rmse_norm']:.6f}\")\n",
    "    print(f\"  TEST MAE  (norm)  : {best_test['test_mae_norm']:.6f}\")\n",
    "    print(f\"  VAL  RMSE (cyc)   : {best_test['val_rmse_cycles']:.3f}\")\n",
    "    print(f\"  VAL  MAE  (cyc)   : {best_test['val_mae_cycles']:.3f}\")\n",
    "    print(f\"  VAL  RMSE (norm)  : {best_test['val_rmse_norm']:.6f}\")\n",
    "    print(f\"  VAL  MAE  (norm)  : {best_test['val_mae_norm']:.6f}\")\n",
    "\n",
    "    print(\"\\n---------------- WIN-RATE (last_epoch vs best_by_val_norm) ----------------\")\n",
    "    print(f\"- {wr_val_rmse['metric']}: last wins={wr_val_rmse['wins_last']}, \"\n",
    "          f\"best wins={wr_val_rmse['wins_best']}, ties={wr_val_rmse['ties']} | \"\n",
    "          f\"mean(last-best)={wr_val_rmse['mean(last-best)']:.6f}\")\n",
    "    print(f\"- {wr_test_rmse['metric']}: last wins={wr_test_rmse['wins_last']}, \"\n",
    "          f\"best wins={wr_test_rmse['wins_best']}, ties={wr_test_rmse['ties']} | \"\n",
    "          f\"mean(last-best)={wr_test_rmse['mean(last-best)']:.6f}\")\n",
    "    print(f\"- {wr_val_rmse_norm['metric']}: last wins={wr_val_rmse_norm['wins_last']}, \"\n",
    "          f\"best wins={wr_val_rmse_norm['wins_best']}, ties={wr_val_rmse_norm['ties']} | \"\n",
    "          f\"mean(last-best)={wr_val_rmse_norm['mean(last-best)']:.6f}\")\n",
    "    print(f\"- {wr_test_rmse_norm['metric']}: last wins={wr_test_rmse_norm['wins_last']}, \"\n",
    "          f\"best wins={wr_test_rmse_norm['wins_best']}, ties={wr_test_rmse_norm['ties']} | \"\n",
    "          f\"mean(last-best)={wr_test_rmse_norm['mean(last-best)']:.6f}\")\n",
    "    print(\"=====================================================\\n\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5) 기록 저장 (VAL 기준 best)\n",
    "    # -----------------------------\n",
    "    out_txt = os.path.join(TRIAL_DIR, \"BEST_MODEL_BY_VAL.txt\")\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"BEST MODEL (Trial16) - Selected by VAL\\n\")\n",
    "        f.write(f\"seed={best_val_seed}\\n\")\n",
    "        f.write(f\"checkpoint={best_val_ckpt}\\n\")\n",
    "        f.write(f\"val_rmse_cycles={best_val['val_rmse_cycles']}\\n\")\n",
    "        f.write(f\"val_mae_cycles={best_val['val_mae_cycles']}\\n\")\n",
    "        f.write(f\"val_rmse_norm={best_val['val_rmse_norm']}\\n\")\n",
    "        f.write(f\"val_mae_norm={best_val['val_mae_norm']}\\n\")\n",
    "        f.write(f\"test_rmse_cycles={best_val['test_rmse_cycles']}\\n\")\n",
    "        f.write(f\"test_mae_cycles={best_val['test_mae_cycles']}\\n\")\n",
    "        f.write(f\"test_rmse_norm={best_val['test_rmse_norm']}\\n\")\n",
    "        f.write(f\"test_mae_norm={best_val['test_mae_norm']}\\n\")\n",
    "\n",
    "    print(f\"Saved -> {out_txt}\")\n",
    "\n",
    "    # (선택) Trial16이 이미 만들어둔 win-rate 파일도 안내\n",
    "    wr_csv = os.path.join(TRIAL_DIR, \"win_rate_summary.csv\")\n",
    "    wr_txt = os.path.join(TRIAL_DIR, \"win_rate_summary.txt\")\n",
    "    if os.path.exists(wr_csv):\n",
    "        print(f\"(Info) Found -> {wr_csv}\")\n",
    "    if os.path.exists(wr_txt):\n",
    "        print(f\"(Info) Found -> {wr_txt}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afbe2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ SELECTION (from summary_across_seeds.csv) ================\n",
      "[BEST BY VAL]  seed=222, ckpt=best_by_val_norm, val_rmse_cycles=460.444, val_mae_cycles=287.159\n",
      "[BEST BY TEST] seed=333, ckpt=best_by_val_norm, test_rmse_cycles=157.840, test_mae_cycles=119.948\n",
      "============================================================================\n",
      "\n",
      "[selected_by_val] [OK] train: λ=0.20:1.000, λ=0.40:1.000, λ=0.60:1.000, λ=0.80:0.900 | mean_all=0.975\n",
      "[selected_by_val] [OK] val: λ=0.20:1.000, λ=0.40:1.000, λ=0.60:1.000, λ=0.80:0.700 | mean_all=0.925\n",
      "[selected_by_val] [OK] test: λ=0.20:1.000, λ=0.40:1.000, λ=0.60:1.000, λ=0.80:0.800 | mean_all=0.950\n",
      "\n",
      "==================== DONE ====================\n",
      "Trial: Trial16 | selection=selected_by_val | seed=222 | ckpt=best_by_val_norm\n",
      "Saved:\n",
      " - ./Trial16\\alpha_lambda_eval\\selected_by_val\\seed_222\\best_by_val_norm\\alpha_lambda_summary__selected_by_val__seed222_best_by_val_norm.csv\n",
      " - ./Trial16\\alpha_lambda_eval\\selected_by_val\\seed_222\\best_by_val_norm\\alpha_lambda_per_file__selected_by_val__seed222_best_by_val_norm.csv\n",
      "==============================================\n",
      "\n",
      "--- Quick view ---\n",
      "split  n_files       lambdas_found  rate_0.20  rate_0.40  rate_0.60  rate_0.80  rate_mean_all\n",
      "train       70 0.20,0.40,0.60,0.80        1.0        1.0        1.0        0.9          0.975\n",
      "  val       20 0.20,0.40,0.60,0.80        1.0        1.0        1.0        0.7          0.925\n",
      " test       10 0.20,0.40,0.60,0.80        1.0        1.0        1.0        0.8          0.950\n",
      "\n",
      "[selected_by_test] [OK] train: λ=0.20:1.000, λ=0.40:1.000, λ=0.60:1.000, λ=0.80:0.900 | mean_all=0.975\n",
      "[selected_by_test] [OK] val: λ=0.20:1.000, λ=0.40:0.950, λ=0.60:1.000, λ=0.80:0.900 | mean_all=0.963\n",
      "[selected_by_test] [OK] test: λ=0.20:1.000, λ=0.40:1.000, λ=0.60:1.000, λ=0.80:0.800 | mean_all=0.950\n",
      "\n",
      "==================== DONE ====================\n",
      "Trial: Trial16 | selection=selected_by_test | seed=333 | ckpt=best_by_val_norm\n",
      "Saved:\n",
      " - ./Trial16\\alpha_lambda_eval\\selected_by_test\\seed_333\\best_by_val_norm\\alpha_lambda_summary__selected_by_test__seed333_best_by_val_norm.csv\n",
      " - ./Trial16\\alpha_lambda_eval\\selected_by_test\\seed_333\\best_by_val_norm\\alpha_lambda_per_file__selected_by_test__seed333_best_by_val_norm.csv\n",
      "==============================================\n",
      "\n",
      "--- Quick view ---\n",
      "split  n_files       lambdas_found  rate_0.20  rate_0.40  rate_0.60  rate_0.80  rate_mean_all\n",
      "train       70 0.20,0.40,0.60,0.80        1.0       1.00        1.0        0.9         0.9750\n",
      "  val       20 0.20,0.40,0.60,0.80        1.0       0.95        1.0        0.9         0.9625\n",
      " test       10 0.20,0.40,0.60,0.80        1.0       1.00        1.0        0.8         0.9500\n",
      "\n",
      "ALL DONE.\n",
      "Check outputs under:\n",
      "./Trial16\\alpha_lambda_eval\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# USER CONFIG (Trial16)\n",
    "# =========================\n",
    "TRIAL_DIR = r\"./Trial16\"                 # ✅ Trial16 루트\n",
    "SPLITS = [\"train\", \"val\", \"test\"]        # 평가할 split\n",
    "\n",
    "# (선택) 후반 λ를 더 중요하게 보고 싶으면 가중치 사용\n",
    "# 예: {\"0.20\":1, \"0.40\":1, \"0.60\":2, \"0.80\":3}\n",
    "LAMBDA_WEIGHTS = None\n",
    "\n",
    "# summary 파일 (Trial16 seed sweep 결과)\n",
    "SUMMARY_CSV = os.path.join(TRIAL_DIR, \"summary_across_seeds.csv\")\n",
    "\n",
    "BEST_TAG = \"best_by_val_norm\"\n",
    "LAST_TAG = \"last_epoch\"\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _require_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "\n",
    "def _list_dir(path: str):\n",
    "    if not os.path.isdir(path):\n",
    "        return []\n",
    "    return sorted([p for p in os.listdir(path)])\n",
    "\n",
    "\n",
    "def discover_lambdas_from_columns(dfm: pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    compute_metrics_for_one_file()가 생성하는 컬럼:\n",
    "      - alpha_lambda_ok_{lam:.2f}\n",
    "      - t_lambda_{lam:.2f}\n",
    "    여기서 lam 문자열(\"0.20\")을 자동 추출.\n",
    "    \"\"\"\n",
    "    lam = []\n",
    "    pat = re.compile(r\"^alpha_lambda_ok_(\\d+\\.\\d+)$\")\n",
    "    for c in dfm.columns:\n",
    "        m = pat.match(c)\n",
    "        if m:\n",
    "            lam.append(m.group(1))\n",
    "    lam = sorted(set(lam), key=lambda s: float(s))\n",
    "    return lam\n",
    "\n",
    "\n",
    "def compute_alpha_lambda_rates(dfm: pd.DataFrame, lam_strs: list, weights=None) -> dict:\n",
    "    \"\"\"\n",
    "    dfm: <split>_prognostics_metrics_per_file.csv (per-file summary)\n",
    "    Returns:\n",
    "      - per-lambda success rate (mean of alpha_lambda_ok_{lam})\n",
    "      - overall mean rate (simple mean or weighted mean)\n",
    "    \"\"\"\n",
    "    rates = {}\n",
    "\n",
    "    for ls in lam_strs:\n",
    "        col = f\"alpha_lambda_ok_{ls}\"\n",
    "        if col in dfm.columns:\n",
    "            rates[f\"rate_{ls}\"] = float(dfm[col].mean())  # 0/1 평균 = 성공률\n",
    "        else:\n",
    "            rates[f\"rate_{ls}\"] = np.nan\n",
    "\n",
    "    # overall score\n",
    "    if weights is None:\n",
    "        vals = [rates[f\"rate_{ls}\"] for ls in lam_strs if np.isfinite(rates[f\"rate_{ls}\"])]\n",
    "        rates[\"rate_mean_all\"] = float(np.mean(vals)) if vals else np.nan\n",
    "    else:\n",
    "        num = 0.0\n",
    "        den = 0.0\n",
    "        for ls in lam_strs:\n",
    "            v = rates[f\"rate_{ls}\"]\n",
    "            w = float(weights.get(ls, 0.0))\n",
    "            if np.isfinite(v) and w > 0:\n",
    "                num += w * v\n",
    "                den += w\n",
    "        rates[\"rate_weighted_all\"] = (num / den) if den > 0 else np.nan\n",
    "\n",
    "    return rates\n",
    "\n",
    "\n",
    "def pick_best_row(df: pd.DataFrame, metric_prefix: str = \"val\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    metric_prefix: \"val\" or \"test\"\n",
    "    Sort rule:\n",
    "      1) <prefix>_rmse_cycles ascending\n",
    "      2) <prefix>_mae_cycles  ascending\n",
    "    \"\"\"\n",
    "    rmse_col = f\"{metric_prefix}_rmse_cycles\"\n",
    "    mae_col = f\"{metric_prefix}_mae_cycles\"\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", rmse_col, mae_col])\n",
    "\n",
    "    df_sorted = df.sort_values(\n",
    "        by=[rmse_col, mae_col],\n",
    "        ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return df_sorted.iloc[0]\n",
    "\n",
    "\n",
    "def run_alpha_lambda_for_one_selection(selection_name: str, seed: int, ckpt: str) -> None:\n",
    "    \"\"\"\n",
    "    selection_name: \"selected_by_val\" or \"selected_by_test\"\n",
    "    seed, ckpt: chosen from summary_across_seeds.csv\n",
    "    \"\"\"\n",
    "    seed_dir = os.path.join(TRIAL_DIR, f\"seed_{seed}\", ckpt)\n",
    "    if not os.path.isdir(seed_dir):\n",
    "        seed_root = os.path.join(TRIAL_DIR, f\"seed_{seed}\")\n",
    "        msg = [\n",
    "            f\"[{selection_name}] Not found: {seed_dir}\",\n",
    "            f\"Available under {TRIAL_DIR}: {_list_dir(TRIAL_DIR)}\",\n",
    "            f\"Available ckpts under {seed_root}: {_list_dir(seed_root)}\",\n",
    "        ]\n",
    "        raise FileNotFoundError(\"\\n\".join(msg))\n",
    "\n",
    "    # ✅ 저장은 Trial16 루트 아래로 (한 군데에 모으기)\n",
    "    out_dir = os.path.join(TRIAL_DIR, \"alpha_lambda_eval\", selection_name, f\"seed_{seed}\", ckpt)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    summary_rows = []\n",
    "    per_file_rows = []\n",
    "\n",
    "    for split in SPLITS:\n",
    "        mpath = os.path.join(seed_dir, f\"{split}_prognostics_metrics_per_file.csv\")\n",
    "        if not os.path.exists(mpath):\n",
    "            print(f\"[{selection_name}] [SKIP] Missing: {mpath}\")\n",
    "            continue\n",
    "\n",
    "        dfm = pd.read_csv(mpath)\n",
    "        _require_cols(dfm, [\"file\"])\n",
    "\n",
    "        lam_strs = discover_lambdas_from_columns(dfm)\n",
    "        if not lam_strs:\n",
    "            print(f\"[{selection_name}] [WARN] No alpha_lambda_ok_* columns in: {mpath}\")\n",
    "            continue\n",
    "\n",
    "        rates = compute_alpha_lambda_rates(dfm, lam_strs, weights=LAMBDA_WEIGHTS)\n",
    "\n",
    "        row = {\n",
    "            \"trial\": \"Trial16\",\n",
    "            \"selection\": selection_name,\n",
    "            \"seed\": int(seed),\n",
    "            \"checkpoint\": str(ckpt),\n",
    "            \"split\": split,\n",
    "            \"n_files\": int(len(dfm)),\n",
    "            \"lambdas_found\": \",\".join(lam_strs),\n",
    "            **rates,\n",
    "        }\n",
    "        summary_rows.append(row)\n",
    "\n",
    "        # per-file export\n",
    "        keep_cols = [\"file\"]\n",
    "        for ls in lam_strs:\n",
    "            c_ok = f\"alpha_lambda_ok_{ls}\"\n",
    "            c_tl = f\"t_lambda_{ls}\"\n",
    "            if c_ok in dfm.columns:\n",
    "                keep_cols.append(c_ok)\n",
    "            if c_tl in dfm.columns:\n",
    "                keep_cols.append(c_tl)\n",
    "\n",
    "        sub = dfm[keep_cols].copy()\n",
    "        sub.insert(0, \"split\", split)\n",
    "        sub.insert(0, \"checkpoint\", ckpt)\n",
    "        sub.insert(0, \"seed\", seed)\n",
    "        sub.insert(0, \"selection\", selection_name)\n",
    "        sub.insert(0, \"trial\", \"Trial16\")\n",
    "        per_file_rows.append(sub)\n",
    "\n",
    "        # console\n",
    "        msg_parts = []\n",
    "        for ls in lam_strs:\n",
    "            v = row.get(f\"rate_{ls}\", np.nan)\n",
    "            if np.isfinite(v):\n",
    "                msg_parts.append(f\"λ={ls}:{v:.3f}\")\n",
    "        msg = \", \".join(msg_parts) if msg_parts else \"no lambda columns found\"\n",
    "\n",
    "        tail = \"\"\n",
    "        if \"rate_weighted_all\" in row and np.isfinite(row[\"rate_weighted_all\"]):\n",
    "            tail = f\" | weighted_all={row['rate_weighted_all']:.3f}\"\n",
    "        elif \"rate_mean_all\" in row and np.isfinite(row[\"rate_mean_all\"]):\n",
    "            tail = f\" | mean_all={row['rate_mean_all']:.3f}\"\n",
    "\n",
    "        print(f\"[{selection_name}] [OK] {split}: {msg}{tail}\")\n",
    "\n",
    "    # save\n",
    "    df_summary = pd.DataFrame(summary_rows)\n",
    "    out_summary = os.path.join(out_dir, f\"alpha_lambda_summary__{selection_name}__seed{seed}_{ckpt}.csv\")\n",
    "    df_summary.to_csv(out_summary, index=False)\n",
    "\n",
    "    out_pf = None\n",
    "    if per_file_rows:\n",
    "        df_pf = pd.concat(per_file_rows, axis=0, ignore_index=True)\n",
    "        out_pf = os.path.join(out_dir, f\"alpha_lambda_per_file__{selection_name}__seed{seed}_{ckpt}.csv\")\n",
    "        df_pf.to_csv(out_pf, index=False)\n",
    "\n",
    "    print(\"\\n==================== DONE ====================\")\n",
    "    print(f\"Trial: Trial16 | selection={selection_name} | seed={seed} | ckpt={ckpt}\")\n",
    "    print(\"Saved:\")\n",
    "    print(\" -\", out_summary)\n",
    "    if out_pf:\n",
    "        print(\" -\", out_pf)\n",
    "    print(\"==============================================\")\n",
    "\n",
    "    if not df_summary.empty:\n",
    "        base = [\"split\", \"n_files\", \"lambdas_found\"]\n",
    "        extra = [c for c in df_summary.columns if c.startswith(\"rate_\")]\n",
    "        show_cols = [c for c in (base + extra) if c in df_summary.columns]\n",
    "        print(\"\\n--- Quick view ---\")\n",
    "        print(df_summary[show_cols].to_string(index=False))\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(SUMMARY_CSV):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Not found: {SUMMARY_CSV}\\n\"\n",
    "            f\"먼저 Trial16 학습 스크립트(run_trial16_seed_sweep)를 실행해 summary_across_seeds.csv를 생성하세요.\"\n",
    "        )\n",
    "\n",
    "    df = pd.read_csv(SUMMARY_CSV)\n",
    "\n",
    "    # ✅ 이미지에서 네가 본 것과 같은 로직:\n",
    "    # - best by val: val_rmse_cycles -> val_mae_cycles\n",
    "    # - best by test: test_rmse_cycles -> test_mae_cycles\n",
    "    best_val = pick_best_row(df, metric_prefix=\"val\")\n",
    "    best_test = pick_best_row(df, metric_prefix=\"test\")\n",
    "\n",
    "    best_val_seed = int(best_val[\"seed\"])\n",
    "    best_val_ckpt = str(best_val[\"checkpoint\"])\n",
    "    best_test_seed = int(best_test[\"seed\"])\n",
    "    best_test_ckpt = str(best_test[\"checkpoint\"])\n",
    "\n",
    "    print(\"\\n================ SELECTION (from summary_across_seeds.csv) ================\")\n",
    "    print(f\"[BEST BY VAL]  seed={best_val_seed}, ckpt={best_val_ckpt}, \"\n",
    "          f\"val_rmse_cycles={best_val['val_rmse_cycles']:.3f}, val_mae_cycles={best_val['val_mae_cycles']:.3f}\")\n",
    "    print(f\"[BEST BY TEST] seed={best_test_seed}, ckpt={best_test_ckpt}, \"\n",
    "          f\"test_rmse_cycles={best_test['test_rmse_cycles']:.3f}, test_mae_cycles={best_test['test_mae_cycles']:.3f}\")\n",
    "    print(\"============================================================================\\n\")\n",
    "\n",
    "    run_alpha_lambda_for_one_selection(\"selected_by_val\", best_val_seed, best_val_ckpt)\n",
    "    print()\n",
    "    run_alpha_lambda_for_one_selection(\"selected_by_test\", best_test_seed, best_test_ckpt)\n",
    "\n",
    "    print(\"\\nALL DONE.\")\n",
    "    print(\"Check outputs under:\")\n",
    "    print(os.path.join(TRIAL_DIR, \"alpha_lambda_eval\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4599d9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Using selections from Trial16 summary ===\n",
      "[BEST BY VAL]  seed=222, ckpt=best_by_val_norm\n",
      "[BEST BY TEST] seed=333, ckpt=best_by_val_norm\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] ./Trial16\\alpha_lambda_eval\\selected_by_val\\seed_222\\best_by_val_norm\\alpha_lambda_curve__selected_by_val__seed222_best_by_val_norm.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] ./Trial16\\alpha_lambda_eval\\selected_by_test\\seed_333\\best_by_val_norm\\alpha_lambda_curve__selected_by_test__seed333_best_by_val_norm.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# USER CONFIG\n",
    "# =========================\n",
    "TRIAL_DIR = r\"./Trial16\"\n",
    "SUMMARY_ACROSS = os.path.join(TRIAL_DIR, \"summary_across_seeds.csv\")\n",
    "\n",
    "BEST_TAG = \"best_by_val_norm\"\n",
    "LAST_TAG = \"last_epoch\"\n",
    "\n",
    "# 기본 λ (파일에 없으면 이걸로 시도)\n",
    "DEFAULT_LAM_STRS = [\"0.20\", \"0.40\", \"0.60\", \"0.80\"]\n",
    "SPLITS_ORDER = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _require_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "\n",
    "def pick_best_row(df: pd.DataFrame, metric_prefix: str = \"val\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    metric_prefix: \"val\" or \"test\"\n",
    "    Sort rule:\n",
    "      1) <prefix>_rmse_cycles ascending\n",
    "      2) <prefix>_mae_cycles  ascending\n",
    "    \"\"\"\n",
    "    rmse_col = f\"{metric_prefix}_rmse_cycles\"\n",
    "    mae_col = f\"{metric_prefix}_mae_cycles\"\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", rmse_col, mae_col])\n",
    "\n",
    "    df_sorted = df.sort_values(\n",
    "        by=[rmse_col, mae_col],\n",
    "        ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return df_sorted.iloc[0]\n",
    "\n",
    "\n",
    "def infer_lam_strs_from_summary(df_sum: pd.DataFrame):\n",
    "    # rate_0.20, rate_0.40 ... 컬럼에서 자동 추출\n",
    "    lam = []\n",
    "    for c in df_sum.columns:\n",
    "        if c.startswith(\"rate_\") and c not in (\"rate_mean_all\", \"rate_weighted_all\"):\n",
    "            lam.append(c.replace(\"rate_\", \"\"))\n",
    "    lam = sorted(set(lam), key=lambda s: float(s))\n",
    "    if lam:\n",
    "        return lam\n",
    "    return DEFAULT_LAM_STRS\n",
    "\n",
    "\n",
    "def plot_one(summary_csv: str, out_png: str, title: str):\n",
    "    if not os.path.exists(summary_csv):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Not found: {summary_csv}\\n\"\n",
    "            f\"먼저 alpha-lambda 요약 스크립트를 실행해 summary CSV를 생성하세요.\"\n",
    "        )\n",
    "\n",
    "    df = pd.read_csv(summary_csv)\n",
    "\n",
    "    lam_strs = infer_lam_strs_from_summary(df)\n",
    "    lam = [float(x) for x in lam_strs]\n",
    "\n",
    "    plt.figure()\n",
    "    for split in SPLITS_ORDER:\n",
    "        sub = df[df[\"split\"] == split]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        row = sub.iloc[0]\n",
    "        rates = [float(row.get(f\"rate_{ls}\", np.nan)) for ls in lam_strs]\n",
    "        plt.plot(lam, rates, marker=\"o\", label=split)\n",
    "\n",
    "    plt.xticks(lam, [f\"{x:.2f}\" for x in lam])\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.xlabel(\"λ (life fraction)\")\n",
    "    plt.ylabel(\"α–λ success rate\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_png), exist_ok=True)\n",
    "    plt.savefig(out_png, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"[SAVE] {out_png}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(SUMMARY_ACROSS):\n",
    "        raise FileNotFoundError(f\"Not found: {SUMMARY_ACROSS}\")\n",
    "\n",
    "    df = pd.read_csv(SUMMARY_ACROSS)\n",
    "\n",
    "    # best by val / best by test 선택\n",
    "    best_val = pick_best_row(df, metric_prefix=\"val\")\n",
    "    best_test = pick_best_row(df, metric_prefix=\"test\")\n",
    "\n",
    "    best_val_seed = int(best_val[\"seed\"])\n",
    "    best_val_ckpt = str(best_val[\"checkpoint\"])\n",
    "    best_test_seed = int(best_test[\"seed\"])\n",
    "    best_test_ckpt = str(best_test[\"checkpoint\"])\n",
    "\n",
    "    # 내가 이전에 준 alpha-lambda 요약 스크립트 저장 규칙에 맞춘 입력 경로\n",
    "    sum_val = os.path.join(\n",
    "        TRIAL_DIR, \"alpha_lambda_eval\", \"selected_by_val\",\n",
    "        f\"seed_{best_val_seed}\", best_val_ckpt,\n",
    "        f\"alpha_lambda_summary__selected_by_val__seed{best_val_seed}_{best_val_ckpt}.csv\"\n",
    "    )\n",
    "    sum_test = os.path.join(\n",
    "        TRIAL_DIR, \"alpha_lambda_eval\", \"selected_by_test\",\n",
    "        f\"seed_{best_test_seed}\", best_test_ckpt,\n",
    "        f\"alpha_lambda_summary__selected_by_test__seed{best_test_seed}_{best_test_ckpt}.csv\"\n",
    "    )\n",
    "\n",
    "    out_val = os.path.join(\n",
    "        TRIAL_DIR, \"alpha_lambda_eval\", \"selected_by_val\",\n",
    "        f\"seed_{best_val_seed}\", best_val_ckpt,\n",
    "        f\"alpha_lambda_curve__selected_by_val__seed{best_val_seed}_{best_val_ckpt}.png\"\n",
    "    )\n",
    "    out_test = os.path.join(\n",
    "        TRIAL_DIR, \"alpha_lambda_eval\", \"selected_by_test\",\n",
    "        f\"seed_{best_test_seed}\", best_test_ckpt,\n",
    "        f\"alpha_lambda_curve__selected_by_test__seed{best_test_seed}_{best_test_ckpt}.png\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Using selections from Trial16 summary ===\")\n",
    "    print(f\"[BEST BY VAL]  seed={best_val_seed}, ckpt={best_val_ckpt}\")\n",
    "    print(f\"[BEST BY TEST] seed={best_test_seed}, ckpt={best_test_ckpt}\")\n",
    "\n",
    "    plot_one(\n",
    "        summary_csv=sum_val,\n",
    "        out_png=out_val,\n",
    "        title=f\"Trial16 α–λ curve | selected_by_val | seed={best_val_seed} | ckpt={best_val_ckpt}\"\n",
    "    )\n",
    "    plot_one(\n",
    "        summary_csv=sum_test,\n",
    "        out_png=out_test,\n",
    "        title=f\"Trial16 α–λ curve | selected_by_test | seed={best_test_seed} | ckpt={best_test_ckpt}\"\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f14060ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Using selections from Trial16 summary ===\n",
      "[BEST BY VAL]  seed=222, ckpt=best_by_val_norm\n",
      "[BEST BY TEST] seed=333, ckpt=best_by_val_norm\n",
      "[Trial16 | selected_by_val | SEED 222 | BEST_BY_VAL_NORM] [train] DONE -> ./Trial16\\alpha_lambda_eval\\selected_by_val\\seed_222\\best_by_val_norm\\paper_figures_bookstyle\\train\n",
      "[Trial16 | selected_by_val | SEED 222 | BEST_BY_VAL_NORM] [val] DONE -> ./Trial16\\alpha_lambda_eval\\selected_by_val\\seed_222\\best_by_val_norm\\paper_figures_bookstyle\\val\n",
      "[Trial16 | selected_by_val | SEED 222 | BEST_BY_VAL_NORM] [test] DONE -> ./Trial16\\alpha_lambda_eval\\selected_by_val\\seed_222\\best_by_val_norm\\paper_figures_bookstyle\\test\n",
      "\n",
      "[selected_by_val] ALL DONE. Saved under:\n",
      "  ./Trial16\\alpha_lambda_eval\\selected_by_val\\seed_222\\best_by_val_norm\\paper_figures_bookstyle\n",
      "\n",
      "[Trial16 | selected_by_test | SEED 333 | BEST_BY_VAL_NORM] [train] DONE -> ./Trial16\\alpha_lambda_eval\\selected_by_test\\seed_333\\best_by_val_norm\\paper_figures_bookstyle\\train\n",
      "[Trial16 | selected_by_test | SEED 333 | BEST_BY_VAL_NORM] [val] DONE -> ./Trial16\\alpha_lambda_eval\\selected_by_test\\seed_333\\best_by_val_norm\\paper_figures_bookstyle\\val\n",
      "[Trial16 | selected_by_test | SEED 333 | BEST_BY_VAL_NORM] [test] DONE -> ./Trial16\\alpha_lambda_eval\\selected_by_test\\seed_333\\best_by_val_norm\\paper_figures_bookstyle\\test\n",
      "\n",
      "[selected_by_test] ALL DONE. Saved under:\n",
      "  ./Trial16\\alpha_lambda_eval\\selected_by_test\\seed_333\\best_by_val_norm\\paper_figures_bookstyle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# USER CONFIG (Trial16)\n",
    "# =========================\n",
    "TRIAL_DIR = r\"./Trial16\"\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "ALPHA = 0.20\n",
    "LAMBDA_TO_PLOT = 0.60\n",
    "MAX_FILES = None  # None=all, or e.g., 10\n",
    "\n",
    "SUMMARY_ACROSS = os.path.join(TRIAL_DIR, \"summary_across_seeds.csv\")\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def safe_name(s: str) -> str:\n",
    "    return s.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "\n",
    "def _require_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "\n",
    "def pick_best_row(df: pd.DataFrame, metric_prefix: str = \"val\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    metric_prefix: \"val\" or \"test\"\n",
    "    Sort rule:\n",
    "      1) <prefix>_rmse_cycles ascending\n",
    "      2) <prefix>_mae_cycles  ascending\n",
    "    \"\"\"\n",
    "    rmse_col = f\"{metric_prefix}_rmse_cycles\"\n",
    "    mae_col = f\"{metric_prefix}_mae_cycles\"\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", rmse_col, mae_col])\n",
    "\n",
    "    df_sorted = df.sort_values(\n",
    "        by=[rmse_col, mae_col],\n",
    "        ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return df_sorted.iloc[0]\n",
    "\n",
    "\n",
    "def load_cycle_seq_and_metrics(seed_ckpt_dir: str, split: str):\n",
    "    \"\"\"\n",
    "    Trial16 export_ckpt()가 만들어 둔 파일들:\n",
    "      - <split>_cycle_sequence_mean.csv\n",
    "      - <split>_prognostics_metrics_per_file.csv\n",
    "    위치:\n",
    "      <TRIAL_DIR>/seed_<seed>/<ckpt>/\n",
    "    \"\"\"\n",
    "    seq_csv = os.path.join(seed_ckpt_dir, f\"{split}_cycle_sequence_mean.csv\")\n",
    "    met_csv = os.path.join(seed_ckpt_dir, f\"{split}_prognostics_metrics_per_file.csv\")\n",
    "\n",
    "    if not os.path.exists(seq_csv):\n",
    "        raise FileNotFoundError(f\"Missing: {seq_csv}\")\n",
    "    if not os.path.exists(met_csv):\n",
    "        raise FileNotFoundError(f\"Missing: {met_csv}\")\n",
    "\n",
    "    df_seq = pd.read_csv(seq_csv)\n",
    "    df_met = pd.read_csv(met_csv)\n",
    "    return df_seq, df_met\n",
    "\n",
    "\n",
    "def get_eval_segment(df_one_file: pd.DataFrame, t_s: int, t_e: int) -> pd.DataFrame:\n",
    "    df = df_one_file.sort_values(\"cycle\").copy()\n",
    "    df = df[(df[\"cycle\"] >= t_s) & (df[\"cycle\"] <= t_e)].copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Plotters\n",
    "# =========================\n",
    "def plot_ph_alpha_absolute_band(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    alpha: float,\n",
    "    out_path: str,\n",
    "    ph_start: Optional[float] = None,\n",
    "    title_prefix: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    BOOK Fig.2.9(a) 스타일: PH용 α-zone은 '절대 폭(평행 밴드)'\n",
    "      alphaZone = alpha * EOL_true\n",
    "      zone = RUL_true ± alphaZone\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].to_numpy()\n",
    "    y_true = df_eval[\"RUL_true\"].to_numpy()\n",
    "    y_pred = df_eval[\"RUL_pred\"].to_numpy()\n",
    "\n",
    "    last_cycle = int(df_eval[\"cycle\"].max())\n",
    "    eol_true = last_cycle + 1\n",
    "\n",
    "    alpha_zone = alpha * float(eol_true)\n",
    "    upper = y_true + alpha_zone\n",
    "    lower = y_true - alpha_zone\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, \"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, \"r\", label=\"Prediction (cycles)\")\n",
    "    plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α-zone (±α·EOL)\")\n",
    "    plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α-zone (±α·EOL)\")\n",
    "\n",
    "    if ph_start is not None and np.isfinite(ph_start):\n",
    "        plt.axvline(int(ph_start), color=\"g\", linestyle=\"-.\", label=\"PH start\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title_prefix} | BOOK-STYLE α+PH (absolute band)\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_alpha_lambda_relative_band(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    t_lambda: Optional[int],\n",
    "    out_path: str,\n",
    "    title_prefix: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    BOOK Fig.2.9(b) 스타일: α–λ는 '상대 폭(수렴 밴드)'\n",
    "      zone = RUL_true*(1±alpha), 그리고 t >= t_lambda 구간만 표시\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].to_numpy()\n",
    "    y_true = df_eval[\"RUL_true\"].to_numpy()\n",
    "    y_pred = df_eval[\"RUL_pred\"].to_numpy()\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, \"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, \"r\", label=\"Prediction (cycles)\")\n",
    "\n",
    "    if t_lambda is not None and np.isfinite(t_lambda):\n",
    "        t_lambda = int(t_lambda)\n",
    "        plt.axvline(t_lambda, color=\"g\", linestyle=\":\", label=f\"t_λ (λ={lambda_to_plot:.2f})\")\n",
    "\n",
    "        mask = x >= t_lambda\n",
    "        if np.any(mask):\n",
    "            plt.plot(x[mask], upper[mask], \"b--\", label=f\"+{alpha:.2f} α–λ zone\")\n",
    "            plt.plot(x[mask], lower[mask], \"b--\", label=f\"-{alpha:.2f} α–λ zone\")\n",
    "        else:\n",
    "            plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α zone\")\n",
    "            plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α zone\")\n",
    "    else:\n",
    "        plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α zone\")\n",
    "        plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α zone\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title_prefix} | BOOK-STYLE α–λ (relative band)\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Main runner\n",
    "# =========================\n",
    "def run_for_one_split(seed_ckpt_dir: str, out_root: str, split: str, seed: int, ckpt: str, title_prefix: str):\n",
    "    df_seq, df_met = load_cycle_seq_and_metrics(seed_ckpt_dir, split)\n",
    "\n",
    "    files = df_seq[\"file\"].unique().tolist()\n",
    "    if MAX_FILES is not None:\n",
    "        files = files[:MAX_FILES]\n",
    "\n",
    "    out_dir = os.path.join(out_root, split)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    lam_key = f\"t_lambda_{LAMBDA_TO_PLOT:.2f}\"\n",
    "\n",
    "    for f in files:\n",
    "        sub = df_seq[df_seq[\"file\"] == f].copy()\n",
    "        mrow = df_met[df_met[\"file\"] == f]\n",
    "        if mrow.empty:\n",
    "            continue\n",
    "        mrow = mrow.iloc[0].to_dict()\n",
    "\n",
    "        t_s = int(mrow[\"t_s\"])\n",
    "        t_e = int(mrow[\"t_e\"])\n",
    "\n",
    "        ph_start = mrow.get(\"t_PH_start\", np.nan)\n",
    "        t_lambda = mrow.get(lam_key, np.nan)\n",
    "\n",
    "        df_eval = get_eval_segment(sub, t_s, t_e)\n",
    "        if df_eval.empty:\n",
    "            continue\n",
    "\n",
    "        sname = safe_name(f)\n",
    "\n",
    "        out_a = os.path.join(out_dir, f\"FIG_A_BOOKSTYLE_alpha_PH__{sname}.png\")\n",
    "        plot_ph_alpha_absolute_band(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            alpha=ALPHA,\n",
    "            out_path=out_a,\n",
    "            ph_start=ph_start if np.isfinite(ph_start) else None,\n",
    "            title_prefix=title_prefix,\n",
    "        )\n",
    "\n",
    "        out_b = os.path.join(out_dir, f\"FIG_B_BOOKSTYLE_alpha_lambda__lam{LAMBDA_TO_PLOT:.2f}__{sname}.png\")\n",
    "        plot_alpha_lambda_relative_band(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            alpha=ALPHA,\n",
    "            lambda_to_plot=LAMBDA_TO_PLOT,\n",
    "            t_lambda=int(t_lambda) if np.isfinite(t_lambda) else None,\n",
    "            out_path=out_b,\n",
    "            title_prefix=title_prefix,\n",
    "        )\n",
    "\n",
    "    print(f\"[{title_prefix}] [{split}] DONE -> {out_dir}\")\n",
    "\n",
    "\n",
    "def run_selection(selection_name: str, seed: int, ckpt: str):\n",
    "    seed_ckpt_dir = os.path.join(TRIAL_DIR, f\"seed_{seed}\", ckpt)\n",
    "    if not os.path.isdir(seed_ckpt_dir):\n",
    "        raise FileNotFoundError(f\"Not found: {seed_ckpt_dir}\")\n",
    "\n",
    "    # ✅ 결과 저장: Trial16 루트 아래 selection별로 분리\n",
    "    out_root = os.path.join(\n",
    "        TRIAL_DIR, \"alpha_lambda_eval\", selection_name,\n",
    "        f\"seed_{seed}\", ckpt,\n",
    "        \"paper_figures_bookstyle\"\n",
    "    )\n",
    "    os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "    title_prefix = f\"Trial16 | {selection_name} | SEED {seed} | {ckpt.upper()}\"\n",
    "\n",
    "    for split in SPLITS:\n",
    "        run_for_one_split(seed_ckpt_dir, out_root, split, seed, ckpt, title_prefix)\n",
    "\n",
    "    print(f\"\\n[{selection_name}] ALL DONE. Saved under:\\n  {out_root}\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(SUMMARY_ACROSS):\n",
    "        raise FileNotFoundError(f\"Not found: {SUMMARY_ACROSS}\")\n",
    "\n",
    "    df = pd.read_csv(SUMMARY_ACROSS)\n",
    "\n",
    "    best_val = pick_best_row(df, metric_prefix=\"val\")\n",
    "    best_test = pick_best_row(df, metric_prefix=\"test\")\n",
    "\n",
    "    best_val_seed = int(best_val[\"seed\"])\n",
    "    best_val_ckpt = str(best_val[\"checkpoint\"])\n",
    "    best_test_seed = int(best_test[\"seed\"])\n",
    "    best_test_ckpt = str(best_test[\"checkpoint\"])\n",
    "\n",
    "    print(\"\\n=== Using selections from Trial16 summary ===\")\n",
    "    print(f\"[BEST BY VAL]  seed={best_val_seed}, ckpt={best_val_ckpt}\")\n",
    "    print(f\"[BEST BY TEST] seed={best_test_seed}, ckpt={best_test_ckpt}\")\n",
    "\n",
    "    run_selection(\"selected_by_val\", best_val_seed, best_val_ckpt)\n",
    "    run_selection(\"selected_by_test\", best_test_seed, best_test_ckpt)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igbt_rnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
