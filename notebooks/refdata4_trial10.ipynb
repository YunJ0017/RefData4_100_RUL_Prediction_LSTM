{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b545ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "[SEED 9819123] device=cuda\n",
      "[SEED 9819123] out=./Trial10\\seed_9819123\n",
      "==============================\n",
      "[SEED 9819123] [001/300] train_mse_cycles=16499510.012 | val_rmse_cycles=3258.582 | val_mae_cycles=2460.728 | best_val_rmse_cycles=3258.582\n",
      "[SEED 9819123] [010/300] train_mse_cycles=8482323.869 | val_rmse_cycles=3441.634 | val_mae_cycles=2502.035 | best_val_rmse_cycles=3258.582\n",
      "[SEED 9819123] [020/300] train_mse_cycles=7699644.131 | val_rmse_cycles=3647.394 | val_mae_cycles=2671.424 | best_val_rmse_cycles=3258.582\n",
      "[SEED 9819123] [030/300] train_mse_cycles=7551903.887 | val_rmse_cycles=3558.172 | val_mae_cycles=2556.499 | best_val_rmse_cycles=3258.582\n",
      "[SEED 9819123] Early stopping at epoch 31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_27596\\589525297.py:802: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 9819123] best_by_val_cycles: VAL rmse_cycles=3258.582, mae_cycles=2460.728 | TEST rmse_cycles=1459.439, mae_cycles=1008.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_27596\\589525297.py:802: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 9819123] last_epoch: VAL rmse_cycles=3539.435, mae_cycles=2516.330 | TEST rmse_cycles=1566.945, mae_cycles=1182.038\n",
      "\n",
      "==============================\n",
      "[SEED 111] device=cuda\n",
      "[SEED 111] out=./Trial10\\seed_111\n",
      "==============================\n",
      "[SEED 111] [001/300] train_mse_cycles=9483841.394 | val_rmse_cycles=3876.673 | val_mae_cycles=2598.139 | best_val_rmse_cycles=3876.673\n",
      "[SEED 111] [010/300] train_mse_cycles=5211259.528 | val_rmse_cycles=4298.958 | val_mae_cycles=2859.311 | best_val_rmse_cycles=3743.676\n",
      "[SEED 111] [020/300] train_mse_cycles=4989230.564 | val_rmse_cycles=4269.335 | val_mae_cycles=2889.262 | best_val_rmse_cycles=3743.676\n",
      "[SEED 111] [030/300] train_mse_cycles=5021417.676 | val_rmse_cycles=4096.406 | val_mae_cycles=2689.691 | best_val_rmse_cycles=3743.676\n",
      "[SEED 111] Early stopping at epoch 34.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_27596\\589525297.py:802: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 111] best_by_val_cycles: VAL rmse_cycles=3743.676, mae_cycles=2551.323 | TEST rmse_cycles=3874.380, mae_cycles=2384.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_27596\\589525297.py:802: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 111] last_epoch: VAL rmse_cycles=4046.967, mae_cycles=2680.071 | TEST rmse_cycles=4170.247, mae_cycles=2639.883\n",
      "\n",
      "==============================\n",
      "[SEED 222] device=cuda\n",
      "[SEED 222] out=./Trial10\\seed_222\n",
      "==============================\n",
      "[SEED 222] [001/300] train_mse_cycles=15029475.411 | val_rmse_cycles=2554.058 | val_mae_cycles=1736.581 | best_val_rmse_cycles=2554.058\n",
      "[SEED 222] [010/300] train_mse_cycles=9106493.051 | val_rmse_cycles=2689.238 | val_mae_cycles=1800.335 | best_val_rmse_cycles=2554.058\n",
      "[SEED 222] [020/300] train_mse_cycles=8413686.007 | val_rmse_cycles=2871.692 | val_mae_cycles=1872.866 | best_val_rmse_cycles=2554.058\n",
      "[SEED 222] [030/300] train_mse_cycles=8033708.257 | val_rmse_cycles=2764.958 | val_mae_cycles=1828.675 | best_val_rmse_cycles=2554.058\n",
      "[SEED 222] Early stopping at epoch 31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_27596\\589525297.py:802: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 222] best_by_val_cycles: VAL rmse_cycles=2554.058, mae_cycles=1736.581 | TEST rmse_cycles=2786.477, mae_cycles=2038.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_27596\\589525297.py:802: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 222] last_epoch: VAL rmse_cycles=2861.529, mae_cycles=1867.148 | TEST rmse_cycles=2657.542, mae_cycles=1861.311\n",
      "\n",
      "==============================\n",
      "[SEED 333] device=cuda\n",
      "[SEED 333] out=./Trial10\\seed_333\n",
      "==============================\n",
      "[SEED 333] [001/300] train_mse_cycles=18019210.986 | val_rmse_cycles=2640.649 | val_mae_cycles=1694.635 | best_val_rmse_cycles=2640.649\n",
      "[SEED 333] [010/300] train_mse_cycles=9562335.314 | val_rmse_cycles=2511.377 | val_mae_cycles=1588.676 | best_val_rmse_cycles=2347.371\n",
      "[SEED 333] [020/300] train_mse_cycles=9323486.851 | val_rmse_cycles=2599.333 | val_mae_cycles=1645.777 | best_val_rmse_cycles=2347.371\n",
      "[SEED 333] [030/300] train_mse_cycles=8676597.273 | val_rmse_cycles=2508.528 | val_mae_cycles=1585.164 | best_val_rmse_cycles=2347.371\n",
      "[SEED 333] Early stopping at epoch 37.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_27596\\589525297.py:802: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 333] best_by_val_cycles: VAL rmse_cycles=2347.371, mae_cycles=1632.633 | TEST rmse_cycles=2004.070, mae_cycles=1216.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_27596\\589525297.py:802: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 333] last_epoch: VAL rmse_cycles=2638.429, mae_cycles=1643.542 | TEST rmse_cycles=1893.009, mae_cycles=1204.365\n",
      "\n",
      "==============================\n",
      "[SEED 444] device=cuda\n",
      "[SEED 444] out=./Trial10\\seed_444\n",
      "==============================\n",
      "[SEED 444] [001/300] train_mse_cycles=15177572.981 | val_rmse_cycles=3725.851 | val_mae_cycles=2304.475 | best_val_rmse_cycles=3725.851\n",
      "[SEED 444] [010/300] train_mse_cycles=7794124.258 | val_rmse_cycles=3626.944 | val_mae_cycles=2220.957 | best_val_rmse_cycles=3259.786\n",
      "[SEED 444] [020/300] train_mse_cycles=7536496.483 | val_rmse_cycles=3638.598 | val_mae_cycles=2239.991 | best_val_rmse_cycles=3259.786\n",
      "[SEED 444] [030/300] train_mse_cycles=7310556.611 | val_rmse_cycles=3775.500 | val_mae_cycles=2248.640 | best_val_rmse_cycles=3259.786\n",
      "[SEED 444] Early stopping at epoch 35.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_27596\\589525297.py:802: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 444] best_by_val_cycles: VAL rmse_cycles=3259.786, mae_cycles=2041.304 | TEST rmse_cycles=2216.925, mae_cycles=1596.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_27596\\589525297.py:802: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 444] last_epoch: VAL rmse_cycles=3841.992, mae_cycles=2368.089 | TEST rmse_cycles=1839.701, mae_cycles=1282.910\n",
      "=== WIN-RATE SUMMARY (TEST; lower is better) ===\n",
      "- test_mae_cycles: last wins=3, best wins=2, ties=0 | mean(last-best)=-14.826915, std(last-best)=211.471600\n",
      "- test_rmse_cycles: last wins=3, best wins=2, ties=0 | mean(last-best)=-42.769173, std(last-best)=228.563176\n",
      "- test_mae_norm: last wins=2, best wins=3, ties=0 | mean(last-best)=0.000096, std(last-best)=0.010943\n",
      "- test_rmse_norm: last wins=2, best wins=3, ties=0 | mean(last-best)=-0.002885, std(last-best)=0.010459\n",
      "\n",
      "=== MEAN ± STD across seeds (TEST) ===\n",
      "                   test_mae_cycles             test_rmse_cycles               \\\n",
      "                              mean         std             mean          std   \n",
      "checkpoint                                                                     \n",
      "best_by_val_cycles     1648.928234  568.433941      2468.258280   918.530775   \n",
      "last_epoch             1634.101319  627.612502      2425.489107  1056.149858   \n",
      "\n",
      "                   test_mae_norm           test_rmse_norm            \n",
      "                            mean       std           mean       std  \n",
      "checkpoint                                                           \n",
      "best_by_val_cycles      0.129610  0.026261       0.168582  0.030872  \n",
      "last_epoch              0.129706  0.028837       0.165697  0.036489  \n",
      "\n",
      "Saved:\n",
      " - ./Trial10\\summary_across_seeds.csv\n",
      " - ./Trial10\\win_rate_summary.csv\n",
      " - ./Trial10\\win_rate_summary.txt\n",
      "\n",
      "DONE. Check Trial10 folder:\n",
      " - per seed results: Trial10/seed_<seed>/...\n",
      " - paper figures: seed_<seed>/<ckpt>/paper_figures/<split>/\n",
      " - cycle seq mean: <ckpt>/<split>_cycle_sequence_mean.csv\n",
      " - PH/α–λ metrics: <ckpt>/<split>_prognostics_metrics_per_file.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Trial10: Trial8(training) + Trial9(evaluation metrics/figures)\n",
    "# - Training: cycle-scale loss (pred_norm*rul0 vs y_cycles)\n",
    "# - Best checkpoint: best_by_val_cycles (selected by val_rmse_cycles)\n",
    "# - Added from Trial9 (EVAL ONLY):\n",
    "#     * windows -> cycle sequence (mean representative)\n",
    "#     * Prognostics metrics: rel_err / RA / CRA / PH / α–λ / convergence\n",
    "#     * Paper-style figures:\n",
    "#         1) alpha + PH\n",
    "#         2) alpha–lambda (single lambda)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0) Reproducibility\n",
    "# ============================================================\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Config (Trial10)\n",
    "# ============================================================\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_dir: str = r\"C:\\Users\\11HOME_AHCI\\Desktop\\PoF\\Winter 2026\\Ref Data4\\100\"\n",
    "    out_dir: str = r\"./Trial10\"\n",
    "\n",
    "    # seeds to sweep\n",
    "    seeds: Tuple[int, ...] = (9819123, 111, 222, 333, 444, 555, 666, 777, 888, 999)\n",
    "\n",
    "    # sliding window\n",
    "    seq_len: int = 100\n",
    "    stride: int = 5\n",
    "    pred_horizon: int = 0\n",
    "\n",
    "    # split by FILE\n",
    "    train_ratio: float = 0.7\n",
    "    val_ratio: float = 0.2\n",
    "    test_ratio: float = 0.1\n",
    "\n",
    "    # training\n",
    "    batch_size: int = 512\n",
    "    epochs: int = 300\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 0.0\n",
    "    patience: int = 30\n",
    "    grad_clip: float = 1.0\n",
    "\n",
    "    # model\n",
    "    hidden_size: int = 512\n",
    "    num_layers: int = 2\n",
    "    dropout: float = 0.2\n",
    "\n",
    "    # output controls\n",
    "    save_figures: bool = True\n",
    "    max_files_to_plot: Optional[int] = None  # None=all\n",
    "    num_workers: int = 0\n",
    "\n",
    "    # ===========================\n",
    "    # Trial10: Evaluation settings (from Trial9)\n",
    "    # ===========================\n",
    "    alpha: float = 0.20                # relative error bound\n",
    "    ph_consecutive_m: int = 5          # PH: need M consecutive points within alpha\n",
    "    rep_method: str = \"mean\"           # cycle representative (fixed: mean)\n",
    "    lambdas: Tuple[float, ...] = (0.2, 0.4, 0.6, 0.8)  # λ grid\n",
    "    lambda_to_plot: float = 0.6        # for paper-style α–λ figure\n",
    "    eps_rul: float = 1e-8              # numeric stability\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Data utils\n",
    "# ============================================================\n",
    "def list_csv_files(data_dir: str) -> List[Path]:\n",
    "    p = Path(data_dir)\n",
    "    files = sorted([f for f in p.glob(\"*.csv\") if f.is_file()])\n",
    "    if len(files) == 0:\n",
    "        raise FileNotFoundError(f\"No CSV files found in: {data_dir}\")\n",
    "    return files\n",
    "\n",
    "\n",
    "def read_one_csv(csv_path: Path) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    df = pd.read_csv(csv_path, header=None)\n",
    "    if df.shape[1] < 2:\n",
    "        raise ValueError(f\"{csv_path.name}: expected at least 2 columns, got {df.shape[1]}\")\n",
    "\n",
    "    vce = df.iloc[:, 0].astype(np.float32).to_numpy()\n",
    "    rul = df.iloc[:, 1].astype(np.float32).to_numpy()\n",
    "\n",
    "    if len(vce) != len(rul):\n",
    "        raise ValueError(f\"{csv_path.name}: length mismatch vce={len(vce)}, rul={len(rul)}\")\n",
    "    if len(vce) < 5:\n",
    "        raise ValueError(f\"{csv_path.name}: too short sequence length={len(vce)}\")\n",
    "\n",
    "    return vce, rul\n",
    "\n",
    "\n",
    "def split_files(\n",
    "    files: List[Path],\n",
    "    train_ratio: float,\n",
    "    val_ratio: float,\n",
    "    test_ratio: float,\n",
    "    seed: int\n",
    ") -> Dict[str, List[Path]]:\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-9\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "    files_shuffled = files[:]\n",
    "    rng.shuffle(files_shuffled)\n",
    "\n",
    "    n = len(files_shuffled)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "\n",
    "    train_files = files_shuffled[:n_train]\n",
    "    val_files = files_shuffled[n_train:n_train + n_val]\n",
    "    test_files = files_shuffled[n_train + n_val:]\n",
    "\n",
    "    return {\"train\": train_files, \"val\": val_files, \"test\": test_files}\n",
    "\n",
    "\n",
    "def compute_dvce(vce: np.ndarray) -> np.ndarray:\n",
    "    dv = np.zeros_like(vce, dtype=np.float32)\n",
    "    dv[1:] = vce[1:] - vce[:-1]\n",
    "    return dv\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Dataset\n",
    "# ============================================================\n",
    "class WindowedRULDatasetNorm2F(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_list: List[Path],\n",
    "        seq_len: int,\n",
    "        stride: int,\n",
    "        pred_horizon: int,\n",
    "        scaler_x: StandardScaler = None,\n",
    "        fit_scaler: bool = False,\n",
    "    ):\n",
    "        self.file_list = file_list\n",
    "        self.seq_len = seq_len\n",
    "        self.stride = stride\n",
    "        self.pred_horizon = pred_horizon\n",
    "        self.scaler_x = scaler_x if scaler_x is not None else StandardScaler()\n",
    "\n",
    "        # store: (name, X2(T,2), rul(T,), rul0)\n",
    "        self.series: List[Tuple[str, np.ndarray, np.ndarray, float]] = []\n",
    "        for fp in self.file_list:\n",
    "            vce, rul = read_one_csv(fp)\n",
    "            rul0 = float(rul[0])\n",
    "            if rul0 <= 0:\n",
    "                raise ValueError(f\"{fp.name}: RUL0 must be > 0, got {rul0}\")\n",
    "\n",
    "            dv = compute_dvce(vce)\n",
    "            x2 = np.stack([vce, dv], axis=1).astype(np.float32)  # (T,2)\n",
    "            self.series.append((fp.name, x2, rul.astype(np.float32), rul0))\n",
    "\n",
    "        if fit_scaler:\n",
    "            all_x = np.concatenate([x2 for _, x2, _, _ in self.series], axis=0)\n",
    "            self.scaler_x.fit(all_x)\n",
    "\n",
    "        # window index\n",
    "        self.index: List[Tuple[int, int]] = []\n",
    "        for fi, (_name, x2, _rul, _rul0) in enumerate(self.series):\n",
    "            T = x2.shape[0]\n",
    "            last_start = T - (seq_len + pred_horizon)\n",
    "            if last_start < 0:\n",
    "                continue\n",
    "            for s in range(0, last_start + 1, stride):\n",
    "                self.index.append((fi, s))\n",
    "\n",
    "        if len(self.index) == 0:\n",
    "            raise ValueError(\"No windows were created. Check seq_len/pred_horizon vs file lengths.\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        fi, s = self.index[idx]\n",
    "        name, x2, rul, rul0 = self.series[fi]\n",
    "\n",
    "        x = x2[s:s + self.seq_len, :]\n",
    "        y_idx = s + self.seq_len - 1 + self.pred_horizon\n",
    "        y_cycles = float(rul[y_idx])\n",
    "        y_norm = np.array([y_cycles / rul0], dtype=np.float32)\n",
    "\n",
    "        x = self.scaler_x.transform(x).astype(np.float32)\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x),\n",
    "            torch.from_numpy(y_norm),\n",
    "            name,\n",
    "            torch.tensor(s, dtype=torch.long),\n",
    "            torch.tensor(y_cycles, dtype=torch.float32),\n",
    "            torch.tensor(rul0, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Model\n",
    "# ============================================================\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 2, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last = out[:, -1, :]\n",
    "        return self.head(last)  # (B,1) norm-scale\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Basic eval + Save window-level predictions\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def evaluate_basic(model, loader, device) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "\n",
    "    mae_norm_list, mse_norm_list = [], []\n",
    "    mae_cyc_list, mse_cyc_list = [], []\n",
    "\n",
    "    for x, y_norm, _name, _s, y_cycles, rul0 in loader:\n",
    "        x = x.to(device)\n",
    "        y_norm = y_norm.to(device)\n",
    "        y_cycles = y_cycles.to(device).view(-1, 1)\n",
    "        rul0 = rul0.to(device).view(-1, 1)\n",
    "\n",
    "        pred_norm = model(x)\n",
    "\n",
    "        # norm metrics\n",
    "        err_norm = pred_norm - y_norm\n",
    "        mae_norm_list.append(torch.mean(torch.abs(err_norm)).item())\n",
    "        mse_norm_list.append(torch.mean(err_norm ** 2).item())\n",
    "\n",
    "        # cycle metrics\n",
    "        pred_cycles = pred_norm * rul0\n",
    "        err_cyc = pred_cycles - y_cycles\n",
    "        mae_cyc_list.append(torch.mean(torch.abs(err_cyc)).item())\n",
    "        mse_cyc_list.append(torch.mean(err_cyc ** 2).item())\n",
    "\n",
    "    return {\n",
    "        \"mae_norm\": float(np.mean(mae_norm_list)) if mae_norm_list else float(\"nan\"),\n",
    "        \"rmse_norm\": float(np.sqrt(np.mean(mse_norm_list))) if mse_norm_list else float(\"nan\"),\n",
    "        \"mae_cycles\": float(np.mean(mae_cyc_list)) if mae_cyc_list else float(\"nan\"),\n",
    "        \"rmse_cycles\": float(np.sqrt(np.mean(mse_cyc_list))) if mse_cyc_list else float(\"nan\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_predictions_windows_csv(model, loader, device, out_csv: str, seq_len: int) -> None:\n",
    "    \"\"\"\n",
    "    window-level 상세 CSV:\n",
    "    file, start_idx, cycle(=target index), RUL_true, RUL_pred, rul0, norm-scale도 같이 저장\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    for x, y_norm, name, s, y_cycles, rul0 in loader:\n",
    "        x = x.to(device)\n",
    "        y_norm = y_norm.to(device)\n",
    "        y_cycles = y_cycles.to(device).view(-1, 1)\n",
    "        rul0 = rul0.to(device).view(-1, 1)\n",
    "\n",
    "        pred_norm = model(x)\n",
    "        pred_cycles = pred_norm * rul0\n",
    "\n",
    "        pred_norm_np = pred_norm.cpu().numpy().reshape(-1)\n",
    "        y_norm_np = y_norm.cpu().numpy().reshape(-1)\n",
    "        pred_cyc_np = pred_cycles.cpu().numpy().reshape(-1)\n",
    "        y_cyc_np = y_cycles.cpu().numpy().reshape(-1)\n",
    "\n",
    "        rul0_np = rul0.cpu().numpy().reshape(-1)\n",
    "        s_np = s.cpu().numpy().reshape(-1)\n",
    "        name_list = list(name)\n",
    "\n",
    "        for i in range(len(pred_norm_np)):\n",
    "            rows.append({\n",
    "                \"file\": name_list[i],\n",
    "                \"start_idx\": int(s_np[i]),\n",
    "                \"cycle\": int(s_np[i] + (seq_len - 1)),\n",
    "                \"rul0\": float(rul0_np[i]),\n",
    "                \"RUL_true\": float(y_cyc_np[i]),\n",
    "                \"RUL_pred\": float(pred_cyc_np[i]),\n",
    "                \"RUL_true_norm\": float(y_norm_np[i]),\n",
    "                \"RUL_pred_norm\": float(pred_norm_np[i]),\n",
    "            })\n",
    "\n",
    "    pd.DataFrame(rows).to_csv(out_csv, index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Window -> Cycle sequence (mean representative)  [ADDED]\n",
    "# ============================================================\n",
    "def windows_to_cycle_sequence_mean(windows_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    동일 (file, cycle)에 여러 window 예측이 있을 수 있으므로,\n",
    "    cycle 단위 mean 대표값 생성.\n",
    "    결과: file, cycle, RUL_true, RUL_pred, rul0\n",
    "    \"\"\"\n",
    "    dfw = pd.read_csv(windows_csv)\n",
    "    if dfw.empty:\n",
    "        raise ValueError(f\"Empty windows csv: {windows_csv}\")\n",
    "\n",
    "    g = dfw.groupby([\"file\", \"cycle\"], as_index=False).agg(\n",
    "        rul0=(\"rul0\", \"first\"),\n",
    "        RUL_true=(\"RUL_true\", \"mean\"),\n",
    "        RUL_pred=(\"RUL_pred\", \"mean\"),\n",
    "        n_windows=(\"RUL_pred\", \"count\"),\n",
    "    )\n",
    "    return g\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) Prognostics metrics (PH / α–λ / CRA / convergence) [ADDED]\n",
    "# ============================================================\n",
    "def compute_metrics_for_one_file(\n",
    "    df_seq_one_file: pd.DataFrame,\n",
    "    seq_len: int,\n",
    "    alpha: float,\n",
    "    ph_consecutive_m: int,\n",
    "    lambdas: Tuple[float, ...],\n",
    "    eps_rul: float,\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    df_seq_one_file columns: cycle, RUL_true, RUL_pred, rul0\n",
    "\n",
    "    - t_s = seq_len - 1\n",
    "    - t_e = last cycle index\n",
    "    - rel_err = |true - pred| / max(|true|, eps_rul)\n",
    "    - RA(t) = 1 - rel_err\n",
    "    - CRA = mean(RA(t)) over [t_s, t_e]\n",
    "    - PH start: first cycle where rel_err<=alpha holds for M consecutive points\n",
    "    - λ mapping: target RUL_true = (1-λ)*RUL0, t_λ = argmin |RUL_true - target|\n",
    "    - α–λ performance: rel_err(t_λ) <= alpha ? (0/1)\n",
    "    \"\"\"\n",
    "    df = df_seq_one_file.sort_values(\"cycle\").reset_index(drop=True).copy()\n",
    "\n",
    "    t_s = seq_len - 1\n",
    "    last_cycle = int(df[\"cycle\"].max())\n",
    "    EOL_true = last_cycle + 1\n",
    "    t_e = EOL_true - 1\n",
    "\n",
    "    df_eval = df[(df[\"cycle\"] >= t_s) & (df[\"cycle\"] <= t_e)].copy()\n",
    "    df_eval.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if df_eval.empty:\n",
    "        summary = {\n",
    "            \"t_s\": t_s, \"t_e\": t_e, \"EOL_true\": EOL_true,\n",
    "            \"PH\": np.nan, \"t_PH_start\": np.nan,\n",
    "            \"CRA\": np.nan, \"Convergence_cycles\": np.nan,\n",
    "        }\n",
    "        for lam in lambdas:\n",
    "            summary[f\"t_lambda_{lam:.2f}\"] = np.nan\n",
    "            summary[f\"alpha_lambda_ok_{lam:.2f}\"] = np.nan\n",
    "        return df_eval, summary\n",
    "\n",
    "    denom = np.maximum(np.abs(df_eval[\"RUL_true\"].values), eps_rul)\n",
    "    rel_err = np.abs(df_eval[\"RUL_true\"].values - df_eval[\"RUL_pred\"].values) / denom\n",
    "    RA = 1.0 - rel_err\n",
    "\n",
    "    df_eval[\"rel_err\"] = rel_err\n",
    "    df_eval[\"RA\"] = RA\n",
    "    df_eval[\"in_alpha\"] = df_eval[\"rel_err\"] <= alpha\n",
    "\n",
    "    CRA = float(np.mean(df_eval[\"RA\"].values))\n",
    "\n",
    "    # PH start: M consecutive in_alpha\n",
    "    flags = df_eval[\"in_alpha\"].values.astype(np.int32)\n",
    "    t_PH_start = np.nan\n",
    "    if len(flags) >= ph_consecutive_m:\n",
    "        run = 0\n",
    "        for i, ok in enumerate(flags):\n",
    "            if ok:\n",
    "                run += 1\n",
    "                if run >= ph_consecutive_m:\n",
    "                    start_i = i - ph_consecutive_m + 1\n",
    "                    t_PH_start = int(df_eval.loc[start_i, \"cycle\"])\n",
    "                    break\n",
    "            else:\n",
    "                run = 0\n",
    "\n",
    "    if np.isfinite(t_PH_start):\n",
    "        PH = float(EOL_true - t_PH_start)\n",
    "        Convergence_cycles = float(t_PH_start - t_s)\n",
    "    else:\n",
    "        PH = np.nan\n",
    "        Convergence_cycles = np.nan\n",
    "\n",
    "    # α–λ\n",
    "    rul0 = float(df_eval[\"rul0\"].iloc[0])\n",
    "    lam_results = {}\n",
    "    for lam in lambdas:\n",
    "        target_rul = (1.0 - float(lam)) * rul0\n",
    "        idx = int(np.argmin(np.abs(df_eval[\"RUL_true\"].values - target_rul)))\n",
    "        t_lam = int(df_eval.loc[idx, \"cycle\"])\n",
    "        ok = bool(df_eval.loc[idx, \"rel_err\"] <= alpha)\n",
    "\n",
    "        lam_results[f\"t_lambda_{lam:.2f}\"] = t_lam\n",
    "        lam_results[f\"alpha_lambda_ok_{lam:.2f}\"] = int(ok)\n",
    "\n",
    "    summary = {\n",
    "        \"t_s\": int(t_s),\n",
    "        \"t_e\": int(t_e),\n",
    "        \"EOL_true\": int(EOL_true),\n",
    "        \"alpha\": float(alpha),\n",
    "        \"ph_consecutive_m\": int(ph_consecutive_m),\n",
    "        \"CRA\": CRA,\n",
    "        \"t_PH_start\": t_PH_start if np.isfinite(t_PH_start) else np.nan,\n",
    "        \"PH\": PH,\n",
    "        \"Convergence_cycles\": Convergence_cycles,\n",
    "        **lam_results\n",
    "    }\n",
    "    return df_eval, summary\n",
    "\n",
    "\n",
    "def compute_metrics_from_windows_csv(\n",
    "    windows_csv: str,\n",
    "    seq_len: int,\n",
    "    alpha: float,\n",
    "    ph_consecutive_m: int,\n",
    "    lambdas: Tuple[float, ...],\n",
    "    eps_rul: float,\n",
    "    out_dir: str,\n",
    "    split_name: str,\n",
    ") -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    windows_csv -> cycle sequence(mean) -> file별 metrics 산출\n",
    "    저장:\n",
    "      - <out_dir>/<split_name>_cycle_sequence_mean.csv\n",
    "      - <out_dir>/<split_name>_prognostics_metrics_per_file.csv\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    df_seq = windows_to_cycle_sequence_mean(windows_csv)\n",
    "    seq_path = os.path.join(out_dir, f\"{split_name}_cycle_sequence_mean.csv\")\n",
    "    df_seq.to_csv(seq_path, index=False)\n",
    "\n",
    "    rows = []\n",
    "    for f in df_seq[\"file\"].unique():\n",
    "        sub = df_seq[df_seq[\"file\"] == f].copy()\n",
    "        _df_eval, summary = compute_metrics_for_one_file(\n",
    "            df_seq_one_file=sub,\n",
    "            seq_len=seq_len,\n",
    "            alpha=alpha,\n",
    "            ph_consecutive_m=ph_consecutive_m,\n",
    "            lambdas=lambdas,\n",
    "            eps_rul=eps_rul,\n",
    "        )\n",
    "        summary[\"file\"] = f\n",
    "        rows.append(summary)\n",
    "\n",
    "    dfm = pd.DataFrame(rows)\n",
    "    metrics_path = os.path.join(out_dir, f\"{split_name}_prognostics_metrics_per_file.csv\")\n",
    "    dfm.to_csv(metrics_path, index=False)\n",
    "\n",
    "    return seq_path, metrics_path\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) Plotters (paper-style figures) [ADDED]\n",
    "# ============================================================\n",
    "def _safe_name(s: str) -> str:\n",
    "    return s.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "\n",
    "def plot_alpha_ph(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    title: str,\n",
    "    alpha: float,\n",
    "    PH_start: Optional[float],\n",
    "    out_path: str,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Fig 1:\n",
    "      - True\n",
    "      - Prediction\n",
    "      - alpha accuracy zone (±alpha, relative)\n",
    "      - PH start (vertical line)\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.figure()\n",
    "\n",
    "    x = df_eval[\"cycle\"].values\n",
    "    y_true = df_eval[\"RUL_true\"].values\n",
    "    y_pred = df_eval[\"RUL_pred\"].values\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.plot(x, y_true, color=\"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, color=\"r\", label=\"Prediction (cycles)\")\n",
    "    plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} alpha zone\")\n",
    "    plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} alpha zone\")\n",
    "\n",
    "    if PH_start is not None and np.isfinite(PH_start):\n",
    "        plt.axvline(int(PH_start), color=\"g\", linestyle=\"-.\", label=\"PH start\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title}\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_alpha_lambda(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    title: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    t_lambda: Optional[int],\n",
    "    out_path: str,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Fig 2:\n",
    "      - True\n",
    "      - Prediction\n",
    "      - alpha-lambda zone: show ±alpha band ONLY for t >= t_lambda\n",
    "      - t_lambda vertical line\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.figure()\n",
    "\n",
    "    x = df_eval[\"cycle\"].values\n",
    "    y_true = df_eval[\"RUL_true\"].values\n",
    "    y_pred = df_eval[\"RUL_pred\"].values\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.plot(x, y_true, color=\"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, color=\"r\", label=\"Prediction (cycles)\")\n",
    "\n",
    "    if t_lambda is not None and np.isfinite(t_lambda):\n",
    "        t_lambda = int(t_lambda)\n",
    "        plt.axvline(t_lambda, linestyle=\":\", color=\"g\", label=f\"t_λ (λ={lambda_to_plot:.2f})\")\n",
    "        mask = x >= t_lambda\n",
    "        if np.any(mask):\n",
    "            plt.plot(x[mask], upper[mask], color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} α–λ zone\")\n",
    "            plt.plot(x[mask], lower[mask], color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} α–λ zone\")\n",
    "        else:\n",
    "            plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} α zone\")\n",
    "            plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} α zone\")\n",
    "    else:\n",
    "        plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} α zone\")\n",
    "        plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} α zone\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title}\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def make_paper_figures_for_split(\n",
    "    cycle_seq_csv: str,\n",
    "    metrics_per_file_csv: str,\n",
    "    out_fig_dir: str,\n",
    "    title_prefix: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    max_files: Optional[int] = None,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    For each file -> generate TWO figures:\n",
    "      1) alpha + PH\n",
    "      2) alpha-lambda (single lambda)\n",
    "    \"\"\"\n",
    "    df_seq = pd.read_csv(cycle_seq_csv)\n",
    "    dfm = pd.read_csv(metrics_per_file_csv)\n",
    "\n",
    "    files = df_seq[\"file\"].unique().tolist()\n",
    "    if max_files is not None:\n",
    "        files = files[:max_files]\n",
    "\n",
    "    os.makedirs(out_fig_dir, exist_ok=True)\n",
    "\n",
    "    lam_key = f\"t_lambda_{lambda_to_plot:.2f}\"\n",
    "\n",
    "    for f in files:\n",
    "        sub = df_seq[df_seq[\"file\"] == f].sort_values(\"cycle\").copy()\n",
    "        mrow = dfm[dfm[\"file\"] == f]\n",
    "        if mrow.empty:\n",
    "            continue\n",
    "        mrow = mrow.iloc[0].to_dict()\n",
    "\n",
    "        t_s = int(mrow[\"t_s\"])\n",
    "        t_e = int(mrow[\"t_e\"])\n",
    "        PH_start = mrow.get(\"t_PH_start\", np.nan)\n",
    "\n",
    "        df_eval = sub[(sub[\"cycle\"] >= t_s) & (sub[\"cycle\"] <= t_e)].copy()\n",
    "        if df_eval.empty:\n",
    "            continue\n",
    "\n",
    "        t_lambda = None\n",
    "        if lam_key in mrow and np.isfinite(mrow[lam_key]):\n",
    "            t_lambda = int(mrow[lam_key])\n",
    "\n",
    "        safe = _safe_name(f)\n",
    "\n",
    "        out1 = os.path.join(out_fig_dir, f\"FIG1_alpha_PH__{safe}.png\")\n",
    "        plot_alpha_ph(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            title=f\"{title_prefix} | α+PH\",\n",
    "            alpha=alpha,\n",
    "            PH_start=PH_start if np.isfinite(PH_start) else None,\n",
    "            out_path=out1,\n",
    "            dpi=dpi,\n",
    "        )\n",
    "\n",
    "        out2 = os.path.join(out_fig_dir, f\"FIG2_alpha_lambda__lam{lambda_to_plot:.2f}__{safe}.png\")\n",
    "        plot_alpha_lambda(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            title=f\"{title_prefix} | α–λ (λ={lambda_to_plot:.2f})\",\n",
    "            alpha=alpha,\n",
    "            lambda_to_plot=lambda_to_plot,\n",
    "            t_lambda=t_lambda,\n",
    "            out_path=out2,\n",
    "            dpi=dpi,\n",
    "        )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9) One seed run (Trial8 training + Trial9 eval outputs)\n",
    "# ============================================================\n",
    "def run_one_seed(cfg: Config, seed: int) -> Dict[str, Any]:\n",
    "    set_seed(seed)\n",
    "\n",
    "    seed_dir = os.path.join(cfg.out_dir, f\"seed_{seed}\")\n",
    "    os.makedirs(seed_dir, exist_ok=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"[SEED {seed}] device={device}\")\n",
    "    print(f\"[SEED {seed}] out={seed_dir}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    # split\n",
    "    files = list_csv_files(cfg.data_dir)\n",
    "    splits = split_files(files, cfg.train_ratio, cfg.val_ratio, cfg.test_ratio, seed)\n",
    "\n",
    "    # save split lists\n",
    "    for k in [\"train\", \"val\", \"test\"]:\n",
    "        pd.Series([p.name for p in splits[k]]).to_csv(\n",
    "            os.path.join(seed_dir, f\"{k}_files.csv\"), index=False, header=False\n",
    "        )\n",
    "\n",
    "    # datasets (fit scaler on train only)\n",
    "    scaler_x = StandardScaler()\n",
    "    train_ds = WindowedRULDatasetNorm2F(\n",
    "        splits[\"train\"], cfg.seq_len, cfg.stride, cfg.pred_horizon,\n",
    "        scaler_x=scaler_x, fit_scaler=True\n",
    "    )\n",
    "    val_ds = WindowedRULDatasetNorm2F(\n",
    "        splits[\"val\"], cfg.seq_len, cfg.stride, cfg.pred_horizon,\n",
    "        scaler_x=train_ds.scaler_x, fit_scaler=False\n",
    "    )\n",
    "    test_ds = WindowedRULDatasetNorm2F(\n",
    "        splits[\"test\"], cfg.seq_len, cfg.stride, cfg.pred_horizon,\n",
    "        scaler_x=train_ds.scaler_x, fit_scaler=False\n",
    "    )\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"feature\": [\"min_vce\", \"d_min_vce\"],\n",
    "        \"mean\": train_ds.scaler_x.mean_.ravel(),\n",
    "        \"std\": np.sqrt(train_ds.scaler_x.var_).ravel(),\n",
    "    }).to_csv(os.path.join(seed_dir, \"scaler_x_mean_std.csv\"), index=False)\n",
    "\n",
    "    # loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True,  num_workers=cfg.num_workers)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "\n",
    "    train_eval = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "    val_eval   = DataLoader(val_ds,   batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "    test_eval  = DataLoader(test_ds,  batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "\n",
    "    # model\n",
    "    model = LSTMRegressor(\n",
    "        input_size=2,\n",
    "        hidden_size=cfg.hidden_size,\n",
    "        num_layers=cfg.num_layers,\n",
    "        dropout=cfg.dropout,\n",
    "    ).to(device)\n",
    "\n",
    "    # IMPORTANT: cycle-loss training (same as Trial8)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "    # best checkpoint rule (same as Trial8)\n",
    "    best_by_val_cycles = float(\"inf\")\n",
    "    best_path = os.path.join(seed_dir, \"best_by_val_cycles.pt\")\n",
    "    last_path = os.path.join(seed_dir, \"last_epoch.pt\")\n",
    "\n",
    "    history: List[Dict[str, Any]] = []\n",
    "    bad_epochs = 0\n",
    "\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        model.train()\n",
    "        losses = []\n",
    "\n",
    "        for x, y_norm, _name, _s, y_cycles, rul0 in train_loader:\n",
    "            x = x.to(device)\n",
    "            y_cycles = y_cycles.to(device).view(-1, 1)\n",
    "            rul0 = rul0.to(device).view(-1, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_norm = model(x)\n",
    "            pred_cycles = pred_norm * rul0  # (B,1)\n",
    "\n",
    "            loss = criterion(pred_cycles, y_cycles)  # cycle MSE\n",
    "            loss.backward()\n",
    "\n",
    "            if cfg.grad_clip and cfg.grad_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        train_mse_cycles = float(np.mean(losses)) if losses else float(\"nan\")\n",
    "        val_metrics = evaluate_basic(model, val_loader, device)\n",
    "\n",
    "        history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_mse_cycles\": train_mse_cycles,\n",
    "            \"val_rmse_cycles\": val_metrics[\"rmse_cycles\"],\n",
    "            \"val_mae_cycles\": val_metrics[\"mae_cycles\"],\n",
    "            \"val_rmse_norm\": val_metrics[\"rmse_norm\"],\n",
    "            \"val_mae_norm\": val_metrics[\"mae_norm\"],\n",
    "        })\n",
    "\n",
    "        # best 기준: val_rmse_cycles\n",
    "        if val_metrics[\"rmse_cycles\"] < best_by_val_cycles:\n",
    "            best_by_val_cycles = val_metrics[\"rmse_cycles\"]\n",
    "            bad_epochs = 0\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(\n",
    "                f\"[SEED {seed}] [{epoch:03d}/{cfg.epochs}] \"\n",
    "                f\"train_mse_cycles={train_mse_cycles:.3f} | \"\n",
    "                f\"val_rmse_cycles={val_metrics['rmse_cycles']:.3f} | \"\n",
    "                f\"val_mae_cycles={val_metrics['mae_cycles']:.3f} | \"\n",
    "                f\"best_val_rmse_cycles={best_by_val_cycles:.3f}\"\n",
    "            )\n",
    "\n",
    "        if bad_epochs >= cfg.patience:\n",
    "            print(f\"[SEED {seed}] Early stopping at epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "    pd.DataFrame(history).to_csv(os.path.join(seed_dir, \"history.csv\"), index=False)\n",
    "    torch.save(model.state_dict(), last_path)\n",
    "\n",
    "    # export helper\n",
    "    def export_ckpt(tag: str, ckpt_path: str) -> Dict[str, Any]:\n",
    "        sub_dir = os.path.join(seed_dir, tag)\n",
    "        os.makedirs(sub_dir, exist_ok=True)\n",
    "\n",
    "        model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        tr = evaluate_basic(model, train_eval, device)\n",
    "        va = evaluate_basic(model, val_eval, device)\n",
    "        te = evaluate_basic(model, test_eval, device)\n",
    "\n",
    "        # save preds + added metrics/figures\n",
    "        for split_name, loader in [(\"train\", train_eval), (\"val\", val_eval), (\"test\", test_eval)]:\n",
    "            win_csv = os.path.join(sub_dir, f\"{split_name}_predictions_windows.csv\")\n",
    "            save_predictions_windows_csv(model, loader, device, win_csv, seq_len=cfg.seq_len)\n",
    "\n",
    "            # ADDED: metrics + cycle sequence\n",
    "            seq_csv, metrics_csv = compute_metrics_from_windows_csv(\n",
    "                windows_csv=win_csv,\n",
    "                seq_len=cfg.seq_len,\n",
    "                alpha=cfg.alpha,\n",
    "                ph_consecutive_m=cfg.ph_consecutive_m,\n",
    "                lambdas=cfg.lambdas,\n",
    "                eps_rul=cfg.eps_rul,\n",
    "                out_dir=sub_dir,\n",
    "                split_name=split_name,\n",
    "            )\n",
    "\n",
    "            # ADDED: paper-style figures\n",
    "            if cfg.save_figures:\n",
    "                fig_dir = os.path.join(sub_dir, \"paper_figures\", split_name)\n",
    "                make_paper_figures_for_split(\n",
    "                    cycle_seq_csv=seq_csv,\n",
    "                    metrics_per_file_csv=metrics_csv,\n",
    "                    out_fig_dir=fig_dir,\n",
    "                    title_prefix=f\"SEED {seed} | {tag.upper()} | {split_name}\",\n",
    "                    alpha=cfg.alpha,\n",
    "                    lambda_to_plot=cfg.lambda_to_plot,\n",
    "                    max_files=cfg.max_files_to_plot,\n",
    "                )\n",
    "\n",
    "        ms = {\n",
    "            \"seed\": seed,\n",
    "            \"checkpoint\": tag,\n",
    "\n",
    "            \"train_rmse_cycles\": tr[\"rmse_cycles\"],\n",
    "            \"train_mae_cycles\": tr[\"mae_cycles\"],\n",
    "            \"train_rmse_norm\": tr[\"rmse_norm\"],\n",
    "            \"train_mae_norm\": tr[\"mae_norm\"],\n",
    "\n",
    "            \"val_rmse_cycles\": va[\"rmse_cycles\"],\n",
    "            \"val_mae_cycles\": va[\"mae_cycles\"],\n",
    "            \"val_rmse_norm\": va[\"rmse_norm\"],\n",
    "            \"val_mae_norm\": va[\"mae_norm\"],\n",
    "\n",
    "            \"test_rmse_cycles\": te[\"rmse_cycles\"],\n",
    "            \"test_mae_cycles\": te[\"mae_cycles\"],\n",
    "            \"test_rmse_norm\": te[\"rmse_norm\"],\n",
    "            \"test_mae_norm\": te[\"mae_norm\"],\n",
    "\n",
    "            \"stopped_epoch\": history[-1][\"epoch\"] if len(history) else None,\n",
    "            \"best_val_rmse_cycles\": best_by_val_cycles,\n",
    "\n",
    "            # eval meta\n",
    "            \"alpha\": cfg.alpha,\n",
    "            \"ph_consecutive_m\": cfg.ph_consecutive_m,\n",
    "            \"rep_method\": cfg.rep_method,\n",
    "            \"lambdas\": str(cfg.lambdas),\n",
    "            \"lambda_to_plot\": cfg.lambda_to_plot,\n",
    "        }\n",
    "        pd.DataFrame([ms]).to_csv(os.path.join(sub_dir, \"metrics_summary.csv\"), index=False)\n",
    "\n",
    "        print(\n",
    "            f\"[SEED {seed}] {tag}: \"\n",
    "            f\"VAL rmse_cycles={va['rmse_cycles']:.3f}, mae_cycles={va['mae_cycles']:.3f} | \"\n",
    "            f\"TEST rmse_cycles={te['rmse_cycles']:.3f}, mae_cycles={te['mae_cycles']:.3f}\"\n",
    "        )\n",
    "        return ms\n",
    "\n",
    "    ms_best = export_ckpt(\"best_by_val_cycles\", best_path)\n",
    "    ms_last = export_ckpt(\"last_epoch\", last_path)\n",
    "\n",
    "    return {\"seed\": seed, \"seed_dir\": seed_dir, \"best\": ms_best, \"last\": ms_last}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10) Seed sweep + global comparison (same style as Trial8/9)\n",
    "# ============================================================\n",
    "def summarize_across_seeds(cfg: Config, results: List[Dict[str, Any]]) -> None:\n",
    "    rows = []\n",
    "    for r in results:\n",
    "        rows.append(r[\"best\"])\n",
    "        rows.append(r[\"last\"])\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(os.path.join(cfg.out_dir, \"summary_across_seeds.csv\"), index=False)\n",
    "\n",
    "    def _isfinite(x: Any) -> bool:\n",
    "        try:\n",
    "            return bool(np.isfinite(float(x)))\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def win_rate(metric: str) -> Dict[str, Any]:\n",
    "        wins_last = 0\n",
    "        wins_best = 0\n",
    "        ties = 0\n",
    "        diffs = []\n",
    "\n",
    "        for r in results:\n",
    "            b = r[\"best\"][metric]\n",
    "            l = r[\"last\"][metric]\n",
    "            if _isfinite(b) and _isfinite(l):\n",
    "                diffs.append(float(l) - float(b))\n",
    "                if float(l) < float(b):\n",
    "                    wins_last += 1\n",
    "                elif float(b) < float(l):\n",
    "                    wins_best += 1\n",
    "                else:\n",
    "                    ties += 1\n",
    "\n",
    "        return {\n",
    "            \"metric\": metric,\n",
    "            \"wins_last\": wins_last,\n",
    "            \"wins_best\": wins_best,\n",
    "            \"ties\": ties,\n",
    "            \"mean(last-best)\": float(np.mean(diffs)) if diffs else float(\"nan\"),\n",
    "            \"std(last-best)\": float(np.std(diffs)) if diffs else float(\"nan\"),\n",
    "        }\n",
    "\n",
    "    metrics = [\"test_mae_cycles\", \"test_rmse_cycles\", \"test_mae_norm\", \"test_rmse_norm\"]\n",
    "    wr = [win_rate(m) for m in metrics]\n",
    "    pd.DataFrame(wr).to_csv(os.path.join(cfg.out_dir, \"win_rate_summary.csv\"), index=False)\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"=== WIN-RATE SUMMARY (TEST; lower is better) ===\")\n",
    "    for row in wr:\n",
    "        lines.append(\n",
    "            f\"- {row['metric']}: last wins={row['wins_last']}, best wins={row['wins_best']}, ties={row['ties']} | \"\n",
    "            f\"mean(last-best)={row['mean(last-best)']:.6f}, std(last-best)={row['std(last-best)']:.6f}\"\n",
    "        )\n",
    "\n",
    "    agg = df.groupby(\"checkpoint\")[metrics].agg([\"mean\", \"std\"])\n",
    "    lines.append(\"\\n=== MEAN ± STD across seeds (TEST) ===\")\n",
    "    lines.append(str(agg))\n",
    "\n",
    "    with open(os.path.join(cfg.out_dir, \"win_rate_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nSaved:\")\n",
    "    print(\" -\", os.path.join(cfg.out_dir, \"summary_across_seeds.csv\"))\n",
    "    print(\" -\", os.path.join(cfg.out_dir, \"win_rate_summary.csv\"))\n",
    "    print(\" -\", os.path.join(cfg.out_dir, \"win_rate_summary.txt\"))\n",
    "\n",
    "\n",
    "def run_trial10_seed_sweep(cfg: Config) -> None:\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    for seed in cfg.seeds:\n",
    "        res = run_one_seed(cfg, seed)\n",
    "        results.append(res)\n",
    "\n",
    "    summarize_across_seeds(cfg, results)\n",
    "\n",
    "    print(\"\\nDONE. Check Trial10 folder:\")\n",
    "    print(\" - per seed results: Trial10/seed_<seed>/...\")\n",
    "    print(\" - paper figures: seed_<seed>/<ckpt>/paper_figures/<split>/\")\n",
    "    print(\" - cycle seq mean: <ckpt>/<split>_cycle_sequence_mean.csv\")\n",
    "    print(\" - PH/α–λ metrics: <ckpt>/<split>_prognostics_metrics_per_file.csv\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 11) Run\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config(\n",
    "        data_dir=r\"C:\\Users\\11HOME_AHCI\\Desktop\\PoF\\Winter 2026\\Ref Data4\\100\",\n",
    "        out_dir=r\"./Trial10\",\n",
    "\n",
    "        seeds=(9819123, 111, 222, 333, 444),\n",
    "\n",
    "        seq_len=100,\n",
    "        stride=5,\n",
    "        pred_horizon=0,\n",
    "\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.2,\n",
    "        test_ratio=0.1,\n",
    "\n",
    "        batch_size=512,\n",
    "        epochs=300,\n",
    "        lr=1e-3,\n",
    "        weight_decay=0.0,\n",
    "        patience=30,\n",
    "        grad_clip=1.0,\n",
    "\n",
    "        hidden_size=512,\n",
    "        num_layers=2,\n",
    "        dropout=0.2,\n",
    "\n",
    "        save_figures=True,\n",
    "        max_files_to_plot=None,\n",
    "        num_workers=0,\n",
    "\n",
    "        # eval settings\n",
    "        alpha=0.20,\n",
    "        ph_consecutive_m=5,\n",
    "        rep_method=\"mean\",\n",
    "        lambdas=(0.2, 0.4, 0.6, 0.8),\n",
    "        lambda_to_plot=0.6,\n",
    "    )\n",
    "\n",
    "    run_trial10_seed_sweep(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e810a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ BEST MODEL (Trial10) ================\n",
      "[SELECTED BY VAL]  (recommended for model selection)\n",
      "  Seed             : 333\n",
      "  Checkpoint       : best_by_val_cycles\n",
      "  VAL  RMSE (cyc)   : 2347.371\n",
      "  VAL  MAE  (cyc)   : 1632.633\n",
      "  VAL  RMSE (norm)  : 0.141799\n",
      "  VAL  MAE  (norm)  : 0.110871\n",
      "  TEST RMSE (cyc)   : 2004.070\n",
      "  TEST MAE  (cyc)   : 1216.491\n",
      "  TEST RMSE (norm)  : 0.188019\n",
      "  TEST MAE  (norm)  : 0.146331\n",
      "\n",
      "[SELECTED BY TEST] (for reporting only; not for tuning)\n",
      "  Seed             : 9819123\n",
      "  Checkpoint       : best_by_val_cycles\n",
      "  TEST RMSE (cyc)   : 1459.439\n",
      "  TEST MAE  (cyc)   : 1008.942\n",
      "  TEST RMSE (norm)  : 0.128745\n",
      "  TEST MAE  (norm)  : 0.093076\n",
      "  VAL  RMSE (cyc)   : 3258.582\n",
      "  VAL  MAE  (cyc)   : 2460.728\n",
      "  VAL  RMSE (norm)  : 0.193396\n",
      "  VAL  MAE  (norm)  : 0.160890\n",
      "\n",
      "---------------- WIN-RATE (last_epoch vs best_by_val_cycles) ----------------\n",
      "- val_rmse_cycles: last wins=0, best wins=5, ties=0 | mean(last-best)=352.976063\n",
      "- test_rmse_cycles: last wins=3, best wins=2, ties=0 | mean(last-best)=-42.769173\n",
      "- val_rmse_norm: last wins=0, best wins=5, ties=0 | mean(last-best)=0.008941\n",
      "- test_rmse_norm: last wins=2, best wins=3, ties=0 | mean(last-best)=-0.002885\n",
      "=====================================================\n",
      "\n",
      "Saved -> ./Trial10\\BEST_MODEL_BY_VAL.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================\n",
    "# Trial10 paths\n",
    "# ============================\n",
    "TRIAL10_DIR = \"./Trial10\"\n",
    "SUMMARY_CSV = os.path.join(TRIAL10_DIR, \"summary_across_seeds.csv\")\n",
    "\n",
    "# Trial10 checkpoint tags\n",
    "BEST_TAG = \"best_by_val_cycles\"\n",
    "LAST_TAG = \"last_epoch\"\n",
    "\n",
    "\n",
    "def _require_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in summary CSV: {missing}\")\n",
    "\n",
    "\n",
    "def pick_best_row(df: pd.DataFrame, metric_prefix: str = \"val\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    metric_prefix: \"val\" or \"test\"\n",
    "    Sort rule (lower is better):\n",
    "      1) <prefix>_rmse_cycles ascending\n",
    "      2) <prefix>_mae_cycles  ascending\n",
    "    \"\"\"\n",
    "    rmse_col = f\"{metric_prefix}_rmse_cycles\"\n",
    "    mae_col = f\"{metric_prefix}_mae_cycles\"\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", rmse_col, mae_col])\n",
    "\n",
    "    df_sorted = df.sort_values(\n",
    "        by=[rmse_col, mae_col],\n",
    "        ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return df_sorted.iloc[0]\n",
    "\n",
    "\n",
    "def win_rate(df: pd.DataFrame, metric: str) -> dict:\n",
    "    \"\"\"\n",
    "    Compare BEST_TAG vs LAST_TAG within each seed on the given metric (lower is better).\n",
    "    Returns wins for last, wins for best, ties, and mean(last-best).\n",
    "    \"\"\"\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", metric])\n",
    "\n",
    "    wins_last = 0\n",
    "    wins_best = 0\n",
    "    ties = 0\n",
    "    diffs = []\n",
    "\n",
    "    for seed, g in df.groupby(\"seed\"):\n",
    "        ckpts = set(g[\"checkpoint\"].astype(str).values)\n",
    "        if not ({BEST_TAG, LAST_TAG} <= ckpts):\n",
    "            continue\n",
    "\n",
    "        b = float(g.loc[g[\"checkpoint\"] == BEST_TAG, metric].iloc[0])\n",
    "        l = float(g.loc[g[\"checkpoint\"] == LAST_TAG, metric].iloc[0])\n",
    "\n",
    "        if np.isfinite(b) and np.isfinite(l):\n",
    "            diffs.append(l - b)  # negative => last better\n",
    "            if l < b:\n",
    "                wins_last += 1\n",
    "            elif b < l:\n",
    "                wins_best += 1\n",
    "            else:\n",
    "                ties += 1\n",
    "\n",
    "    return {\n",
    "        \"metric\": metric,\n",
    "        \"wins_last\": wins_last,\n",
    "        \"wins_best\": wins_best,\n",
    "        \"ties\": ties,\n",
    "        \"mean(last-best)\": float(np.mean(diffs)) if diffs else float(\"nan\"),\n",
    "        \"std(last-best)\": float(np.std(diffs)) if diffs else float(\"nan\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(SUMMARY_CSV):\n",
    "        raise FileNotFoundError(f\"Not found: {SUMMARY_CSV}\")\n",
    "\n",
    "    df = pd.read_csv(SUMMARY_CSV)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) VAL 기준 best (권장)\n",
    "    # -----------------------------\n",
    "    best_val = pick_best_row(df, metric_prefix=\"val\")\n",
    "    best_val_seed = int(best_val[\"seed\"])\n",
    "    best_val_ckpt = str(best_val[\"checkpoint\"])\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2) TEST 기준 best (참고)\n",
    "    # -----------------------------\n",
    "    best_test = pick_best_row(df, metric_prefix=\"test\")\n",
    "    best_test_seed = int(best_test[\"seed\"])\n",
    "    best_test_ckpt = str(best_test[\"checkpoint\"])\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3) win-rate (seed별 last vs best 비교)\n",
    "    # -----------------------------\n",
    "    wr_val_rmse_cyc = win_rate(df, \"val_rmse_cycles\")\n",
    "    wr_test_rmse_cyc = win_rate(df, \"test_rmse_cycles\")\n",
    "\n",
    "    # norm 지표도 같이 보는 경우\n",
    "    wr_val_rmse_norm = win_rate(df, \"val_rmse_norm\")\n",
    "    wr_test_rmse_norm = win_rate(df, \"test_rmse_norm\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4) 출력\n",
    "    # -----------------------------\n",
    "    print(\"\\n================ BEST MODEL (Trial10) ================\")\n",
    "    print(\"[SELECTED BY VAL]  (recommended for model selection)\")\n",
    "    print(f\"  Seed             : {best_val_seed}\")\n",
    "    print(f\"  Checkpoint       : {best_val_ckpt}\")\n",
    "    print(f\"  VAL  RMSE (cyc)   : {best_val['val_rmse_cycles']:.3f}\")\n",
    "    print(f\"  VAL  MAE  (cyc)   : {best_val['val_mae_cycles']:.3f}\")\n",
    "    print(f\"  VAL  RMSE (norm)  : {best_val['val_rmse_norm']:.6f}\")\n",
    "    print(f\"  VAL  MAE  (norm)  : {best_val['val_mae_norm']:.6f}\")\n",
    "    print(f\"  TEST RMSE (cyc)   : {best_val['test_rmse_cycles']:.3f}\")\n",
    "    print(f\"  TEST MAE  (cyc)   : {best_val['test_mae_cycles']:.3f}\")\n",
    "    print(f\"  TEST RMSE (norm)  : {best_val['test_rmse_norm']:.6f}\")\n",
    "    print(f\"  TEST MAE  (norm)  : {best_val['test_mae_norm']:.6f}\")\n",
    "\n",
    "    # Trial10은 best 기준이 val_rmse_cycles이지만, 참고용 test-best도 출력\n",
    "    print(\"\\n[SELECTED BY TEST] (for reporting only; not for tuning)\")\n",
    "    print(f\"  Seed             : {best_test_seed}\")\n",
    "    print(f\"  Checkpoint       : {best_test_ckpt}\")\n",
    "    print(f\"  TEST RMSE (cyc)   : {best_test['test_rmse_cycles']:.3f}\")\n",
    "    print(f\"  TEST MAE  (cyc)   : {best_test['test_mae_cycles']:.3f}\")\n",
    "    print(f\"  TEST RMSE (norm)  : {best_test['test_rmse_norm']:.6f}\")\n",
    "    print(f\"  TEST MAE  (norm)  : {best_test['test_mae_norm']:.6f}\")\n",
    "    print(f\"  VAL  RMSE (cyc)   : {best_test['val_rmse_cycles']:.3f}\")\n",
    "    print(f\"  VAL  MAE  (cyc)   : {best_test['val_mae_cycles']:.3f}\")\n",
    "    print(f\"  VAL  RMSE (norm)  : {best_test['val_rmse_norm']:.6f}\")\n",
    "    print(f\"  VAL  MAE  (norm)  : {best_test['val_mae_norm']:.6f}\")\n",
    "\n",
    "    print(\"\\n---------------- WIN-RATE (last_epoch vs best_by_val_cycles) ----------------\")\n",
    "    print(f\"- {wr_val_rmse_cyc['metric']}: last wins={wr_val_rmse_cyc['wins_last']}, \"\n",
    "          f\"best wins={wr_val_rmse_cyc['wins_best']}, ties={wr_val_rmse_cyc['ties']} | \"\n",
    "          f\"mean(last-best)={wr_val_rmse_cyc['mean(last-best)']:.6f}\")\n",
    "    print(f\"- {wr_test_rmse_cyc['metric']}: last wins={wr_test_rmse_cyc['wins_last']}, \"\n",
    "          f\"best wins={wr_test_rmse_cyc['wins_best']}, ties={wr_test_rmse_cyc['ties']} | \"\n",
    "          f\"mean(last-best)={wr_test_rmse_cyc['mean(last-best)']:.6f}\")\n",
    "    print(f\"- {wr_val_rmse_norm['metric']}: last wins={wr_val_rmse_norm['wins_last']}, \"\n",
    "          f\"best wins={wr_val_rmse_norm['wins_best']}, ties={wr_val_rmse_norm['ties']} | \"\n",
    "          f\"mean(last-best)={wr_val_rmse_norm['mean(last-best)']:.6f}\")\n",
    "    print(f\"- {wr_test_rmse_norm['metric']}: last wins={wr_test_rmse_norm['wins_last']}, \"\n",
    "          f\"best wins={wr_test_rmse_norm['wins_best']}, ties={wr_test_rmse_norm['ties']} | \"\n",
    "          f\"mean(last-best)={wr_test_rmse_norm['mean(last-best)']:.6f}\")\n",
    "    print(\"=====================================================\\n\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5) 기록 저장 (VAL 기준 best)\n",
    "    # -----------------------------\n",
    "    out_txt = os.path.join(TRIAL10_DIR, \"BEST_MODEL_BY_VAL.txt\")\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"BEST MODEL (Trial10) - Selected by VAL (rmse_cycles then mae_cycles)\\n\")\n",
    "        f.write(f\"seed={best_val_seed}\\n\")\n",
    "        f.write(f\"checkpoint={best_val_ckpt}\\n\")\n",
    "        f.write(f\"val_rmse_cycles={best_val['val_rmse_cycles']}\\n\")\n",
    "        f.write(f\"val_mae_cycles={best_val['val_mae_cycles']}\\n\")\n",
    "        f.write(f\"val_rmse_norm={best_val['val_rmse_norm']}\\n\")\n",
    "        f.write(f\"val_mae_norm={best_val['val_mae_norm']}\\n\")\n",
    "        f.write(f\"test_rmse_cycles={best_val['test_rmse_cycles']}\\n\")\n",
    "        f.write(f\"test_mae_cycles={best_val['test_mae_cycles']}\\n\")\n",
    "        f.write(f\"test_rmse_norm={best_val['test_rmse_norm']}\\n\")\n",
    "        f.write(f\"test_mae_norm={best_val['test_mae_norm']}\\n\")\n",
    "\n",
    "        # Trial10 summary에는 eval meta도 같이 들어갈 수 있어서 있으면 같이 저장\n",
    "        for k in [\"alpha\", \"ph_consecutive_m\", \"rep_method\", \"lambdas\", \"lambda_to_plot\", \"best_val_rmse_cycles\"]:\n",
    "            if k in best_val.index:\n",
    "                f.write(f\"{k}={best_val[k]}\\n\")\n",
    "\n",
    "    print(f\"Saved -> {out_txt}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc58d489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] train: λ=0.20:0.686, λ=0.40:0.329, λ=0.60:0.271, λ=0.80:0.243, overall:0.382\n",
      "[OK] val: λ=0.20:0.600, λ=0.40:0.500, λ=0.60:0.450, λ=0.80:0.250, overall:0.450\n",
      "[OK] test: λ=0.20:0.700, λ=0.40:0.600, λ=0.60:0.100, λ=0.80:0.300, overall:0.425\n",
      "\n",
      "==================== DONE ====================\n",
      "Saved:\n",
      " - ./Trial10\\seed_333\\best_by_val_cycles\\alpha_lambda_eval\\alpha_lambda_summary_seed333_best_by_val_cycles.csv\n",
      " - ./Trial10\\seed_333\\best_by_val_cycles\\alpha_lambda_eval\\alpha_lambda_per_file_seed333_best_by_val_cycles.csv\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# USER CONFIG (Trial10)\n",
    "# =========================\n",
    "TRIAL_DIR = r\"./Trial10\"            # Trial10 루트 폴더\n",
    "SEED = 333                          # 선택된 seed\n",
    "\n",
    "# Trial10 checkpoint tag:\n",
    "#  - \"best_by_val_cycles\"  (recommended)\n",
    "#  - \"last_epoch\"\n",
    "CKPT = \"best_by_val_cycles\"\n",
    "\n",
    "SPLITS = [\"train\", \"val\", \"test\"]   # 평가할 split\n",
    "LAM_STRS = [\"0.20\", \"0.40\", \"0.60\", \"0.80\"]\n",
    "\n",
    "# (선택) 후반 λ를 더 중요하게 보고 싶으면 가중치 사용 (기본 None이면 단순 평균)\n",
    "# 예: λ=0.2,0.4,0.6,0.8 가중치 = 1,1,2,3\n",
    "LAMBDA_WEIGHTS = None  # 또는 {\"0.20\": 1, \"0.40\": 1, \"0.60\": 2, \"0.80\": 3}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _require_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "\n",
    "def compute_alpha_lambda_rates(dfm: pd.DataFrame, lam_strs, weights=None) -> dict:\n",
    "    \"\"\"\n",
    "    dfm: <split>_prognostics_metrics_per_file.csv\n",
    "    Returns:\n",
    "      - per-lambda success rate (mean of alpha_lambda_ok_{lam})\n",
    "      - overall mean rate (simple mean or weighted mean)\n",
    "    \"\"\"\n",
    "    rates = {}\n",
    "\n",
    "    # per-lambda\n",
    "    for ls in lam_strs:\n",
    "        col = f\"alpha_lambda_ok_{ls}\"\n",
    "        rates[f\"rate_{ls}\"] = float(dfm[col].mean()) if col in dfm.columns else np.nan\n",
    "\n",
    "    # overall\n",
    "    if weights is None:\n",
    "        vals = [rates[f\"rate_{ls}\"] for ls in lam_strs if np.isfinite(rates[f\"rate_{ls}\"])]\n",
    "        rates[\"rate_mean_all\"] = float(np.mean(vals)) if vals else np.nan\n",
    "    else:\n",
    "        num, den = 0.0, 0.0\n",
    "        for ls in lam_strs:\n",
    "            v = rates[f\"rate_{ls}\"]\n",
    "            w = float(weights.get(ls, 0.0))\n",
    "            if np.isfinite(v) and w > 0:\n",
    "                num += w * v\n",
    "                den += w\n",
    "        rates[\"rate_weighted_all\"] = (num / den) if den > 0 else np.nan\n",
    "\n",
    "    return rates\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Trial10 폴더 구조: ./Trial10/seed_<seed>/<ckpt>/\n",
    "    ckpt_dir = os.path.join(TRIAL_DIR, f\"seed_{SEED}\", CKPT)\n",
    "    if not os.path.isdir(ckpt_dir):\n",
    "        raise FileNotFoundError(f\"Not found: {ckpt_dir}\\n\"\n",
    "                                f\"Check TRIAL_DIR/SEED/CKPT. \"\n",
    "                                f\"CKPT should be 'best_by_val_cycles' or 'last_epoch'.\")\n",
    "\n",
    "    out_dir = os.path.join(ckpt_dir, \"alpha_lambda_eval\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    summary_rows = []\n",
    "    per_file_rows = []\n",
    "\n",
    "    for split in SPLITS:\n",
    "        # Trial10 export 위치: <ckpt_dir>/<split>_prognostics_metrics_per_file.csv\n",
    "        mpath = os.path.join(ckpt_dir, f\"{split}_prognostics_metrics_per_file.csv\")\n",
    "        if not os.path.exists(mpath):\n",
    "            print(f\"[SKIP] Missing: {mpath}\")\n",
    "            continue\n",
    "\n",
    "        dfm = pd.read_csv(mpath)\n",
    "        _require_cols(dfm, [\"file\"])  # 최소 file은 있어야 함\n",
    "\n",
    "        # split 요약(성공률)\n",
    "        rates = compute_alpha_lambda_rates(dfm, LAM_STRS, weights=LAMBDA_WEIGHTS)\n",
    "        row = {\n",
    "            \"trial_dir\": TRIAL_DIR,\n",
    "            \"seed\": SEED,\n",
    "            \"checkpoint\": CKPT,\n",
    "            \"split\": split,\n",
    "            \"n_files\": int(len(dfm)),\n",
    "            **rates\n",
    "        }\n",
    "        summary_rows.append(row)\n",
    "\n",
    "        # (선택) 파일별 pass/fail 저장\n",
    "        keep_cols = [\"file\"]\n",
    "        for ls in LAM_STRS:\n",
    "            c_ok = f\"alpha_lambda_ok_{ls}\"\n",
    "            c_tl = f\"t_lambda_{ls}\"\n",
    "            if c_ok in dfm.columns:\n",
    "                keep_cols.append(c_ok)\n",
    "            if c_tl in dfm.columns:\n",
    "                keep_cols.append(c_tl)\n",
    "\n",
    "        sub = dfm[keep_cols].copy()\n",
    "        sub.insert(0, \"split\", split)\n",
    "        sub.insert(0, \"checkpoint\", CKPT)\n",
    "        sub.insert(0, \"seed\", SEED)\n",
    "        per_file_rows.append(sub)\n",
    "\n",
    "        # 콘솔 출력\n",
    "        parts = []\n",
    "        for ls in LAM_STRS:\n",
    "            v = row.get(f\"rate_{ls}\", np.nan)\n",
    "            if np.isfinite(v):\n",
    "                parts.append(f\"λ={ls}:{v:.3f}\")\n",
    "        overall_key = \"rate_weighted_all\" if LAMBDA_WEIGHTS is not None else \"rate_mean_all\"\n",
    "        overall = row.get(overall_key, np.nan)\n",
    "        if np.isfinite(overall):\n",
    "            parts.append(f\"overall:{overall:.3f}\")\n",
    "        print(f\"[OK] {split}: \" + \", \".join(parts))\n",
    "\n",
    "    # 저장: split별 요약\n",
    "    df_summary = pd.DataFrame(summary_rows)\n",
    "    out_summary = os.path.join(out_dir, f\"alpha_lambda_summary_seed{SEED}_{CKPT}.csv\")\n",
    "    df_summary.to_csv(out_summary, index=False)\n",
    "\n",
    "    # 저장: 파일별 pass/fail (선택)\n",
    "    out_pf = None\n",
    "    if per_file_rows:\n",
    "        df_pf = pd.concat(per_file_rows, axis=0, ignore_index=True)\n",
    "        out_pf = os.path.join(out_dir, f\"alpha_lambda_per_file_seed{SEED}_{CKPT}.csv\")\n",
    "        df_pf.to_csv(out_pf, index=False)\n",
    "\n",
    "    print(\"\\n==================== DONE ====================\")\n",
    "    print(\"Saved:\")\n",
    "    print(\" -\", out_summary)\n",
    "    if out_pf:\n",
    "        print(\" -\", out_pf)\n",
    "    print(\"==============================================\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfd6bbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] selected by VAL (val_rmse_cycles, val_mae_cycles)\n",
      "  seed=333, checkpoint=best_by_val_cycles\n",
      "[READ] ./Trial10\\seed_333\\best_by_val_cycles\\alpha_lambda_eval\\alpha_lambda_summary_seed333_best_by_val_cycles.csv\n",
      "[SAVE] ./alpha_lambda_curve_best_trial10.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# USER CONFIG (Trial10)\n",
    "# =========================\n",
    "TRIAL10_DIR = r\"./Trial10\"  # 또는 r\"C:\\... \\Trial10\"\n",
    "OUT_PNG = r\"./alpha_lambda_curve_best_trial10.png\"\n",
    "\n",
    "LAM_STRS = [\"0.20\", \"0.40\", \"0.60\", \"0.80\"]\n",
    "LAM = [float(x) for x in LAM_STRS]\n",
    "SPLITS_ORDER = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _require_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "def pick_best_row_by_val_cycles(summary_csv: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Trial10 summary_across_seeds.csv에서\n",
    "    VAL 기준 best 모델 1개 선택:\n",
    "      1) val_rmse_cycles 최소\n",
    "      2) val_mae_cycles 최소 (tie-break)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(summary_csv):\n",
    "        raise FileNotFoundError(f\"Not found: {summary_csv}\")\n",
    "\n",
    "    df = pd.read_csv(summary_csv)\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", \"val_rmse_cycles\", \"val_mae_cycles\"])\n",
    "\n",
    "    df_sorted = df.sort_values(\n",
    "        by=[\"val_rmse_cycles\", \"val_mae_cycles\"],\n",
    "        ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return df_sorted.iloc[0]\n",
    "\n",
    "def find_alpha_lambda_summary_csv(trial_dir: str, seed: int, ckpt: str) -> str:\n",
    "    \"\"\"\n",
    "    Trial10 구조 기준:\n",
    "      <trial_dir>/seed_<seed>/<ckpt>/alpha_lambda_eval/alpha_lambda_summary_seed<seed>_<ckpt>.csv\n",
    "    \"\"\"\n",
    "    cand = os.path.join(\n",
    "        trial_dir,\n",
    "        f\"seed_{seed}\",\n",
    "        ckpt,\n",
    "        \"alpha_lambda_eval\",\n",
    "        f\"alpha_lambda_summary_seed{seed}_{ckpt}.csv\"\n",
    "    )\n",
    "    if os.path.exists(cand):\n",
    "        return cand\n",
    "\n",
    "    # 혹시 파일명이 다르게 저장된 경우를 위한 fallback: 폴더 내 summary csv 아무거나 찾기\n",
    "    alt_dir = os.path.join(trial_dir, f\"seed_{seed}\", ckpt, \"alpha_lambda_eval\")\n",
    "    if os.path.isdir(alt_dir):\n",
    "        for fn in os.listdir(alt_dir):\n",
    "            if fn.lower().startswith(\"alpha_lambda_summary\") and fn.lower().endswith(\".csv\"):\n",
    "                return os.path.join(alt_dir, fn)\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        \"alpha-lambda summary csv not found.\\n\"\n",
    "        f\"Expected: {cand}\\n\"\n",
    "        f\"Also checked: {alt_dir}\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    summary_csv = os.path.join(TRIAL10_DIR, \"summary_across_seeds.csv\")\n",
    "\n",
    "    best = pick_best_row_by_val_cycles(summary_csv)\n",
    "    best_seed = int(best[\"seed\"])\n",
    "    best_ckpt = str(best[\"checkpoint\"])\n",
    "\n",
    "    summary_path = find_alpha_lambda_summary_csv(TRIAL10_DIR, best_seed, best_ckpt)\n",
    "    df = pd.read_csv(summary_path)\n",
    "\n",
    "    # plot\n",
    "    plt.figure()\n",
    "    for split in SPLITS_ORDER:\n",
    "        sub = df[df[\"split\"] == split]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        row = sub.iloc[0]\n",
    "        rates = [float(row.get(f\"rate_{ls}\", np.nan)) for ls in LAM_STRS]\n",
    "        plt.plot(LAM, rates, marker=\"o\", label=split)\n",
    "\n",
    "    plt.xticks(LAM, [f\"{x:.2f}\" for x in LAM])\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.xlabel(\"λ (life fraction)\")\n",
    "    plt.ylabel(\"α–λ success rate\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.title(f\"Trial10 BEST (VAL) | seed={best_seed} | ckpt={best_ckpt}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(OUT_PNG, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"[BEST] selected by VAL (val_rmse_cycles, val_mae_cycles)\")\n",
    "    print(f\"  seed={best_seed}, checkpoint={best_ckpt}\")\n",
    "    print(f\"[READ] {summary_path}\")\n",
    "    print(f\"[SAVE] {OUT_PNG}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abed7de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] DONE -> ./Trial10\\seed_333\\best_by_val_cycles\\paper_figures_bookstyle\\train\n",
      "[val] DONE -> ./Trial10\\seed_333\\best_by_val_cycles\\paper_figures_bookstyle\\val\n",
      "[test] DONE -> ./Trial10\\seed_333\\best_by_val_cycles\\paper_figures_bookstyle\\test\n",
      "\n",
      "ALL DONE.\n",
      "Saved under: ./Trial10\\seed_333\\best_by_val_cycles\\paper_figures_bookstyle\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# USER CONFIG (Trial10)\n",
    "# ============================================================\n",
    "TRIAL_DIR = r\"./Trial10\"              # ✅ Trial10 폴더\n",
    "SEED = 333                            # 선택된 seed\n",
    "CKPT = \"best_by_val_cycles\"           # ✅ Trial10 checkpoint: \"best_by_val_cycles\" or \"last_epoch\"\n",
    "\n",
    "SPLITS = [\"train\", \"val\", \"test\"]     # 여러 split 한번에\n",
    "\n",
    "ALPHA = 0.20\n",
    "LAMBDA_TO_PLOT = 0.60                 # α–λ 그림에 표시할 λ\n",
    "\n",
    "MAX_FILES = None                      # None=모두, 아니면 예: 10\n",
    "\n",
    "# 저장 폴더 루트\n",
    "OUT_ROOT = os.path.join(TRIAL_DIR, f\"seed_{SEED}\", CKPT, \"paper_figures_bookstyle\")\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "def safe_name(s: str) -> str:\n",
    "    return s.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "def load_cycle_seq_and_metrics(seed_dir: str, split: str):\n",
    "    \"\"\"\n",
    "    Trial10에서 export 단계가 만들어 둔 파일들:\n",
    "      - <split>_cycle_sequence_mean.csv\n",
    "      - <split>_prognostics_metrics_per_file.csv\n",
    "    위치: seed_<seed>/<ckpt>/\n",
    "    \"\"\"\n",
    "    seq_csv = os.path.join(seed_dir, f\"{split}_cycle_sequence_mean.csv\")\n",
    "    met_csv = os.path.join(seed_dir, f\"{split}_prognostics_metrics_per_file.csv\")\n",
    "\n",
    "    if not os.path.exists(seq_csv):\n",
    "        raise FileNotFoundError(f\"Missing: {seq_csv}\")\n",
    "    if not os.path.exists(met_csv):\n",
    "        raise FileNotFoundError(f\"Missing: {met_csv}\")\n",
    "\n",
    "    df_seq = pd.read_csv(seq_csv)\n",
    "    df_met = pd.read_csv(met_csv)\n",
    "    return df_seq, df_met\n",
    "\n",
    "def get_eval_segment(df_one_file: pd.DataFrame, t_s: int, t_e: int) -> pd.DataFrame:\n",
    "    df = df_one_file.sort_values(\"cycle\").copy()\n",
    "    df = df[(df[\"cycle\"] >= t_s) & (df[\"cycle\"] <= t_e)].copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# Plotters\n",
    "# ============================================================\n",
    "def plot_ph_alpha_absolute_band(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    alpha: float,\n",
    "    out_path: str,\n",
    "    ph_start: Optional[float] = None,\n",
    "    title_prefix: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    BOOK Fig.2.9(a) 스타일:\n",
    "    - PH용 α-zone = '절대 폭(평행 밴드)'\n",
    "      alphaZone = alpha * EOL_true\n",
    "      zone = RUL_true ± alphaZone\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].to_numpy()\n",
    "    y_true = df_eval[\"RUL_true\"].to_numpy()\n",
    "    y_pred = df_eval[\"RUL_pred\"].to_numpy()\n",
    "\n",
    "    last_cycle = int(df_eval[\"cycle\"].max())\n",
    "    eol_true = last_cycle + 1\n",
    "\n",
    "    alpha_zone = alpha * float(eol_true)  # 평행 밴드 폭\n",
    "    upper = y_true + alpha_zone\n",
    "    lower = y_true - alpha_zone\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, \"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, \"r\", label=\"Prediction (cycles)\")\n",
    "    plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α-zone (±α·EOL)\")\n",
    "    plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α-zone (±α·EOL)\")\n",
    "\n",
    "    if ph_start is not None and np.isfinite(ph_start):\n",
    "        plt.axvline(int(ph_start), color=\"g\", linestyle=\"-.\", label=\"PH start\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title_prefix} | BOOK-STYLE α+PH (absolute band)\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_alpha_lambda_relative_band(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    t_lambda: Optional[int],\n",
    "    out_path: str,\n",
    "    title_prefix: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    BOOK Fig.2.9(b) 스타일:\n",
    "    - α–λ는 '상대 폭(수렴 밴드)'\n",
    "      zone = RUL_true*(1±alpha), 그리고 t >= t_lambda 구간만 표시\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].to_numpy()\n",
    "    y_true = df_eval[\"RUL_true\"].to_numpy()\n",
    "    y_pred = df_eval[\"RUL_pred\"].to_numpy()\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, \"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, \"r\", label=\"Prediction (cycles)\")\n",
    "\n",
    "    if t_lambda is not None and np.isfinite(t_lambda):\n",
    "        t_lambda = int(t_lambda)\n",
    "        plt.axvline(t_lambda, color=\"g\", linestyle=\":\", label=f\"t_λ (λ={lambda_to_plot:.2f})\")\n",
    "\n",
    "        mask = x >= t_lambda\n",
    "        if np.any(mask):\n",
    "            plt.plot(x[mask], upper[mask], \"b--\", label=f\"+{alpha:.2f} α–λ zone\")\n",
    "            plt.plot(x[mask], lower[mask], \"b--\", label=f\"-{alpha:.2f} α–λ zone\")\n",
    "        else:\n",
    "            plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α zone\")\n",
    "            plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α zone\")\n",
    "    else:\n",
    "        plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α zone\")\n",
    "        plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α zone\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title_prefix} | BOOK-STYLE α–λ (relative band)\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# Main (multi-split)\n",
    "# ============================================================\n",
    "def run_for_one_split(seed_dir: str, split: str):\n",
    "    df_seq, df_met = load_cycle_seq_and_metrics(seed_dir, split)\n",
    "\n",
    "    files = df_seq[\"file\"].unique().tolist()\n",
    "    if MAX_FILES is not None:\n",
    "        files = files[:MAX_FILES]\n",
    "\n",
    "    out_dir = os.path.join(OUT_ROOT, split)  # split별 폴더\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    lam_key = f\"t_lambda_{LAMBDA_TO_PLOT:.2f}\"\n",
    "    title_prefix = f\"SEED {SEED} | {CKPT.upper()} | {split}\"\n",
    "\n",
    "    for f in files:\n",
    "        sub = df_seq[df_seq[\"file\"] == f].copy()\n",
    "        mrow = df_met[df_met[\"file\"] == f]\n",
    "        if mrow.empty:\n",
    "            continue\n",
    "        mrow = mrow.iloc[0].to_dict()\n",
    "\n",
    "        t_s = int(mrow[\"t_s\"])\n",
    "        t_e = int(mrow[\"t_e\"])\n",
    "        ph_start = mrow.get(\"t_PH_start\", np.nan)\n",
    "        t_lambda = mrow.get(lam_key, np.nan)\n",
    "\n",
    "        df_eval = get_eval_segment(sub, t_s, t_e)\n",
    "        if df_eval.empty:\n",
    "            continue\n",
    "\n",
    "        sname = safe_name(f)\n",
    "\n",
    "        out_a = os.path.join(out_dir, f\"FIG_A_BOOKSTYLE_alpha_PH__{sname}.png\")\n",
    "        plot_ph_alpha_absolute_band(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            alpha=ALPHA,\n",
    "            out_path=out_a,\n",
    "            ph_start=ph_start if np.isfinite(ph_start) else None,\n",
    "            title_prefix=title_prefix,\n",
    "        )\n",
    "\n",
    "        out_b = os.path.join(out_dir, f\"FIG_B_BOOKSTYLE_alpha_lambda__lam{LAMBDA_TO_PLOT:.2f}__{sname}.png\")\n",
    "        plot_alpha_lambda_relative_band(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            alpha=ALPHA,\n",
    "            lambda_to_plot=LAMBDA_TO_PLOT,\n",
    "            t_lambda=int(t_lambda) if np.isfinite(t_lambda) else None,\n",
    "            out_path=out_b,\n",
    "            title_prefix=title_prefix,\n",
    "        )\n",
    "\n",
    "    print(f\"[{split}] DONE -> {out_dir}\")\n",
    "\n",
    "def main():\n",
    "    seed_dir = os.path.join(TRIAL_DIR, f\"seed_{SEED}\", CKPT)\n",
    "    if not os.path.isdir(seed_dir):\n",
    "        raise FileNotFoundError(f\"Not found: {seed_dir}\")\n",
    "\n",
    "    for split in SPLITS:\n",
    "        run_for_one_split(seed_dir, split)\n",
    "\n",
    "    print(\"\\nALL DONE.\")\n",
    "    print(\"Saved under:\", OUT_ROOT)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a24a586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE. saved figures -> ./Trial10\\seed_333\\best_by_val_cycles\\paper_figures\\test_manual\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Trial10 USER CONFIG\n",
    "# =========================\n",
    "TRIAL_DIR = r\"./Trial10\"\n",
    "SEED = 333\n",
    "CKPT = \"best_by_val_cycles\"   # ✅ Trial10: \"best_by_val_cycles\" or \"last_epoch\"\n",
    "SPLIT = \"test\"                # \"train\" / \"val\" / \"test\"\n",
    "\n",
    "ALPHA = 0.20\n",
    "LAMBDA_TO_PLOT = 0.60\n",
    "MAX_FILES = 1                 # 1개만 만들기 (원하면 None)\n",
    "DPI = 200\n",
    "\n",
    "\n",
    "def _safe_name(s: str) -> str:\n",
    "    return s.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "\n",
    "def plot_alpha_ph(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    title: str,\n",
    "    alpha: float,\n",
    "    PH_start: Optional[float],\n",
    "    out_path: str,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.figure()\n",
    "\n",
    "    x = df_eval[\"cycle\"].values\n",
    "    y_true = df_eval[\"RUL_true\"].values\n",
    "    y_pred = df_eval[\"RUL_pred\"].values\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.plot(x, y_true, color=\"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, color=\"r\", label=\"Prediction (cycles)\")\n",
    "    plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} alpha accuracy zone\")\n",
    "    plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} alpha accuracy zone\")\n",
    "\n",
    "    if PH_start is not None and np.isfinite(PH_start):\n",
    "        plt.axvline(int(PH_start), color=\"g\", linestyle=\"-.\", label=\"PH start\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title}\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_alpha_lambda(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    title: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    t_lambda: Optional[int],\n",
    "    out_path: str,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].values\n",
    "    y_true = df_eval[\"RUL_true\"].values\n",
    "    y_pred = df_eval[\"RUL_pred\"].values\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, color=\"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, color=\"r\", label=\"Prediction (cycles)\")\n",
    "\n",
    "    if t_lambda is not None and np.isfinite(t_lambda):\n",
    "        t_lambda = int(t_lambda)\n",
    "        plt.axvline(t_lambda, linestyle=\":\", color=\"g\", label=f\"t_λ (λ={lambda_to_plot:.2f})\")\n",
    "        mask = x >= t_lambda\n",
    "        if np.any(mask):\n",
    "            plt.plot(x[mask], upper[mask], color=\"b\", linestyle=\"--\",\n",
    "                     label=f\"+{alpha:.2f} alpha–lambda accuracy zone\")\n",
    "            plt.plot(x[mask], lower[mask], color=\"b\", linestyle=\"--\",\n",
    "                     label=f\"-{alpha:.2f} alpha–lambda accuracy zone\")\n",
    "        else:\n",
    "            plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} α zone\")\n",
    "            plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} α zone\")\n",
    "    else:\n",
    "        plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} α zone\")\n",
    "        plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} α zone\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title}\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def make_paper_figures_for_split(\n",
    "    cycle_seq_csv: str,\n",
    "    metrics_per_file_csv: str,\n",
    "    out_fig_dir: str,\n",
    "    title_prefix: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    max_files: Optional[int] = None,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    if not os.path.exists(cycle_seq_csv):\n",
    "        raise FileNotFoundError(f\"Missing cycle seq csv: {cycle_seq_csv}\")\n",
    "    if not os.path.exists(metrics_per_file_csv):\n",
    "        raise FileNotFoundError(f\"Missing metrics csv: {metrics_per_file_csv}\")\n",
    "\n",
    "    df_seq = pd.read_csv(cycle_seq_csv)\n",
    "    dfm = pd.read_csv(metrics_per_file_csv)\n",
    "\n",
    "    files = df_seq[\"file\"].unique().tolist()\n",
    "    if max_files is not None:\n",
    "        files = files[:max_files]\n",
    "\n",
    "    os.makedirs(out_fig_dir, exist_ok=True)\n",
    "\n",
    "    lam_key = f\"t_lambda_{lambda_to_plot:.2f}\"\n",
    "\n",
    "    for f in files:\n",
    "        sub = df_seq[df_seq[\"file\"] == f].sort_values(\"cycle\").copy()\n",
    "        mrow = dfm[dfm[\"file\"] == f]\n",
    "        if mrow.empty:\n",
    "            print(f\"[WARN] metrics row missing for file={f}. skip.\")\n",
    "            continue\n",
    "        mrow = mrow.iloc[0].to_dict()\n",
    "\n",
    "        # evaluation interval\n",
    "        t_s = int(mrow.get(\"t_s\", int(sub[\"cycle\"].min())))\n",
    "        t_e = int(mrow.get(\"t_e\", int(sub[\"cycle\"].max())))\n",
    "        PH_start = mrow.get(\"t_PH_start\", np.nan)\n",
    "\n",
    "        df_eval = sub[(sub[\"cycle\"] >= t_s) & (sub[\"cycle\"] <= t_e)].copy()\n",
    "        if df_eval.empty:\n",
    "            print(f\"[WARN] empty df_eval for file={f}. skip.\")\n",
    "            continue\n",
    "\n",
    "        # t_lambda\n",
    "        t_lambda = None\n",
    "        if lam_key in mrow and np.isfinite(mrow[lam_key]):\n",
    "            t_lambda = int(mrow[lam_key])\n",
    "\n",
    "        safe = _safe_name(f)\n",
    "\n",
    "        out1 = os.path.join(out_fig_dir, f\"FIG1_alpha_PH__{safe}.png\")\n",
    "        plot_alpha_ph(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            title=f\"{title_prefix} | α+PH\",\n",
    "            alpha=alpha,\n",
    "            PH_start=PH_start if np.isfinite(PH_start) else None,\n",
    "            out_path=out1,\n",
    "            dpi=dpi,\n",
    "        )\n",
    "\n",
    "        out2 = os.path.join(out_fig_dir, f\"FIG2_alpha_lambda__lam{lambda_to_plot:.2f}__{safe}.png\")\n",
    "        plot_alpha_lambda(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            title=f\"{title_prefix} | α–λ (λ={lambda_to_plot:.2f})\",\n",
    "            alpha=alpha,\n",
    "            lambda_to_plot=lambda_to_plot,\n",
    "            t_lambda=t_lambda,\n",
    "            out_path=out2,\n",
    "            dpi=dpi,\n",
    "        )\n",
    "\n",
    "    print(f\"DONE. saved figures -> {out_fig_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ✅ Trial10 경로 자동 구성\n",
    "    seed_dir = os.path.join(TRIAL_DIR, f\"seed_{SEED}\", CKPT)\n",
    "\n",
    "    cycle_seq_csv = os.path.join(seed_dir, f\"{SPLIT}_cycle_sequence_mean.csv\")\n",
    "    metrics_csv   = os.path.join(seed_dir, f\"{SPLIT}_prognostics_metrics_per_file.csv\")\n",
    "\n",
    "    # ✅ output도 Trial10 아래로\n",
    "    out_fig_dir   = os.path.join(seed_dir, \"paper_figures\", f\"{SPLIT}_manual\")\n",
    "\n",
    "    make_paper_figures_for_split(\n",
    "        cycle_seq_csv=cycle_seq_csv,\n",
    "        metrics_per_file_csv=metrics_csv,\n",
    "        out_fig_dir=out_fig_dir,\n",
    "        title_prefix=f\"SEED {SEED} | {CKPT.upper()} | {SPLIT}\",\n",
    "        alpha=ALPHA,\n",
    "        lambda_to_plot=LAMBDA_TO_PLOT,\n",
    "        max_files=MAX_FILES,   # 1개만 만들기 / None이면 전체\n",
    "        dpi=DPI,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igbt_rnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
