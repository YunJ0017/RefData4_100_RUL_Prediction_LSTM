{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae270bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "[SEED 9819123] device=cuda\n",
      "[SEED 9819123] out=./Trial12\\seed_9819123\n",
      "==============================\n",
      "[SEED 9819123] [001/300] train_mse_norm=0.037195 | val_rmse_norm=0.168327 | val_mae_cycles=2313.958 | best_val_rmse_norm=0.168327\n",
      "[SEED 9819123] [010/300] train_mse_norm=0.017193 | val_rmse_norm=0.160237 | val_mae_cycles=2236.971 | best_val_rmse_norm=0.156716\n",
      "[SEED 9819123] [020/300] train_mse_norm=0.016542 | val_rmse_norm=0.159898 | val_mae_cycles=2190.030 | best_val_rmse_norm=0.156070\n",
      "[SEED 9819123] [030/300] train_mse_norm=0.015623 | val_rmse_norm=0.159811 | val_mae_cycles=2185.266 | best_val_rmse_norm=0.156070\n",
      "[SEED 9819123] [040/300] train_mse_norm=0.006460 | val_rmse_norm=0.174910 | val_mae_cycles=2316.268 | best_val_rmse_norm=0.156070\n",
      "[SEED 9819123] Early stopping at epoch 42.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_55348\\3332692613.py:784: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 9819123] best_by_val_norm: TEST mae_cycles=1145.277 | rmse_cycles=1648.851 | rmse_norm=0.113897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_55348\\3332692613.py:784: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 9819123] last_epoch: TEST mae_cycles=1348.384 | rmse_cycles=2030.520 | rmse_norm=0.137769\n",
      "\n",
      "==============================\n",
      "[SEED 111] device=cuda\n",
      "[SEED 111] out=./Trial12\\seed_111\n",
      "==============================\n",
      "[SEED 111] [001/300] train_mse_norm=0.044603 | val_rmse_norm=0.144347 | val_mae_cycles=2674.129 | best_val_rmse_norm=0.144347\n",
      "[SEED 111] [010/300] train_mse_norm=0.018686 | val_rmse_norm=0.143380 | val_mae_cycles=2783.269 | best_val_rmse_norm=0.141782\n",
      "[SEED 111] [020/300] train_mse_norm=0.017691 | val_rmse_norm=0.139825 | val_mae_cycles=2696.613 | best_val_rmse_norm=0.136842\n",
      "[SEED 111] [030/300] train_mse_norm=0.017481 | val_rmse_norm=0.137595 | val_mae_cycles=2611.991 | best_val_rmse_norm=0.135146\n",
      "[SEED 111] [040/300] train_mse_norm=0.015118 | val_rmse_norm=0.160148 | val_mae_cycles=3050.392 | best_val_rmse_norm=0.135146\n",
      "[SEED 111] [050/300] train_mse_norm=0.003178 | val_rmse_norm=0.164575 | val_mae_cycles=3192.712 | best_val_rmse_norm=0.135146\n",
      "[SEED 111] Early stopping at epoch 52.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_55348\\3332692613.py:784: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 111] best_by_val_norm: TEST mae_cycles=1756.050 | rmse_cycles=2758.003 | rmse_norm=0.145836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_55348\\3332692613.py:784: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 111] last_epoch: TEST mae_cycles=1892.860 | rmse_cycles=3036.065 | rmse_norm=0.165161\n",
      "\n",
      "==============================\n",
      "[SEED 222] device=cuda\n",
      "[SEED 222] out=./Trial12\\seed_222\n",
      "==============================\n",
      "[SEED 222] [001/300] train_mse_norm=0.035482 | val_rmse_norm=0.157786 | val_mae_cycles=1749.332 | best_val_rmse_norm=0.157786\n",
      "[SEED 222] [010/300] train_mse_norm=0.018678 | val_rmse_norm=0.138862 | val_mae_cycles=1542.725 | best_val_rmse_norm=0.138862\n",
      "[SEED 222] [020/300] train_mse_norm=0.018176 | val_rmse_norm=0.137558 | val_mae_cycles=1543.917 | best_val_rmse_norm=0.137128\n",
      "[SEED 222] [030/300] train_mse_norm=0.016003 | val_rmse_norm=0.146610 | val_mae_cycles=1572.141 | best_val_rmse_norm=0.137128\n",
      "[SEED 222] [040/300] train_mse_norm=0.004161 | val_rmse_norm=0.171479 | val_mae_cycles=1763.326 | best_val_rmse_norm=0.137128\n",
      "[SEED 222] Early stopping at epoch 44.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_55348\\3332692613.py:784: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 222] best_by_val_norm: TEST mae_cycles=2127.980 | rmse_cycles=3080.341 | rmse_norm=0.127276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_55348\\3332692613.py:784: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 222] last_epoch: TEST mae_cycles=2524.869 | rmse_cycles=3736.116 | rmse_norm=0.156834\n",
      "\n",
      "==============================\n",
      "[SEED 333] device=cuda\n",
      "[SEED 333] out=./Trial12\\seed_333\n",
      "==============================\n",
      "[SEED 333] [001/300] train_mse_norm=0.038998 | val_rmse_norm=0.131317 | val_mae_cycles=1559.437 | best_val_rmse_norm=0.131317\n",
      "[SEED 333] [010/300] train_mse_norm=0.019226 | val_rmse_norm=0.123491 | val_mae_cycles=1492.631 | best_val_rmse_norm=0.122642\n",
      "[SEED 333] [020/300] train_mse_norm=0.018568 | val_rmse_norm=0.125220 | val_mae_cycles=1508.860 | best_val_rmse_norm=0.121050\n",
      "[SEED 333] [030/300] train_mse_norm=0.015282 | val_rmse_norm=0.134721 | val_mae_cycles=1595.911 | best_val_rmse_norm=0.121050\n",
      "[SEED 333] [040/300] train_mse_norm=0.002750 | val_rmse_norm=0.161771 | val_mae_cycles=1926.301 | best_val_rmse_norm=0.121050\n",
      "[SEED 333] Early stopping at epoch 43.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_55348\\3332692613.py:784: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 333] best_by_val_norm: TEST mae_cycles=975.492 | rmse_cycles=1563.467 | rmse_norm=0.145153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_55348\\3332692613.py:784: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 333] last_epoch: TEST mae_cycles=1000.572 | rmse_cycles=1688.126 | rmse_norm=0.163151\n",
      "\n",
      "==============================\n",
      "[SEED 444] device=cuda\n",
      "[SEED 444] out=./Trial12\\seed_444\n",
      "==============================\n",
      "[SEED 444] [001/300] train_mse_norm=0.037951 | val_rmse_norm=0.154871 | val_mae_cycles=2110.791 | best_val_rmse_norm=0.154871\n",
      "[SEED 444] [010/300] train_mse_norm=0.017869 | val_rmse_norm=0.143869 | val_mae_cycles=2085.898 | best_val_rmse_norm=0.140337\n",
      "[SEED 444] [020/300] train_mse_norm=0.017419 | val_rmse_norm=0.143148 | val_mae_cycles=2100.915 | best_val_rmse_norm=0.138707\n",
      "[SEED 444] [030/300] train_mse_norm=0.015903 | val_rmse_norm=0.143042 | val_mae_cycles=2079.419 | best_val_rmse_norm=0.138707\n",
      "[SEED 444] [040/300] train_mse_norm=0.003682 | val_rmse_norm=0.170817 | val_mae_cycles=2471.257 | best_val_rmse_norm=0.138707\n",
      "[SEED 444] Early stopping at epoch 46.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_55348\\3332692613.py:784: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 444] best_by_val_norm: TEST mae_cycles=1461.894 | rmse_cycles=2095.544 | rmse_norm=0.142121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11HOME_AHCI\\AppData\\Local\\Temp\\ipykernel_55348\\3332692613.py:784: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEED 444] last_epoch: TEST mae_cycles=1644.095 | rmse_cycles=2493.644 | rmse_norm=0.161851\n",
      "=== WIN-RATE SUMMARY (TEST; lower is better) ===\n",
      "- test_mae_cycles: last wins=0, best wins=5, ties=0 | mean(last-best)=188.817554, std(last-best)=120.877341\n",
      "- test_rmse_cycles: last wins=0, best wins=5, ties=0 | mean(last-best)=367.652850, std(last-best)=173.902428\n",
      "- test_mae_norm: last wins=0, best wins=5, ties=0 | mean(last-best)=0.012481, std(last-best)=0.003271\n",
      "- test_rmse_norm: last wins=0, best wins=5, ties=0 | mean(last-best)=0.022097, std(last-best)=0.004217\n",
      "\n",
      "=== MEAN ± STD across seeds (TEST) ===\n",
      "                 test_mae_cycles             test_rmse_cycles              \\\n",
      "                            mean         std             mean         std   \n",
      "checkpoint                                                                  \n",
      "best_by_val_norm     1493.338609  464.243350       2229.24131  671.182331   \n",
      "last_epoch           1682.156163  577.055242       2596.89416  813.633666   \n",
      "\n",
      "                 test_mae_norm           test_rmse_norm            \n",
      "                          mean       std           mean       std  \n",
      "checkpoint                                                         \n",
      "best_by_val_norm      0.105349  0.011142       0.134857  0.013929  \n",
      "last_epoch            0.117830  0.009237       0.156953  0.011156  \n",
      "\n",
      "Saved:\n",
      " - ./Trial12\\summary_across_seeds.csv\n",
      " - ./Trial12\\win_rate_summary.csv\n",
      " - ./Trial12\\win_rate_summary.txt\n",
      "\n",
      "DONE. Check Trial12 folder:\n",
      " - per seed results: Trial12/seed_<seed>/...\n",
      " - figures (paper-style): seed_<seed>/<ckpt>/paper_figures/<split>/\n",
      " - cycle sequence mean CSV: <ckpt>/<split>_cycle_sequence_mean.csv\n",
      " - PH/α–λ metrics CSV: <ckpt>/<split>_prognostics_metrics_per_file.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0) Reproducibility\n",
    "# ============================================================\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Config (Trial12: Trial9 + dvce smoothing + last-k pooling)\n",
    "# ============================================================\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_dir: str = r\"C:\\Users\\11HOME_AHCI\\Desktop\\PoF\\Winter 2026\\Ref Data4\\100\"\n",
    "    out_dir: str = r\"./Trial12\"   # ✅ Trial12로 변경\n",
    "\n",
    "    # seeds to sweep\n",
    "    seeds: Tuple[int, ...] = (9819123, 111, 222, 333, 444)\n",
    "\n",
    "    # sliding window\n",
    "    seq_len: int = 100\n",
    "    stride: int = 5\n",
    "    pred_horizon: int = 0\n",
    "\n",
    "    # split by FILE\n",
    "    train_ratio: float = 0.7\n",
    "    val_ratio: float = 0.2\n",
    "    test_ratio: float = 0.1\n",
    "\n",
    "    # training\n",
    "    batch_size: int = 512\n",
    "    epochs: int = 300\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 0.0\n",
    "    patience: int = 30\n",
    "    grad_clip: float = 1.0\n",
    "\n",
    "    # model\n",
    "    hidden_size: int = 512\n",
    "    num_layers: int = 2\n",
    "    dropout: float = 0.2\n",
    "\n",
    "    # ✅ Trial12: last-k pooling\n",
    "    last_k_pool: int = 20  # head input = mean(out[:, -k:, :])\n",
    "\n",
    "    # ✅ Trial12: dvce smoothing / robust difference params\n",
    "    dvce_ma_window: int = 5   # MA window size (causal)\n",
    "    dvce_lag: int = 5         # dv[t] = MA[t] - MA[t-lag]\n",
    "\n",
    "    # output controls\n",
    "    save_figures: bool = True\n",
    "    max_files_to_plot: Optional[int] = None  # None=all\n",
    "    num_workers: int = 0\n",
    "\n",
    "    # ===========================\n",
    "    # Trial9: Evaluation settings\n",
    "    # ===========================\n",
    "    alpha: float = 0.20\n",
    "    ph_consecutive_m: int = 5\n",
    "    rep_method: str = \"mean\"\n",
    "\n",
    "    lambdas: Tuple[float, ...] = (0.2, 0.4, 0.6, 0.8)\n",
    "    lambda_to_plot: float = 0.6\n",
    "\n",
    "    eps_rul: float = 1e-8\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Data utils\n",
    "# ============================================================\n",
    "def list_csv_files(data_dir: str) -> List[Path]:\n",
    "    p = Path(data_dir)\n",
    "    files = sorted([f for f in p.glob(\"*.csv\") if f.is_file()])\n",
    "    if len(files) == 0:\n",
    "        raise FileNotFoundError(f\"No CSV files found in: {data_dir}\")\n",
    "    return files\n",
    "\n",
    "\n",
    "def read_one_csv(csv_path: Path) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    df = pd.read_csv(csv_path, header=None)\n",
    "    if df.shape[1] < 2:\n",
    "        raise ValueError(f\"{csv_path.name}: expected at least 2 columns, got {df.shape[1]}\")\n",
    "    vce = df.iloc[:, 0].astype(np.float32).to_numpy()\n",
    "    rul = df.iloc[:, 1].astype(np.float32).to_numpy()\n",
    "\n",
    "    if len(vce) != len(rul):\n",
    "        raise ValueError(f\"{csv_path.name}: length mismatch vce={len(vce)}, rul={len(rul)}\")\n",
    "    if len(vce) < 5:\n",
    "        raise ValueError(f\"{csv_path.name}: too short sequence length={len(vce)}\")\n",
    "    return vce, rul\n",
    "\n",
    "\n",
    "def split_files(\n",
    "    files: List[Path],\n",
    "    train_ratio: float,\n",
    "    val_ratio: float,\n",
    "    test_ratio: float,\n",
    "    seed: int\n",
    ") -> Dict[str, List[Path]]:\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-9\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "    files_shuffled = files[:]\n",
    "    rng.shuffle(files_shuffled)\n",
    "\n",
    "    n = len(files_shuffled)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "\n",
    "    train_files = files_shuffled[:n_train]\n",
    "    val_files = files_shuffled[n_train:n_train + n_val]\n",
    "    test_files = files_shuffled[n_train + n_val:]\n",
    "\n",
    "    return {\"train\": train_files, \"val\": val_files, \"test\": test_files}\n",
    "\n",
    "\n",
    "def causal_moving_average(x: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Causal MA: ma[t] = mean(x[max(0,t-window+1):t+1])\n",
    "    Leakage 없이 현재/과거만 사용.\n",
    "    \"\"\"\n",
    "    if window <= 1:\n",
    "        return x.astype(np.float32)\n",
    "\n",
    "    x = x.astype(np.float32)\n",
    "    csum = np.cumsum(x, dtype=np.float64)\n",
    "    out = np.empty_like(x, dtype=np.float32)\n",
    "    for t in range(len(x)):\n",
    "        s = max(0, t - window + 1)\n",
    "        tot = csum[t] - (csum[s - 1] if s > 0 else 0.0)\n",
    "        out[t] = float(tot / (t - s + 1))\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_dvce_smooth(vce: np.ndarray, ma_window: int, lag: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    ✅ Trial12 robust dvce:\n",
    "      ma = causal MA(vce)\n",
    "      dv[t] = ma[t] - ma[t-lag]   (t<lag -> 0)\n",
    "    \"\"\"\n",
    "    ma = causal_moving_average(vce, ma_window)\n",
    "    dv = np.zeros_like(ma, dtype=np.float32)\n",
    "    if lag <= 0:\n",
    "        # fallback: first difference on MA (still smoother than raw)\n",
    "        dv[1:] = ma[1:] - ma[:-1]\n",
    "        return dv\n",
    "\n",
    "    dv[lag:] = ma[lag:] - ma[:-lag]\n",
    "    return dv\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Dataset\n",
    "# ============================================================\n",
    "class WindowedRULDatasetNorm2F(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_list: List[Path],\n",
    "        seq_len: int,\n",
    "        stride: int,\n",
    "        pred_horizon: int,\n",
    "        scaler_x: StandardScaler = None,\n",
    "        fit_scaler: bool = False,\n",
    "        # ✅ Trial12: dvce smoothing params\n",
    "        dvce_ma_window: int = 5,\n",
    "        dvce_lag: int = 5,\n",
    "    ):\n",
    "        self.file_list = file_list\n",
    "        self.seq_len = seq_len\n",
    "        self.stride = stride\n",
    "        self.pred_horizon = pred_horizon\n",
    "        self.scaler_x = scaler_x if scaler_x is not None else StandardScaler()\n",
    "        self.dvce_ma_window = dvce_ma_window\n",
    "        self.dvce_lag = dvce_lag\n",
    "\n",
    "        # store: (name, X2(T,2), rul(T,), rul0)\n",
    "        self.series: List[Tuple[str, np.ndarray, np.ndarray, float]] = []\n",
    "        for fp in self.file_list:\n",
    "            vce, rul = read_one_csv(fp)\n",
    "            rul0 = float(rul[0])\n",
    "            if rul0 <= 0:\n",
    "                raise ValueError(f\"{fp.name}: RUL0 must be > 0, got {rul0}\")\n",
    "\n",
    "            dv = compute_dvce_smooth(vce, ma_window=self.dvce_ma_window, lag=self.dvce_lag)\n",
    "            x2 = np.stack([vce.astype(np.float32), dv.astype(np.float32)], axis=1).astype(np.float32)  # (T,2)\n",
    "            self.series.append((fp.name, x2, rul.astype(np.float32), rul0))\n",
    "\n",
    "        if fit_scaler:\n",
    "            all_x = np.concatenate([x2 for _, x2, _, _ in self.series], axis=0)\n",
    "            self.scaler_x.fit(all_x)\n",
    "\n",
    "        # window index\n",
    "        self.index: List[Tuple[int, int]] = []\n",
    "        for fi, (_name, x2, _rul, _rul0) in enumerate(self.series):\n",
    "            T = x2.shape[0]\n",
    "            last_start = T - (seq_len + pred_horizon)\n",
    "            if last_start < 0:\n",
    "                continue\n",
    "            for s in range(0, last_start + 1, stride):\n",
    "                self.index.append((fi, s))\n",
    "\n",
    "        if len(self.index) == 0:\n",
    "            raise ValueError(\"No windows were created. Check seq_len/pred_horizon vs file lengths.\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        fi, s = self.index[idx]\n",
    "        name, x2, rul, rul0 = self.series[fi]\n",
    "\n",
    "        x = x2[s:s + self.seq_len, :]\n",
    "        y_idx = s + self.seq_len - 1 + self.pred_horizon\n",
    "        y_cycles = float(rul[y_idx])\n",
    "        y_norm = np.array([y_cycles / rul0], dtype=np.float32)\n",
    "\n",
    "        x = self.scaler_x.transform(x).astype(np.float32)\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x),\n",
    "            torch.from_numpy(y_norm),\n",
    "            name,\n",
    "            torch.tensor(s, dtype=torch.long),\n",
    "            torch.tensor(y_cycles, dtype=torch.float32),\n",
    "            torch.tensor(rul0, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Model (Trial12: last-k pooling)\n",
    "# ============================================================\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int, dropout: float, last_k_pool: int = 20):\n",
    "        super().__init__()\n",
    "        self.last_k_pool = int(last_k_pool)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 2, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # (B,T,H)\n",
    "        k = self.last_k_pool\n",
    "        if k is None or k <= 1:\n",
    "            pooled = out[:, -1, :]\n",
    "        else:\n",
    "            k = min(k, out.shape[1])\n",
    "            pooled = out[:, -k:, :].mean(dim=1)  # ✅ last-k pooling\n",
    "        return self.head(pooled)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Basic Eval + Save window-level predictions\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def evaluate_basic(model, loader, device) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "\n",
    "    mae_norm_list, mse_norm_list = [], []\n",
    "    mae_cyc_list, mse_cyc_list = [], []\n",
    "\n",
    "    for x, y_norm, _name, _s, y_cycles, rul0 in loader:\n",
    "        x = x.to(device)\n",
    "        y_norm = y_norm.to(device)\n",
    "        y_cycles = y_cycles.to(device).view(-1, 1)\n",
    "        rul0 = rul0.to(device).view(-1, 1)\n",
    "\n",
    "        pred_norm = model(x)\n",
    "\n",
    "        err_norm = pred_norm - y_norm\n",
    "        mae_norm_list.append(torch.mean(torch.abs(err_norm)).item())\n",
    "        mse_norm_list.append(torch.mean(err_norm ** 2).item())\n",
    "\n",
    "        pred_cycles = pred_norm * rul0\n",
    "        err_cyc = pred_cycles - y_cycles\n",
    "        mae_cyc_list.append(torch.mean(torch.abs(err_cyc)).item())\n",
    "        mse_cyc_list.append(torch.mean(err_cyc ** 2).item())\n",
    "\n",
    "    return {\n",
    "        \"mae_norm\": float(np.mean(mae_norm_list)) if mae_norm_list else float(\"nan\"),\n",
    "        \"rmse_norm\": float(np.sqrt(np.mean(mse_norm_list))) if mse_norm_list else float(\"nan\"),\n",
    "        \"mae_cycles\": float(np.mean(mae_cyc_list)) if mae_cyc_list else float(\"nan\"),\n",
    "        \"rmse_cycles\": float(np.sqrt(np.mean(mse_cyc_list))) if mse_cyc_list else float(\"nan\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_predictions_windows_csv(model, loader, device, out_csv: str, seq_len: int) -> None:\n",
    "    model.eval()\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    for x, y_norm, name, s, y_cycles, rul0 in loader:\n",
    "        x = x.to(device)\n",
    "        y_norm = y_norm.to(device)\n",
    "        y_cycles = y_cycles.to(device).view(-1, 1)\n",
    "        rul0 = rul0.to(device).view(-1, 1)\n",
    "\n",
    "        pred_norm = model(x)\n",
    "        pred_cycles = pred_norm * rul0\n",
    "\n",
    "        pred_norm_np = pred_norm.cpu().numpy().reshape(-1)\n",
    "        y_norm_np = y_norm.cpu().numpy().reshape(-1)\n",
    "        pred_cyc_np = pred_cycles.cpu().numpy().reshape(-1)\n",
    "        y_cyc_np = y_cycles.cpu().numpy().reshape(-1)\n",
    "\n",
    "        rul0_np = rul0.cpu().numpy().reshape(-1)\n",
    "        s_np = s.cpu().numpy().reshape(-1)\n",
    "        name_list = list(name)\n",
    "\n",
    "        for i in range(len(pred_norm_np)):\n",
    "            rows.append({\n",
    "                \"file\": name_list[i],\n",
    "                \"start_idx\": int(s_np[i]),\n",
    "                \"cycle\": int(s_np[i] + (seq_len - 1)),\n",
    "                \"rul0\": float(rul0_np[i]),\n",
    "                \"RUL_true\": float(y_cyc_np[i]),\n",
    "                \"RUL_pred\": float(pred_cyc_np[i]),\n",
    "                \"RUL_true_norm\": float(y_norm_np[i]),\n",
    "                \"RUL_pred_norm\": float(pred_norm_np[i]),\n",
    "            })\n",
    "\n",
    "    pd.DataFrame(rows).to_csv(out_csv, index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Window -> Cycle sequence (mean representative)\n",
    "# ============================================================\n",
    "def windows_to_cycle_sequence_mean(windows_csv: str) -> pd.DataFrame:\n",
    "    dfw = pd.read_csv(windows_csv)\n",
    "    if dfw.empty:\n",
    "        raise ValueError(f\"Empty windows csv: {windows_csv}\")\n",
    "\n",
    "    g = dfw.groupby([\"file\", \"cycle\"], as_index=False).agg(\n",
    "        rul0=(\"rul0\", \"first\"),\n",
    "        RUL_true=(\"RUL_true\", \"mean\"),\n",
    "        RUL_pred=(\"RUL_pred\", \"mean\"),\n",
    "        n_windows=(\"RUL_pred\", \"count\"),\n",
    "    )\n",
    "    return g\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) Prognostics metrics: Relative Error / RA / CRA / PH / α–λ / Convergence\n",
    "# ============================================================\n",
    "def compute_metrics_for_one_file(\n",
    "    df_seq_one_file: pd.DataFrame,\n",
    "    seq_len: int,\n",
    "    alpha: float,\n",
    "    ph_consecutive_m: int,\n",
    "    lambdas: Tuple[float, ...],\n",
    "    eps_rul: float,\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    df = df_seq_one_file.sort_values(\"cycle\").reset_index(drop=True).copy()\n",
    "\n",
    "    t_s = seq_len - 1\n",
    "    last_cycle = int(df[\"cycle\"].max())\n",
    "    EOL_true = last_cycle + 1\n",
    "    t_e = EOL_true - 1\n",
    "\n",
    "    df_eval = df[(df[\"cycle\"] >= t_s) & (df[\"cycle\"] <= t_e)].copy()\n",
    "    df_eval.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if df_eval.empty:\n",
    "        summary = {\n",
    "            \"t_s\": t_s, \"t_e\": t_e, \"EOL_true\": EOL_true,\n",
    "            \"PH\": np.nan, \"t_PH_start\": np.nan,\n",
    "            \"CRA\": np.nan, \"Convergence_cycles\": np.nan,\n",
    "        }\n",
    "        for lam in lambdas:\n",
    "            summary[f\"t_lambda_{lam:.2f}\"] = np.nan\n",
    "            summary[f\"alpha_lambda_ok_{lam:.2f}\"] = np.nan\n",
    "        return df_eval, summary\n",
    "\n",
    "    denom = np.maximum(np.abs(df_eval[\"RUL_true\"].values), eps_rul)\n",
    "    rel_err = np.abs(df_eval[\"RUL_true\"].values - df_eval[\"RUL_pred\"].values) / denom\n",
    "    RA = 1.0 - rel_err\n",
    "\n",
    "    df_eval[\"rel_err\"] = rel_err\n",
    "    df_eval[\"RA\"] = RA\n",
    "    df_eval[\"in_alpha\"] = df_eval[\"rel_err\"] <= alpha\n",
    "\n",
    "    CRA = float(np.mean(df_eval[\"RA\"].values))\n",
    "\n",
    "    flags = df_eval[\"in_alpha\"].values.astype(np.int32)\n",
    "    t_PH_start = np.nan\n",
    "    if len(flags) >= ph_consecutive_m:\n",
    "        run = 0\n",
    "        for i, ok in enumerate(flags):\n",
    "            if ok:\n",
    "                run += 1\n",
    "                if run >= ph_consecutive_m:\n",
    "                    start_i = i - ph_consecutive_m + 1\n",
    "                    t_PH_start = int(df_eval.loc[start_i, \"cycle\"])\n",
    "                    break\n",
    "            else:\n",
    "                run = 0\n",
    "\n",
    "    if np.isfinite(t_PH_start):\n",
    "        PH = float(EOL_true - t_PH_start)\n",
    "        Convergence_cycles = float(t_PH_start - t_s)\n",
    "    else:\n",
    "        PH = np.nan\n",
    "        Convergence_cycles = np.nan\n",
    "\n",
    "    rul0 = float(df_eval[\"rul0\"].iloc[0])\n",
    "    lam_results = {}\n",
    "    for lam in lambdas:\n",
    "        target_rul = (1.0 - float(lam)) * rul0\n",
    "        idx = int(np.argmin(np.abs(df_eval[\"RUL_true\"].values - target_rul)))\n",
    "        t_lam = int(df_eval.loc[idx, \"cycle\"])\n",
    "        ok = bool(df_eval.loc[idx, \"rel_err\"] <= alpha)\n",
    "\n",
    "        lam_results[f\"t_lambda_{lam:.2f}\"] = t_lam\n",
    "        lam_results[f\"alpha_lambda_ok_{lam:.2f}\"] = int(ok)\n",
    "\n",
    "    summary = {\n",
    "        \"t_s\": int(t_s),\n",
    "        \"t_e\": int(t_e),\n",
    "        \"EOL_true\": int(EOL_true),\n",
    "        \"alpha\": float(alpha),\n",
    "        \"ph_consecutive_m\": int(ph_consecutive_m),\n",
    "        \"CRA\": CRA,\n",
    "        \"t_PH_start\": t_PH_start if np.isfinite(t_PH_start) else np.nan,\n",
    "        \"PH\": PH,\n",
    "        \"Convergence_cycles\": Convergence_cycles,\n",
    "        **lam_results\n",
    "    }\n",
    "    return df_eval, summary\n",
    "\n",
    "\n",
    "def compute_metrics_from_windows_csv(\n",
    "    windows_csv: str,\n",
    "    seq_len: int,\n",
    "    alpha: float,\n",
    "    ph_consecutive_m: int,\n",
    "    lambdas: Tuple[float, ...],\n",
    "    eps_rul: float,\n",
    "    out_dir: str,\n",
    "    split_name: str,\n",
    ") -> Tuple[str, str]:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    df_seq = windows_to_cycle_sequence_mean(windows_csv)\n",
    "    seq_path = os.path.join(out_dir, f\"{split_name}_cycle_sequence_mean.csv\")\n",
    "    df_seq.to_csv(seq_path, index=False)\n",
    "\n",
    "    rows = []\n",
    "    for f in df_seq[\"file\"].unique():\n",
    "        sub = df_seq[df_seq[\"file\"] == f].copy()\n",
    "        _df_eval, summary = compute_metrics_for_one_file(\n",
    "            df_seq_one_file=sub,\n",
    "            seq_len=seq_len,\n",
    "            alpha=alpha,\n",
    "            ph_consecutive_m=ph_consecutive_m,\n",
    "            lambdas=lambdas,\n",
    "            eps_rul=eps_rul,\n",
    "        )\n",
    "        summary[\"file\"] = f\n",
    "        rows.append(summary)\n",
    "\n",
    "    dfm = pd.DataFrame(rows)\n",
    "    metrics_path = os.path.join(out_dir, f\"{split_name}_prognostics_metrics_per_file.csv\")\n",
    "    dfm.to_csv(metrics_path, index=False)\n",
    "\n",
    "    return seq_path, metrics_path\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) Plotters (2 figures)\n",
    "# ============================================================\n",
    "def _safe_name(s: str) -> str:\n",
    "    return s.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "\n",
    "def plot_alpha_ph(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    title: str,\n",
    "    alpha: float,\n",
    "    PH_start: Optional[float],\n",
    "    out_path: str,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.figure()\n",
    "\n",
    "    x = df_eval[\"cycle\"].values\n",
    "    y_true = df_eval[\"RUL_true\"].values\n",
    "    y_pred = df_eval[\"RUL_pred\"].values\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.plot(x, y_true, color=\"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, color=\"r\", label=\"Prediction (cycles)\")\n",
    "    plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} alpha accuracy zone\")\n",
    "    plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} alpha accuracy zone\")\n",
    "\n",
    "    if PH_start is not None and np.isfinite(PH_start):\n",
    "        plt.axvline(int(PH_start), color=\"g\", linestyle=\"-.\", label=\"PH start\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title}\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_alpha_lambda(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    title: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    t_lambda: Optional[int],\n",
    "    out_path: str,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].values\n",
    "    y_true = df_eval[\"RUL_true\"].values\n",
    "    y_pred = df_eval[\"RUL_pred\"].values\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, color=\"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, color=\"r\", label=\"Prediction (cycles)\")\n",
    "\n",
    "    if t_lambda is not None and np.isfinite(t_lambda):\n",
    "        t_lambda = int(t_lambda)\n",
    "        plt.axvline(t_lambda, linestyle=\":\", color=\"g\", label=f\"t_λ (λ={lambda_to_plot:.2f})\")\n",
    "\n",
    "        mask = x >= t_lambda\n",
    "        if np.any(mask):\n",
    "            plt.plot(x[mask], upper[mask], color=\"b\", linestyle=\"--\",\n",
    "                     label=f\"+{alpha:.2f} alpha–lambda accuracy zone\")\n",
    "            plt.plot(x[mask], lower[mask], color=\"b\", linestyle=\"--\",\n",
    "                     label=f\"-{alpha:.2f} alpha–lambda accuracy zone\")\n",
    "        else:\n",
    "            plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} α zone\")\n",
    "            plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} α zone\")\n",
    "    else:\n",
    "        plt.plot(x, upper, color=\"b\", linestyle=\"--\", label=f\"+{alpha:.2f} α zone\")\n",
    "        plt.plot(x, lower, color=\"b\", linestyle=\"--\", label=f\"-{alpha:.2f} α zone\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title}\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def make_paper_figures_for_split(\n",
    "    cycle_seq_csv: str,\n",
    "    metrics_per_file_csv: str,\n",
    "    out_fig_dir: str,\n",
    "    title_prefix: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    max_files: Optional[int] = None,\n",
    "    dpi: int = 200,\n",
    ") -> None:\n",
    "    df_seq = pd.read_csv(cycle_seq_csv)\n",
    "    dfm = pd.read_csv(metrics_per_file_csv)\n",
    "\n",
    "    files = df_seq[\"file\"].unique().tolist()\n",
    "    if max_files is not None:\n",
    "        files = files[:max_files]\n",
    "\n",
    "    os.makedirs(out_fig_dir, exist_ok=True)\n",
    "    lam_key = f\"t_lambda_{lambda_to_plot:.2f}\"\n",
    "\n",
    "    for f in files:\n",
    "        sub = df_seq[df_seq[\"file\"] == f].sort_values(\"cycle\").copy()\n",
    "        mrow = dfm[dfm[\"file\"] == f]\n",
    "        if mrow.empty:\n",
    "            continue\n",
    "        mrow = mrow.iloc[0].to_dict()\n",
    "\n",
    "        t_s = int(mrow[\"t_s\"])\n",
    "        t_e = int(mrow[\"t_e\"])\n",
    "        PH_start = mrow.get(\"t_PH_start\", np.nan)\n",
    "\n",
    "        df_eval = sub[(sub[\"cycle\"] >= t_s) & (sub[\"cycle\"] <= t_e)].copy()\n",
    "        if df_eval.empty:\n",
    "            continue\n",
    "\n",
    "        t_lambda = None\n",
    "        if lam_key in mrow and np.isfinite(mrow[lam_key]):\n",
    "            t_lambda = int(mrow[lam_key])\n",
    "\n",
    "        safe = _safe_name(f)\n",
    "\n",
    "        out1 = os.path.join(out_fig_dir, f\"FIG1_alpha_PH__{safe}.png\")\n",
    "        plot_alpha_ph(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            title=f\"{title_prefix} | α+PH\",\n",
    "            alpha=alpha,\n",
    "            PH_start=PH_start if np.isfinite(PH_start) else None,\n",
    "            out_path=out1,\n",
    "            dpi=dpi,\n",
    "        )\n",
    "\n",
    "        out2 = os.path.join(out_fig_dir, f\"FIG2_alpha_lambda__lam{lambda_to_plot:.2f}__{safe}.png\")\n",
    "        plot_alpha_lambda(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            title=f\"{title_prefix} | α–λ (λ={lambda_to_plot:.2f})\",\n",
    "            alpha=alpha,\n",
    "            lambda_to_plot=lambda_to_plot,\n",
    "            t_lambda=t_lambda,\n",
    "            out_path=out2,\n",
    "            dpi=dpi,\n",
    "        )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9) One seed run (train + export best/last + metrics)\n",
    "# ============================================================\n",
    "def run_one_seed(cfg: Config, seed: int) -> Dict[str, Any]:\n",
    "    set_seed(seed)\n",
    "\n",
    "    seed_dir = os.path.join(cfg.out_dir, f\"seed_{seed}\")\n",
    "    os.makedirs(seed_dir, exist_ok=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"[SEED {seed}] device={device}\")\n",
    "    print(f\"[SEED {seed}] out={seed_dir}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    files = list_csv_files(cfg.data_dir)\n",
    "    splits = split_files(files, cfg.train_ratio, cfg.val_ratio, cfg.test_ratio, seed)\n",
    "\n",
    "    for k in [\"train\", \"val\", \"test\"]:\n",
    "        pd.Series([p.name for p in splits[k]]).to_csv(\n",
    "            os.path.join(seed_dir, f\"{k}_files.csv\"), index=False, header=False\n",
    "        )\n",
    "\n",
    "    scaler_x = StandardScaler()\n",
    "    train_ds = WindowedRULDatasetNorm2F(\n",
    "        splits[\"train\"], cfg.seq_len, cfg.stride, cfg.pred_horizon,\n",
    "        scaler_x=scaler_x, fit_scaler=True,\n",
    "        dvce_ma_window=cfg.dvce_ma_window, dvce_lag=cfg.dvce_lag\n",
    "    )\n",
    "    val_ds = WindowedRULDatasetNorm2F(\n",
    "        splits[\"val\"], cfg.seq_len, cfg.stride, cfg.pred_horizon,\n",
    "        scaler_x=train_ds.scaler_x, fit_scaler=False,\n",
    "        dvce_ma_window=cfg.dvce_ma_window, dvce_lag=cfg.dvce_lag\n",
    "    )\n",
    "    test_ds = WindowedRULDatasetNorm2F(\n",
    "        splits[\"test\"], cfg.seq_len, cfg.stride, cfg.pred_horizon,\n",
    "        scaler_x=train_ds.scaler_x, fit_scaler=False,\n",
    "        dvce_ma_window=cfg.dvce_ma_window, dvce_lag=cfg.dvce_lag\n",
    "    )\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"feature\": [\"min_vce\", \"d_min_vce_smooth\"],\n",
    "        \"mean\": train_ds.scaler_x.mean_.ravel(),\n",
    "        \"std\": np.sqrt(train_ds.scaler_x.var_).ravel(),\n",
    "        \"dvce_ma_window\": [cfg.dvce_ma_window, cfg.dvce_ma_window],\n",
    "        \"dvce_lag\": [cfg.dvce_lag, cfg.dvce_lag],\n",
    "    }).to_csv(os.path.join(seed_dir, \"scaler_x_mean_std.csv\"), index=False)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "\n",
    "    train_eval = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "    val_eval = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "    test_eval = DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "\n",
    "    model = LSTMRegressor(\n",
    "        input_size=2,\n",
    "        hidden_size=cfg.hidden_size,\n",
    "        num_layers=cfg.num_layers,\n",
    "        dropout=cfg.dropout,\n",
    "        last_k_pool=cfg.last_k_pool,\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "    best_by_val_norm = float(\"inf\")\n",
    "    best_path = os.path.join(seed_dir, \"best_by_val_norm.pt\")\n",
    "    last_path = os.path.join(seed_dir, \"last_epoch.pt\")\n",
    "\n",
    "    history: List[Dict[str, Any]] = []\n",
    "    bad_epochs = 0\n",
    "\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        model.train()\n",
    "        losses = []\n",
    "\n",
    "        for x, y_norm, *_ in train_loader:\n",
    "            x = x.to(device)\n",
    "            y_norm = y_norm.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_norm = model(x)\n",
    "            loss = criterion(pred_norm, y_norm)\n",
    "            loss.backward()\n",
    "\n",
    "            if cfg.grad_clip and cfg.grad_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        train_mse_norm = float(np.mean(losses)) if losses else float(\"nan\")\n",
    "        val_metrics = evaluate_basic(model, val_loader, device)\n",
    "\n",
    "        history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_mse_norm\": train_mse_norm,\n",
    "            \"val_rmse_norm\": val_metrics[\"rmse_norm\"],\n",
    "            \"val_mae_norm\": val_metrics[\"mae_norm\"],\n",
    "            \"val_rmse_cycles\": val_metrics[\"rmse_cycles\"],\n",
    "            \"val_mae_cycles\": val_metrics[\"mae_cycles\"],\n",
    "        })\n",
    "\n",
    "        if val_metrics[\"rmse_norm\"] < best_by_val_norm:\n",
    "            best_by_val_norm = val_metrics[\"rmse_norm\"]\n",
    "            bad_epochs = 0\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(\n",
    "                f\"[SEED {seed}] [{epoch:03d}/{cfg.epochs}] \"\n",
    "                f\"train_mse_norm={train_mse_norm:.6f} | \"\n",
    "                f\"val_rmse_norm={val_metrics['rmse_norm']:.6f} | \"\n",
    "                f\"val_mae_cycles={val_metrics['mae_cycles']:.3f} | \"\n",
    "                f\"best_val_rmse_norm={best_by_val_norm:.6f}\"\n",
    "            )\n",
    "\n",
    "        if bad_epochs >= cfg.patience:\n",
    "            print(f\"[SEED {seed}] Early stopping at epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "    pd.DataFrame(history).to_csv(os.path.join(seed_dir, \"history.csv\"), index=False)\n",
    "    torch.save(model.state_dict(), last_path)\n",
    "\n",
    "    def export_ckpt(tag: str, ckpt_path: str) -> Dict[str, Any]:\n",
    "        sub_dir = os.path.join(seed_dir, tag)\n",
    "        os.makedirs(sub_dir, exist_ok=True)\n",
    "\n",
    "        model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        tr = evaluate_basic(model, train_eval, device)\n",
    "        va = evaluate_basic(model, val_eval, device)\n",
    "        te = evaluate_basic(model, test_eval, device)\n",
    "\n",
    "        for split_name, loader in [(\"train\", train_eval), (\"val\", val_eval), (\"test\", test_eval)]:\n",
    "            win_csv = os.path.join(sub_dir, f\"{split_name}_predictions_windows.csv\")\n",
    "            save_predictions_windows_csv(model, loader, device, win_csv, seq_len=cfg.seq_len)\n",
    "\n",
    "            seq_csv, metrics_csv = compute_metrics_from_windows_csv(\n",
    "                windows_csv=win_csv,\n",
    "                seq_len=cfg.seq_len,\n",
    "                alpha=cfg.alpha,\n",
    "                ph_consecutive_m=cfg.ph_consecutive_m,\n",
    "                lambdas=cfg.lambdas,\n",
    "                eps_rul=cfg.eps_rul,\n",
    "                out_dir=sub_dir,\n",
    "                split_name=split_name,\n",
    "            )\n",
    "\n",
    "            if cfg.save_figures:\n",
    "                fig_dir = os.path.join(sub_dir, \"paper_figures\", split_name)\n",
    "                make_paper_figures_for_split(\n",
    "                    cycle_seq_csv=seq_csv,\n",
    "                    metrics_per_file_csv=metrics_csv,\n",
    "                    out_fig_dir=fig_dir,\n",
    "                    title_prefix=f\"SEED {seed} | {tag.upper()} | {split_name} | Trial12\",\n",
    "                    alpha=cfg.alpha,\n",
    "                    lambda_to_plot=cfg.lambda_to_plot,\n",
    "                    max_files=cfg.max_files_to_plot,\n",
    "                )\n",
    "\n",
    "        ms = {\n",
    "            \"seed\": seed,\n",
    "            \"checkpoint\": tag,\n",
    "            \"train_rmse_cycles\": tr[\"rmse_cycles\"],\n",
    "            \"train_mae_cycles\": tr[\"mae_cycles\"],\n",
    "            \"train_rmse_norm\": tr[\"rmse_norm\"],\n",
    "            \"train_mae_norm\": tr[\"mae_norm\"],\n",
    "            \"val_rmse_cycles\": va[\"rmse_cycles\"],\n",
    "            \"val_mae_cycles\": va[\"mae_cycles\"],\n",
    "            \"val_rmse_norm\": va[\"rmse_norm\"],\n",
    "            \"val_mae_norm\": va[\"mae_norm\"],\n",
    "            \"test_rmse_cycles\": te[\"rmse_cycles\"],\n",
    "            \"test_mae_cycles\": te[\"mae_cycles\"],\n",
    "            \"test_rmse_norm\": te[\"rmse_norm\"],\n",
    "            \"test_mae_norm\": te[\"mae_norm\"],\n",
    "            \"stopped_epoch\": history[-1][\"epoch\"] if len(history) else None,\n",
    "            \"best_val_rmse_norm\": best_by_val_norm,\n",
    "            \"alpha\": cfg.alpha,\n",
    "            \"ph_consecutive_m\": cfg.ph_consecutive_m,\n",
    "            \"rep_method\": cfg.rep_method,\n",
    "            \"lambdas\": str(cfg.lambdas),\n",
    "            \"lambda_to_plot\": cfg.lambda_to_plot,\n",
    "            \"last_k_pool\": cfg.last_k_pool,\n",
    "            \"dvce_ma_window\": cfg.dvce_ma_window,\n",
    "            \"dvce_lag\": cfg.dvce_lag,\n",
    "        }\n",
    "        pd.DataFrame([ms]).to_csv(os.path.join(sub_dir, \"metrics_summary.csv\"), index=False)\n",
    "\n",
    "        print(f\"[SEED {seed}] {tag}: TEST mae_cycles={te['mae_cycles']:.3f} | rmse_cycles={te['rmse_cycles']:.3f} | rmse_norm={te['rmse_norm']:.6f}\")\n",
    "        return ms\n",
    "\n",
    "    ms_best = export_ckpt(\"best_by_val_norm\", best_path)\n",
    "    ms_last = export_ckpt(\"last_epoch\", last_path)\n",
    "\n",
    "    return {\"seed\": seed, \"seed_dir\": seed_dir, \"best\": ms_best, \"last\": ms_last}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10) Seed sweep + global comparison\n",
    "# ============================================================\n",
    "def summarize_across_seeds(cfg: Config, results: List[Dict[str, Any]]) -> None:\n",
    "    rows = []\n",
    "    for r in results:\n",
    "        rows.append(r[\"best\"])\n",
    "        rows.append(r[\"last\"])\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(os.path.join(cfg.out_dir, \"summary_across_seeds.csv\"), index=False)\n",
    "\n",
    "    def _isfinite(x: Any) -> bool:\n",
    "        try:\n",
    "            return bool(np.isfinite(float(x)))\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def win_rate(metric: str) -> Dict[str, Any]:\n",
    "        wins_last = 0\n",
    "        wins_best = 0\n",
    "        ties = 0\n",
    "        diffs = []\n",
    "\n",
    "        for r in results:\n",
    "            b = r[\"best\"][metric]\n",
    "            l = r[\"last\"][metric]\n",
    "            if _isfinite(b) and _isfinite(l):\n",
    "                diffs.append(float(l) - float(b))\n",
    "                if float(l) < float(b):\n",
    "                    wins_last += 1\n",
    "                elif float(b) < float(l):\n",
    "                    wins_best += 1\n",
    "                else:\n",
    "                    ties += 1\n",
    "\n",
    "        return {\n",
    "            \"metric\": metric,\n",
    "            \"wins_last\": wins_last,\n",
    "            \"wins_best\": wins_best,\n",
    "            \"ties\": ties,\n",
    "            \"mean(last-best)\": float(np.mean(diffs)) if diffs else float(\"nan\"),\n",
    "            \"std(last-best)\": float(np.std(diffs)) if diffs else float(\"nan\"),\n",
    "        }\n",
    "\n",
    "    metrics = [\"test_mae_cycles\", \"test_rmse_cycles\", \"test_mae_norm\", \"test_rmse_norm\"]\n",
    "    wr = [win_rate(m) for m in metrics]\n",
    "    pd.DataFrame(wr).to_csv(os.path.join(cfg.out_dir, \"win_rate_summary.csv\"), index=False)\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"=== WIN-RATE SUMMARY (TEST; lower is better) ===\")\n",
    "    for row in wr:\n",
    "        lines.append(\n",
    "            f\"- {row['metric']}: last wins={row['wins_last']}, best wins={row['wins_best']}, ties={row['ties']} | \"\n",
    "            f\"mean(last-best)={row['mean(last-best)']:.6f}, std(last-best)={row['std(last-best)']:.6f}\"\n",
    "        )\n",
    "\n",
    "    agg = df.groupby(\"checkpoint\")[metrics].agg([\"mean\", \"std\"])\n",
    "    lines.append(\"\\n=== MEAN ± STD across seeds (TEST) ===\")\n",
    "    lines.append(str(agg))\n",
    "\n",
    "    with open(os.path.join(cfg.out_dir, \"win_rate_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nSaved:\")\n",
    "    print(\" -\", os.path.join(cfg.out_dir, \"summary_across_seeds.csv\"))\n",
    "    print(\" -\", os.path.join(cfg.out_dir, \"win_rate_summary.csv\"))\n",
    "    print(\" -\", os.path.join(cfg.out_dir, \"win_rate_summary.txt\"))\n",
    "\n",
    "\n",
    "def run_trial12_seed_sweep(cfg: Config) -> None:\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    for seed in cfg.seeds:\n",
    "        res = run_one_seed(cfg, seed)\n",
    "        results.append(res)\n",
    "\n",
    "    summarize_across_seeds(cfg, results)\n",
    "\n",
    "    print(\"\\nDONE. Check Trial12 folder:\")\n",
    "    print(\" - per seed results: Trial12/seed_<seed>/...\")\n",
    "    print(\" - figures (paper-style): seed_<seed>/<ckpt>/paper_figures/<split>/\")\n",
    "    print(\" - cycle sequence mean CSV: <ckpt>/<split>_cycle_sequence_mean.csv\")\n",
    "    print(\" - PH/α–λ metrics CSV: <ckpt>/<split>_prognostics_metrics_per_file.csv\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 11) Run\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config(\n",
    "        data_dir=r\"C:\\Users\\11HOME_AHCI\\Desktop\\PoF\\Winter 2026\\Ref Data4\\100\",\n",
    "        out_dir=r\"./Trial12\",\n",
    "\n",
    "        seeds=(9819123, 111, 222, 333, 444),\n",
    "\n",
    "        seq_len=100,\n",
    "        stride=5,\n",
    "        pred_horizon=0,\n",
    "\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.2,\n",
    "        test_ratio=0.1,\n",
    "\n",
    "        batch_size=512,\n",
    "        epochs=300,\n",
    "        lr=1e-3,\n",
    "        weight_decay=0.0,\n",
    "        patience=30,\n",
    "        grad_clip=1.0,\n",
    "\n",
    "        hidden_size=512,\n",
    "        num_layers=2,\n",
    "        dropout=0.2,\n",
    "\n",
    "        # ✅ Trial12 knobs\n",
    "        last_k_pool=20,\n",
    "        dvce_ma_window=5,\n",
    "        dvce_lag=5,\n",
    "\n",
    "        save_figures=True,\n",
    "        max_files_to_plot=None,\n",
    "        num_workers=0,\n",
    "\n",
    "        alpha=0.20,\n",
    "        ph_consecutive_m=5,\n",
    "        rep_method=\"mean\",\n",
    "        lambdas=(0.2, 0.4, 0.6, 0.8),\n",
    "        lambda_to_plot=0.6,\n",
    "    )\n",
    "\n",
    "    run_trial12_seed_sweep(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf1484dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ BEST MODEL (Trial12) ================\n",
      "[SELECTED BY VAL]  (recommended for model selection)\n",
      "  Seed             : 333\n",
      "  Checkpoint       : best_by_val_norm\n",
      "  VAL  RMSE (cyc)   : 2129.574\n",
      "  VAL  MAE  (cyc)   : 1452.357\n",
      "  VAL  RMSE (norm)  : 0.121050\n",
      "  VAL  MAE  (norm)  : 0.094400\n",
      "  TEST RMSE (cyc)   : 1563.467\n",
      "  TEST MAE  (cyc)   : 975.492\n",
      "  TEST RMSE (norm)  : 0.145153\n",
      "  TEST MAE  (norm)  : 0.115274\n",
      "\n",
      "[SELECTED BY TEST] (for reporting only; not for tuning)\n",
      "  Seed             : 333\n",
      "  Checkpoint       : best_by_val_norm\n",
      "  TEST RMSE (cyc)   : 1563.467\n",
      "  TEST MAE  (cyc)   : 975.492\n",
      "  TEST RMSE (norm)  : 0.145153\n",
      "  TEST MAE  (norm)  : 0.115274\n",
      "  VAL  RMSE (cyc)   : 2129.574\n",
      "  VAL  MAE  (cyc)   : 1452.357\n",
      "  VAL  RMSE (norm)  : 0.121050\n",
      "  VAL  MAE  (norm)  : 0.094400\n",
      "\n",
      "---------------- WIN-RATE (last_epoch vs best_by_val_norm) ----------------\n",
      "- val_rmse_cycles: last wins=0, best wins=5, ties=0 | mean(last-best)=561.637136\n",
      "- test_rmse_cycles: last wins=0, best wins=5, ties=0 | mean(last-best)=367.652850\n",
      "- val_rmse_norm: last wins=0, best wins=5, ties=0 | mean(last-best)=0.026717\n",
      "- test_rmse_norm: last wins=0, best wins=5, ties=0 | mean(last-best)=0.022097\n",
      "=====================================================\n",
      "\n",
      "Saved -> ./Trial12\\BEST_MODEL_BY_VAL.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================\n",
    "# Trial12 paths\n",
    "# ============================\n",
    "TRIAL12_DIR = \"./Trial12\"\n",
    "SUMMARY_CSV = os.path.join(TRIAL12_DIR, \"summary_across_seeds.csv\")\n",
    "\n",
    "BEST_TAG = \"best_by_val_norm\"\n",
    "LAST_TAG = \"last_epoch\"\n",
    "\n",
    "\n",
    "def _require_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in summary CSV: {missing}\")\n",
    "\n",
    "\n",
    "def pick_best_row(df: pd.DataFrame, metric_prefix: str = \"val\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    metric_prefix: \"val\" or \"test\"\n",
    "    Sort rule (lower is better):\n",
    "      1) <prefix>_rmse_cycles ascending\n",
    "      2) <prefix>_mae_cycles  ascending\n",
    "    \"\"\"\n",
    "    rmse_col = f\"{metric_prefix}_rmse_cycles\"\n",
    "    mae_col = f\"{metric_prefix}_mae_cycles\"\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", rmse_col, mae_col])\n",
    "\n",
    "    df_sorted = df.sort_values(\n",
    "        by=[rmse_col, mae_col],\n",
    "        ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return df_sorted.iloc[0]\n",
    "\n",
    "\n",
    "def win_rate(df: pd.DataFrame, metric: str) -> dict:\n",
    "    \"\"\"\n",
    "    Compare BEST_TAG vs LAST_TAG within each seed on the given metric (lower is better).\n",
    "    Returns wins for last, wins for best, ties, and mean(last-best).\n",
    "    \"\"\"\n",
    "    _require_cols(df, [\"seed\", \"checkpoint\", metric])\n",
    "\n",
    "    wins_last = 0\n",
    "    wins_best = 0\n",
    "    ties = 0\n",
    "    diffs = []\n",
    "\n",
    "    for seed, g in df.groupby(\"seed\"):\n",
    "        ckpts = set(g[\"checkpoint\"].astype(str).values)\n",
    "        if not ({BEST_TAG, LAST_TAG} <= ckpts):\n",
    "            continue\n",
    "\n",
    "        b = float(g.loc[g[\"checkpoint\"] == BEST_TAG, metric].iloc[0])\n",
    "        l = float(g.loc[g[\"checkpoint\"] == LAST_TAG, metric].iloc[0])\n",
    "\n",
    "        if np.isfinite(b) and np.isfinite(l):\n",
    "            diffs.append(l - b)  # negative => last better\n",
    "            if l < b:\n",
    "                wins_last += 1\n",
    "            elif b < l:\n",
    "                wins_best += 1\n",
    "            else:\n",
    "                ties += 1\n",
    "\n",
    "    return {\n",
    "        \"metric\": metric,\n",
    "        \"wins_last\": wins_last,\n",
    "        \"wins_best\": wins_best,\n",
    "        \"ties\": ties,\n",
    "        \"mean(last-best)\": float(np.mean(diffs)) if diffs else float(\"nan\"),\n",
    "        \"std(last-best)\": float(np.std(diffs)) if diffs else float(\"nan\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(SUMMARY_CSV):\n",
    "        raise FileNotFoundError(f\"Not found: {SUMMARY_CSV}\")\n",
    "\n",
    "    df = pd.read_csv(SUMMARY_CSV)\n",
    "\n",
    "    # sanity check (Trial12 summary columns)\n",
    "    needed = [\n",
    "        \"seed\", \"checkpoint\",\n",
    "        \"train_rmse_cycles\", \"train_mae_cycles\", \"train_rmse_norm\", \"train_mae_norm\",\n",
    "        \"val_rmse_cycles\", \"val_mae_cycles\", \"val_rmse_norm\", \"val_mae_norm\",\n",
    "        \"test_rmse_cycles\", \"test_mae_cycles\", \"test_rmse_norm\", \"test_mae_norm\",\n",
    "    ]\n",
    "    _require_cols(df, needed)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) VAL 기준 best (권장)\n",
    "    # -----------------------------\n",
    "    best_val = pick_best_row(df, metric_prefix=\"val\")\n",
    "    best_val_seed = int(best_val[\"seed\"])\n",
    "    best_val_ckpt = str(best_val[\"checkpoint\"])\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2) TEST 기준 best (보고용)\n",
    "    # -----------------------------\n",
    "    best_test = pick_best_row(df, metric_prefix=\"test\")\n",
    "    best_test_seed = int(best_test[\"seed\"])\n",
    "    best_test_ckpt = str(best_test[\"checkpoint\"])\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3) win-rate (seed별 last vs best 비교)\n",
    "    # -----------------------------\n",
    "    wr_val_rmse = win_rate(df, \"val_rmse_cycles\")\n",
    "    wr_test_rmse = win_rate(df, \"test_rmse_cycles\")\n",
    "    wr_val_rmse_norm = win_rate(df, \"val_rmse_norm\")\n",
    "    wr_test_rmse_norm = win_rate(df, \"test_rmse_norm\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4) 출력\n",
    "    # -----------------------------\n",
    "    print(\"\\n================ BEST MODEL (Trial12) ================\")\n",
    "    print(\"[SELECTED BY VAL]  (recommended for model selection)\")\n",
    "    print(f\"  Seed             : {best_val_seed}\")\n",
    "    print(f\"  Checkpoint       : {best_val_ckpt}\")\n",
    "    print(f\"  VAL  RMSE (cyc)   : {best_val['val_rmse_cycles']:.3f}\")\n",
    "    print(f\"  VAL  MAE  (cyc)   : {best_val['val_mae_cycles']:.3f}\")\n",
    "    print(f\"  VAL  RMSE (norm)  : {best_val['val_rmse_norm']:.6f}\")\n",
    "    print(f\"  VAL  MAE  (norm)  : {best_val['val_mae_norm']:.6f}\")\n",
    "    print(f\"  TEST RMSE (cyc)   : {best_val['test_rmse_cycles']:.3f}\")\n",
    "    print(f\"  TEST MAE  (cyc)   : {best_val['test_mae_cycles']:.3f}\")\n",
    "    print(f\"  TEST RMSE (norm)  : {best_val['test_rmse_norm']:.6f}\")\n",
    "    print(f\"  TEST MAE  (norm)  : {best_val['test_mae_norm']:.6f}\")\n",
    "\n",
    "    print(\"\\n[SELECTED BY TEST] (for reporting only; not for tuning)\")\n",
    "    print(f\"  Seed             : {best_test_seed}\")\n",
    "    print(f\"  Checkpoint       : {best_test_ckpt}\")\n",
    "    print(f\"  TEST RMSE (cyc)   : {best_test['test_rmse_cycles']:.3f}\")\n",
    "    print(f\"  TEST MAE  (cyc)   : {best_test['test_mae_cycles']:.3f}\")\n",
    "    print(f\"  TEST RMSE (norm)  : {best_test['test_rmse_norm']:.6f}\")\n",
    "    print(f\"  TEST MAE  (norm)  : {best_test['test_mae_norm']:.6f}\")\n",
    "    print(f\"  VAL  RMSE (cyc)   : {best_test['val_rmse_cycles']:.3f}\")\n",
    "    print(f\"  VAL  MAE  (cyc)   : {best_test['val_mae_cycles']:.3f}\")\n",
    "    print(f\"  VAL  RMSE (norm)  : {best_test['val_rmse_norm']:.6f}\")\n",
    "    print(f\"  VAL  MAE  (norm)  : {best_test['val_mae_norm']:.6f}\")\n",
    "\n",
    "    print(\"\\n---------------- WIN-RATE (last_epoch vs best_by_val_norm) ----------------\")\n",
    "    print(f\"- {wr_val_rmse['metric']}: last wins={wr_val_rmse['wins_last']}, \"\n",
    "          f\"best wins={wr_val_rmse['wins_best']}, ties={wr_val_rmse['ties']} | \"\n",
    "          f\"mean(last-best)={wr_val_rmse['mean(last-best)']:.6f}\")\n",
    "    print(f\"- {wr_test_rmse['metric']}: last wins={wr_test_rmse['wins_last']}, \"\n",
    "          f\"best wins={wr_test_rmse['wins_best']}, ties={wr_test_rmse['ties']} | \"\n",
    "          f\"mean(last-best)={wr_test_rmse['mean(last-best)']:.6f}\")\n",
    "    print(f\"- {wr_val_rmse_norm['metric']}: last wins={wr_val_rmse_norm['wins_last']}, \"\n",
    "          f\"best wins={wr_val_rmse_norm['wins_best']}, ties={wr_val_rmse_norm['ties']} | \"\n",
    "          f\"mean(last-best)={wr_val_rmse_norm['mean(last-best)']:.6f}\")\n",
    "    print(f\"- {wr_test_rmse_norm['metric']}: last wins={wr_test_rmse_norm['wins_last']}, \"\n",
    "          f\"best wins={wr_test_rmse_norm['wins_best']}, ties={wr_test_rmse_norm['ties']} | \"\n",
    "          f\"mean(last-best)={wr_test_rmse_norm['mean(last-best)']:.6f}\")\n",
    "    print(\"=====================================================\\n\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5) 기록 저장 (VAL 기준 best)\n",
    "    # -----------------------------\n",
    "    out_txt = os.path.join(TRIAL12_DIR, \"BEST_MODEL_BY_VAL.txt\")\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"BEST MODEL (Trial12) - Selected by VAL\\n\")\n",
    "        f.write(f\"seed={best_val_seed}\\n\")\n",
    "        f.write(f\"checkpoint={best_val_ckpt}\\n\")\n",
    "        f.write(f\"val_rmse_cycles={best_val['val_rmse_cycles']}\\n\")\n",
    "        f.write(f\"val_mae_cycles={best_val['val_mae_cycles']}\\n\")\n",
    "        f.write(f\"val_rmse_norm={best_val['val_rmse_norm']}\\n\")\n",
    "        f.write(f\"val_mae_norm={best_val['val_mae_norm']}\\n\")\n",
    "        f.write(f\"test_rmse_cycles={best_val['test_rmse_cycles']}\\n\")\n",
    "        f.write(f\"test_mae_cycles={best_val['test_mae_cycles']}\\n\")\n",
    "        f.write(f\"test_rmse_norm={best_val['test_rmse_norm']}\\n\")\n",
    "        f.write(f\"test_mae_norm={best_val['test_mae_norm']}\\n\")\n",
    "\n",
    "        # (추가로 기록하면 실험 재현에 도움되는 Trial12 knobs)\n",
    "        for k in [\"last_k_pool\", \"dvce_ma_window\", \"dvce_lag\", \"stopped_epoch\", \"best_val_rmse_norm\"]:\n",
    "            if k in best_val.index:\n",
    "                f.write(f\"{k}={best_val[k]}\\n\")\n",
    "\n",
    "    print(f\"Saved -> {out_txt}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0388cb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] train: λ=0.20:0.743, λ=0.40:0.571, λ=0.60:0.514, λ=0.80:0.443\n",
      "[OK] val: λ=0.20:0.700, λ=0.40:0.550, λ=0.60:0.550, λ=0.80:0.500\n",
      "[OK] test: λ=0.20:0.800, λ=0.40:0.700, λ=0.60:0.700, λ=0.80:0.600\n",
      "\n",
      "==================== DONE ====================\n",
      "Saved:\n",
      " - ./Trial12\\seed_333\\best_by_val_norm\\alpha_lambda_eval\\alpha_lambda_summary_seed333_best_by_val_norm.csv\n",
      " - ./Trial12\\seed_333\\best_by_val_norm\\alpha_lambda_eval\\alpha_lambda_per_file_seed333_best_by_val_norm.csv\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# USER CONFIG (Trial12)\n",
    "# =========================\n",
    "TRIAL12_DIR = r\"./Trial12\"          # ✅ Trial12 루트 폴더\n",
    "SEED = 333                          # 선택된 seed\n",
    "CKPT = \"best_by_val_norm\"           # \"best_by_val_norm\" or \"last_epoch\"\n",
    "SPLITS = [\"train\", \"val\", \"test\"]   # 평가할 split\n",
    "LAM_STRS = [\"0.20\", \"0.40\", \"0.60\", \"0.80\"]\n",
    "\n",
    "# (선택) 후반 λ를 더 중요하게 보고 싶으면 가중치 사용\n",
    "# 예: λ=0.2,0.4,0.6,0.8 가중치 = 1,1,2,3\n",
    "LAMBDA_WEIGHTS = None  # 또는 {\"0.20\":1, \"0.40\":1, \"0.60\":2, \"0.80\":3}\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _require_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "\n",
    "def compute_alpha_lambda_rates(dfm: pd.DataFrame, lam_strs, weights=None) -> dict:\n",
    "    \"\"\"\n",
    "    dfm: <split>_prognostics_metrics_per_file.csv  (per-file summary)\n",
    "    Returns:\n",
    "      - per-lambda success rate (mean of alpha_lambda_ok_{lam})\n",
    "      - overall mean rate (simple mean or weighted mean)\n",
    "    \"\"\"\n",
    "    rates = {}\n",
    "\n",
    "    for ls in lam_strs:\n",
    "        col = f\"alpha_lambda_ok_{ls}\"\n",
    "        if col in dfm.columns:\n",
    "            # 0/1 평균 = 성공률\n",
    "            rates[f\"rate_{ls}\"] = float(dfm[col].mean())\n",
    "        else:\n",
    "            rates[f\"rate_{ls}\"] = np.nan\n",
    "\n",
    "    # overall score\n",
    "    if weights is None:\n",
    "        vals = [rates[f\"rate_{ls}\"] for ls in lam_strs if np.isfinite(rates[f\"rate_{ls}\"])]\n",
    "        rates[\"rate_mean_all\"] = float(np.mean(vals)) if vals else np.nan\n",
    "    else:\n",
    "        num = 0.0\n",
    "        den = 0.0\n",
    "        for ls in lam_strs:\n",
    "            v = rates[f\"rate_{ls}\"]\n",
    "            w = float(weights.get(ls, 0.0))\n",
    "            if np.isfinite(v) and w > 0:\n",
    "                num += w * v\n",
    "                den += w\n",
    "        rates[\"rate_weighted_all\"] = (num / den) if den > 0 else np.nan\n",
    "\n",
    "    return rates\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Trial12 구조: ./Trial12/seed_<seed>/<ckpt>/\n",
    "    seed_dir = os.path.join(TRIAL12_DIR, f\"seed_{SEED}\", CKPT)\n",
    "    if not os.path.isdir(seed_dir):\n",
    "        raise FileNotFoundError(f\"Not found: {seed_dir}\")\n",
    "\n",
    "    out_dir = os.path.join(seed_dir, \"alpha_lambda_eval\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    summary_rows = []\n",
    "    per_file_rows = []  # (선택) 파일별 ok 값도 모아서 저장\n",
    "\n",
    "    for split in SPLITS:\n",
    "        mpath = os.path.join(seed_dir, f\"{split}_prognostics_metrics_per_file.csv\")\n",
    "        if not os.path.exists(mpath):\n",
    "            print(f\"[SKIP] Missing: {mpath}\")\n",
    "            continue\n",
    "\n",
    "        dfm = pd.read_csv(mpath)\n",
    "        _require_cols(dfm, [\"file\"])  # 최소 file은 있어야 함\n",
    "\n",
    "        # split 요약(성공률)\n",
    "        rates = compute_alpha_lambda_rates(dfm, LAM_STRS, weights=LAMBDA_WEIGHTS)\n",
    "        row = {\n",
    "            \"seed\": SEED,\n",
    "            \"checkpoint\": CKPT,\n",
    "            \"split\": split,\n",
    "            \"n_files\": int(len(dfm)),\n",
    "            **rates\n",
    "        }\n",
    "        summary_rows.append(row)\n",
    "\n",
    "        # (선택) 파일별 pass/fail + t_lambda 저장\n",
    "        keep_cols = [\"file\"]\n",
    "        for ls in LAM_STRS:\n",
    "            c_ok = f\"alpha_lambda_ok_{ls}\"\n",
    "            c_tl = f\"t_lambda_{ls}\"\n",
    "            if c_ok in dfm.columns:\n",
    "                keep_cols.append(c_ok)\n",
    "            if c_tl in dfm.columns:\n",
    "                keep_cols.append(c_tl)\n",
    "\n",
    "        sub = dfm[keep_cols].copy()\n",
    "        sub.insert(0, \"split\", split)\n",
    "        sub.insert(0, \"checkpoint\", CKPT)\n",
    "        sub.insert(0, \"seed\", SEED)\n",
    "        per_file_rows.append(sub)\n",
    "\n",
    "        # 콘솔 출력\n",
    "        msg_parts = []\n",
    "        for ls in LAM_STRS:\n",
    "            v = row.get(f\"rate_{ls}\", np.nan)\n",
    "            if np.isfinite(v):\n",
    "                msg_parts.append(f\"λ={ls}:{v:.3f}\")\n",
    "        msg = \", \".join(msg_parts) if msg_parts else \"no lambda columns found\"\n",
    "        print(f\"[OK] {split}: {msg}\")\n",
    "\n",
    "    # 저장: split별 요약\n",
    "    df_summary = pd.DataFrame(summary_rows)\n",
    "    out_summary = os.path.join(out_dir, f\"alpha_lambda_summary_seed{SEED}_{CKPT}.csv\")\n",
    "    df_summary.to_csv(out_summary, index=False)\n",
    "\n",
    "    # 저장: 파일별 pass/fail (선택)\n",
    "    out_pf = None\n",
    "    if per_file_rows:\n",
    "        df_pf = pd.concat(per_file_rows, axis=0, ignore_index=True)\n",
    "        out_pf = os.path.join(out_dir, f\"alpha_lambda_per_file_seed{SEED}_{CKPT}.csv\")\n",
    "        df_pf.to_csv(out_pf, index=False)\n",
    "\n",
    "    print(\"\\n==================== DONE ====================\")\n",
    "    print(\"Saved:\")\n",
    "    print(\" -\", out_summary)\n",
    "    if out_pf:\n",
    "        print(\" -\", out_pf)\n",
    "    print(\"==============================================\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee039e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] ./Trial12\\seed_333\\best_by_val_norm\\alpha_lambda_eval\\alpha_lambda_curve_seed333_best_by_val_norm.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# USER CONFIG (Trial12)\n",
    "# =========================\n",
    "TRIAL12_DIR = r\"./Trial12\"\n",
    "SEED = 333\n",
    "CKPT = \"best_by_val_norm\"   # or \"last_epoch\"\n",
    "\n",
    "LAM_STRS = [\"0.20\", \"0.40\", \"0.60\", \"0.80\"]\n",
    "LAM = [float(x) for x in LAM_STRS]\n",
    "SPLITS_ORDER = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# =========================\n",
    "# Paths\n",
    "# =========================\n",
    "AL_DIR = os.path.join(\n",
    "    TRIAL12_DIR, f\"seed_{SEED}\", CKPT, \"alpha_lambda_eval\"\n",
    ")\n",
    "SUMMARY_CSV = os.path.join(\n",
    "    AL_DIR, f\"alpha_lambda_summary_seed{SEED}_{CKPT}.csv\"\n",
    ")\n",
    "OUT_PNG = os.path.join(\n",
    "    AL_DIR, f\"alpha_lambda_curve_seed{SEED}_{CKPT}.png\"\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Load\n",
    "# =========================\n",
    "if not os.path.exists(SUMMARY_CSV):\n",
    "    raise FileNotFoundError(f\"Not found: {SUMMARY_CSV}\")\n",
    "\n",
    "df = pd.read_csv(SUMMARY_CSV)\n",
    "\n",
    "# =========================\n",
    "# Plot\n",
    "# =========================\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for split in SPLITS_ORDER:\n",
    "    sub = df[df[\"split\"] == split]\n",
    "    if sub.empty:\n",
    "        print(f\"[SKIP] no data for split={split}\")\n",
    "        continue\n",
    "\n",
    "    row = sub.iloc[0]\n",
    "    rates = []\n",
    "    for ls in LAM_STRS:\n",
    "        v = row.get(f\"rate_{ls}\", np.nan)\n",
    "        rates.append(float(v) if np.isfinite(v) else np.nan)\n",
    "\n",
    "    plt.plot(\n",
    "        LAM,\n",
    "        rates,\n",
    "        marker=\"o\",\n",
    "        linewidth=2,\n",
    "        label=split\n",
    "    )\n",
    "\n",
    "plt.xticks(LAM, [f\"{x:.2f}\" for x in LAM])\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.xlabel(\"λ (life fraction)\")\n",
    "plt.ylabel(\"α–λ success rate\")\n",
    "plt.title(f\"α–λ Success Rate Curve\\nSeed {SEED} | {CKPT} | Trial12\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# =========================\n",
    "# Save\n",
    "# =========================\n",
    "os.makedirs(os.path.dirname(OUT_PNG), exist_ok=True)\n",
    "plt.savefig(OUT_PNG, dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"[SAVE] {OUT_PNG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0459b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# USER CONFIG\n",
    "# ============================================================\n",
    "TRIAL_DIR = r\"./Trial9\"              # Trial9 폴더\n",
    "SEED = 333                           # seed 선택\n",
    "CKPT = \"best_by_val_norm\"            # \"best_by_val_norm\" or \"last_epoch\"\n",
    "\n",
    "SPLITS = [\"train\", \"val\", \"test\"]    # ✅ 여러 split 한 번에\n",
    "\n",
    "ALPHA = 0.20\n",
    "SEQ_LEN = 100                        # (참고) eval 구간에서 t_s=seq_len-1을 이미 metrics가 갖고 있어 직접 쓰진 않음\n",
    "LAMBDA_TO_PLOT = 0.60                # α–λ 그림에 표시할 λ\n",
    "\n",
    "MAX_FILES = None                     # None=모두, 아니면 예: 10\n",
    "\n",
    "# 저장 폴더 루트\n",
    "OUT_ROOT = os.path.join(TRIAL_DIR, f\"seed_{SEED}\", CKPT, \"paper_figures_bookstyle\")\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "def safe_name(s: str) -> str:\n",
    "    return s.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "def load_cycle_seq_and_metrics(seed_dir: str, split: str):\n",
    "    \"\"\"\n",
    "    Trial9가 이미 만들어 둔 파일들:\n",
    "      - <split>_cycle_sequence_mean.csv\n",
    "      - <split>_prognostics_metrics_per_file.csv\n",
    "    \"\"\"\n",
    "    seq_csv = os.path.join(seed_dir, f\"{split}_cycle_sequence_mean.csv\")\n",
    "    met_csv = os.path.join(seed_dir, f\"{split}_prognostics_metrics_per_file.csv\")\n",
    "\n",
    "    if not os.path.exists(seq_csv):\n",
    "        raise FileNotFoundError(f\"Missing: {seq_csv}\")\n",
    "    if not os.path.exists(met_csv):\n",
    "        raise FileNotFoundError(f\"Missing: {met_csv}\")\n",
    "\n",
    "    df_seq = pd.read_csv(seq_csv)\n",
    "    df_met = pd.read_csv(met_csv)\n",
    "    return df_seq, df_met\n",
    "\n",
    "def get_eval_segment(df_one_file: pd.DataFrame, t_s: int, t_e: int) -> pd.DataFrame:\n",
    "    df = df_one_file.sort_values(\"cycle\").copy()\n",
    "    df = df[(df[\"cycle\"] >= t_s) & (df[\"cycle\"] <= t_e)].copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# Plotters\n",
    "# ============================================================\n",
    "def plot_ph_alpha_absolute_band(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    alpha: float,\n",
    "    out_path: str,\n",
    "    ph_start: Optional[float] = None,\n",
    "    title_prefix: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    BOOK Fig.2.9(a) 스타일: PH용 α-zone은 '절대 폭(평행 밴드)'\n",
    "      alphaZone = alpha * EOL_true\n",
    "      zone = RUL_true ± alphaZone\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].to_numpy()\n",
    "    y_true = df_eval[\"RUL_true\"].to_numpy()\n",
    "    y_pred = df_eval[\"RUL_pred\"].to_numpy()\n",
    "\n",
    "    last_cycle = int(df_eval[\"cycle\"].max())\n",
    "    eol_true = last_cycle + 1\n",
    "\n",
    "    alpha_zone = alpha * float(eol_true)  # ✅ book-style 핵심 (평행 밴드)\n",
    "    upper = y_true + alpha_zone\n",
    "    lower = y_true - alpha_zone\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, \"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, \"r\", label=\"Prediction (cycles)\")\n",
    "    plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α-zone (±α·EOL)\")\n",
    "    plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α-zone (±α·EOL)\")\n",
    "\n",
    "    if ph_start is not None and np.isfinite(ph_start):\n",
    "        plt.axvline(int(ph_start), color=\"g\", linestyle=\"-.\", label=\"PH start\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title_prefix} | BOOK-STYLE α+PH (absolute band)\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_alpha_lambda_relative_band(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    t_lambda: Optional[int],\n",
    "    out_path: str,\n",
    "    title_prefix: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    BOOK Fig.2.9(b) 스타일: α–λ는 '상대 폭(수렴 밴드)'\n",
    "      zone = RUL_true*(1±alpha), 그리고 t >= t_lambda 구간만 표시\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].to_numpy()\n",
    "    y_true = df_eval[\"RUL_true\"].to_numpy()\n",
    "    y_pred = df_eval[\"RUL_pred\"].to_numpy()\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, \"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, \"r\", label=\"Prediction (cycles)\")\n",
    "\n",
    "    if t_lambda is not None and np.isfinite(t_lambda):\n",
    "        t_lambda = int(t_lambda)\n",
    "        plt.axvline(t_lambda, color=\"g\", linestyle=\":\", label=f\"t_λ (λ={lambda_to_plot:.2f})\")\n",
    "\n",
    "        mask = x >= t_lambda\n",
    "        if np.any(mask):\n",
    "            plt.plot(x[mask], upper[mask], \"b--\", label=f\"+{alpha:.2f} α–λ zone\")\n",
    "            plt.plot(x[mask], lower[mask], \"b--\", label=f\"-{alpha:.2f} α–λ zone\")\n",
    "        else:\n",
    "            plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α zone\")\n",
    "            plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α zone\")\n",
    "    else:\n",
    "        plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α zone\")\n",
    "        plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α zone\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title_prefix} | BOOK-STYLE α–λ (relative band)\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# Main (multi-split)\n",
    "# ============================================================\n",
    "def run_for_one_split(seed_dir: str, split: str):\n",
    "    df_seq, df_met = load_cycle_seq_and_metrics(seed_dir, split)\n",
    "\n",
    "    files = df_seq[\"file\"].unique().tolist()\n",
    "    if MAX_FILES is not None:\n",
    "        files = files[:MAX_FILES]\n",
    "\n",
    "    out_dir = os.path.join(OUT_ROOT, split)  # ✅ split별 폴더\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    lam_key = f\"t_lambda_{LAMBDA_TO_PLOT:.2f}\"\n",
    "    title_prefix = f\"SEED {SEED} | {CKPT.upper()} | {split}\"\n",
    "\n",
    "    for f in files:\n",
    "        sub = df_seq[df_seq[\"file\"] == f].copy()\n",
    "        mrow = df_met[df_met[\"file\"] == f]\n",
    "        if mrow.empty:\n",
    "            continue\n",
    "        mrow = mrow.iloc[0].to_dict()\n",
    "\n",
    "        t_s = int(mrow[\"t_s\"])\n",
    "        t_e = int(mrow[\"t_e\"])\n",
    "        ph_start = mrow.get(\"t_PH_start\", np.nan)\n",
    "        t_lambda = mrow.get(lam_key, np.nan)\n",
    "\n",
    "        df_eval = get_eval_segment(sub, t_s, t_e)\n",
    "        if df_eval.empty:\n",
    "            continue\n",
    "\n",
    "        sname = safe_name(f)\n",
    "\n",
    "        out_a = os.path.join(out_dir, f\"FIG_A_BOOKSTYLE_alpha_PH__{sname}.png\")\n",
    "        plot_ph_alpha_absolute_band(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            alpha=ALPHA,\n",
    "            out_path=out_a,\n",
    "            ph_start=ph_start if np.isfinite(ph_start) else None,\n",
    "            title_prefix=title_prefix,\n",
    "        )\n",
    "\n",
    "        out_b = os.path.join(out_dir, f\"FIG_B_BOOKSTYLE_alpha_lambda__lam{LAMBDA_TO_PLOT:.2f}__{sname}.png\")\n",
    "        plot_alpha_lambda_relative_band(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            alpha=ALPHA,\n",
    "            lambda_to_plot=LAMBDA_TO_PLOT,\n",
    "            t_lambda=int(t_lambda) if np.isfinite(t_lambda) else None,\n",
    "            out_path=out_b,\n",
    "            title_prefix=title_prefix,\n",
    "        )\n",
    "\n",
    "    print(f\"[{split}] DONE -> {out_dir}\")\n",
    "\n",
    "def main():\n",
    "    seed_dir = os.path.join(TRIAL_DIR, f\"seed_{SEED}\", CKPT)\n",
    "\n",
    "    for split in SPLITS:\n",
    "        run_for_one_split(seed_dir, split)\n",
    "\n",
    "    print(\"\\nALL DONE.\")\n",
    "    print(\"Saved under:\", OUT_ROOT)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b64611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] DONE -> ./Trial12\\seed_333\\best_by_val_norm\\paper_figures_bookstyle\\train\n",
      "[val] DONE -> ./Trial12\\seed_333\\best_by_val_norm\\paper_figures_bookstyle\\val\n",
      "[test] DONE -> ./Trial12\\seed_333\\best_by_val_norm\\paper_figures_bookstyle\\test\n",
      "\n",
      "ALL DONE.\n",
      "Saved under: ./Trial12\\seed_333\\best_by_val_norm\\paper_figures_bookstyle\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# USER CONFIG (Trial12)\n",
    "# ============================================================\n",
    "TRIAL_DIR = r\"./Trial12\"             # ✅ Trial12 루트 폴더\n",
    "SEED = 333                           # seed 선택\n",
    "CKPT = \"best_by_val_norm\"            # \"best_by_val_norm\" or \"last_epoch\"\n",
    "\n",
    "SPLITS = [\"train\", \"val\", \"test\"]    # ✅ 여러 split 한 번에\n",
    "\n",
    "ALPHA = 0.20\n",
    "LAMBDA_TO_PLOT = 0.60                # α–λ 그림에 표시할 λ\n",
    "MAX_FILES = None                     # None=모두, 아니면 예: 10\n",
    "\n",
    "# ============================================================\n",
    "# Paths\n",
    "# Trial12 구조:\n",
    "#   ./Trial12/seed_<seed>/<ckpt>/\n",
    "#       train_cycle_sequence_mean.csv\n",
    "#       train_prognostics_metrics_per_file.csv\n",
    "#       ...\n",
    "# ============================================================\n",
    "SEED_DIR = os.path.join(TRIAL_DIR, f\"seed_{SEED}\", CKPT)\n",
    "\n",
    "# 저장 폴더 루트 (원하면 이름 바꿔도 됨)\n",
    "OUT_ROOT = os.path.join(SEED_DIR, \"paper_figures_bookstyle\")\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "def safe_name(s: str) -> str:\n",
    "    return s.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "\n",
    "def load_cycle_seq_and_metrics(seed_dir: str, split: str):\n",
    "    \"\"\"\n",
    "    Trial12가 만들어 둔 파일들:\n",
    "      - <split>_cycle_sequence_mean.csv\n",
    "      - <split>_prognostics_metrics_per_file.csv\n",
    "    (Trial12 export_ckpt()가 sub_dir(=seed_dir/tag) 아래에 저장함)\n",
    "    \"\"\"\n",
    "    seq_csv = os.path.join(seed_dir, f\"{split}_cycle_sequence_mean.csv\")\n",
    "    met_csv = os.path.join(seed_dir, f\"{split}_prognostics_metrics_per_file.csv\")\n",
    "\n",
    "    if not os.path.exists(seq_csv):\n",
    "        raise FileNotFoundError(f\"Missing: {seq_csv}\")\n",
    "    if not os.path.exists(met_csv):\n",
    "        raise FileNotFoundError(f\"Missing: {met_csv}\")\n",
    "\n",
    "    df_seq = pd.read_csv(seq_csv)\n",
    "    df_met = pd.read_csv(met_csv)\n",
    "    return df_seq, df_met\n",
    "\n",
    "\n",
    "def get_eval_segment(df_one_file: pd.DataFrame, t_s: int, t_e: int) -> pd.DataFrame:\n",
    "    df = df_one_file.sort_values(\"cycle\").copy()\n",
    "    df = df[(df[\"cycle\"] >= t_s) & (df[\"cycle\"] <= t_e)].copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plotters\n",
    "# ============================================================\n",
    "def plot_ph_alpha_absolute_band(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    alpha: float,\n",
    "    out_path: str,\n",
    "    ph_start: Optional[float] = None,\n",
    "    title_prefix: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    BOOK Fig.2.9(a) 스타일: PH용 α-zone은 '절대 폭(평행 밴드)'\n",
    "      alphaZone = alpha * EOL_true\n",
    "      zone = RUL_true ± alphaZone\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].to_numpy()\n",
    "    y_true = df_eval[\"RUL_true\"].to_numpy()\n",
    "    y_pred = df_eval[\"RUL_pred\"].to_numpy()\n",
    "\n",
    "    last_cycle = int(df_eval[\"cycle\"].max())\n",
    "    eol_true = last_cycle + 1\n",
    "\n",
    "    alpha_zone = alpha * float(eol_true)  # ✅ book-style 핵심 (평행 밴드)\n",
    "    upper = y_true + alpha_zone\n",
    "    lower = y_true - alpha_zone\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, \"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, \"r\", label=\"Prediction (cycles)\")\n",
    "    plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α-zone (±α·EOL)\")\n",
    "    plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α-zone (±α·EOL)\")\n",
    "\n",
    "    if ph_start is not None and np.isfinite(ph_start):\n",
    "        plt.axvline(int(ph_start), color=\"g\", linestyle=\"-.\", label=\"PH start\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title_prefix} | BOOK-STYLE α+PH (absolute band)\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_alpha_lambda_relative_band(\n",
    "    df_eval: pd.DataFrame,\n",
    "    file_name: str,\n",
    "    alpha: float,\n",
    "    lambda_to_plot: float,\n",
    "    t_lambda: Optional[int],\n",
    "    out_path: str,\n",
    "    title_prefix: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    BOOK Fig.2.9(b) 스타일: α–λ는 '상대 폭(수렴 밴드)'\n",
    "      zone = RUL_true*(1±alpha), 그리고 t >= t_lambda 구간만 표시\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    x = df_eval[\"cycle\"].to_numpy()\n",
    "    y_true = df_eval[\"RUL_true\"].to_numpy()\n",
    "    y_pred = df_eval[\"RUL_pred\"].to_numpy()\n",
    "\n",
    "    upper = y_true * (1.0 + alpha)\n",
    "    lower = y_true * (1.0 - alpha)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y_true, \"k\", label=\"True (cycles)\")\n",
    "    plt.plot(x, y_pred, \"r\", label=\"Prediction (cycles)\")\n",
    "\n",
    "    if t_lambda is not None and np.isfinite(t_lambda):\n",
    "        t_lambda = int(t_lambda)\n",
    "        plt.axvline(t_lambda, color=\"g\", linestyle=\":\", label=f\"t_λ (λ={lambda_to_plot:.2f})\")\n",
    "\n",
    "        mask = x >= t_lambda\n",
    "        if np.any(mask):\n",
    "            plt.plot(x[mask], upper[mask], \"b--\", label=f\"+{alpha:.2f} α–λ zone\")\n",
    "            plt.plot(x[mask], lower[mask], \"b--\", label=f\"-{alpha:.2f} α–λ zone\")\n",
    "        else:\n",
    "            plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α zone\")\n",
    "            plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α zone\")\n",
    "    else:\n",
    "        plt.plot(x, upper, \"b--\", label=f\"+{alpha:.2f} α zone\")\n",
    "        plt.plot(x, lower, \"b--\", label=f\"-{alpha:.2f} α zone\")\n",
    "\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RUL (cycles)\")\n",
    "    plt.title(f\"{title_prefix} | BOOK-STYLE α–λ (relative band)\\n{file_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main (multi-split)\n",
    "# ============================================================\n",
    "def run_for_one_split(seed_dir: str, split: str):\n",
    "    df_seq, df_met = load_cycle_seq_and_metrics(seed_dir, split)\n",
    "\n",
    "    files = df_seq[\"file\"].unique().tolist()\n",
    "    if MAX_FILES is not None:\n",
    "        files = files[:MAX_FILES]\n",
    "\n",
    "    out_dir = os.path.join(OUT_ROOT, split)  # ✅ split별 폴더\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    lam_key = f\"t_lambda_{LAMBDA_TO_PLOT:.2f}\"\n",
    "    title_prefix = f\"SEED {SEED} | {CKPT.upper()} | {split} | Trial12\"\n",
    "\n",
    "    for f in files:\n",
    "        sub = df_seq[df_seq[\"file\"] == f].copy()\n",
    "        mrow = df_met[df_met[\"file\"] == f]\n",
    "        if mrow.empty:\n",
    "            continue\n",
    "        mrow = mrow.iloc[0].to_dict()\n",
    "\n",
    "        t_s = int(mrow[\"t_s\"])\n",
    "        t_e = int(mrow[\"t_e\"])\n",
    "        ph_start = mrow.get(\"t_PH_start\", np.nan)\n",
    "        t_lambda = mrow.get(lam_key, np.nan)\n",
    "\n",
    "        df_eval = get_eval_segment(sub, t_s, t_e)\n",
    "        if df_eval.empty:\n",
    "            continue\n",
    "\n",
    "        sname = safe_name(f)\n",
    "\n",
    "        out_a = os.path.join(out_dir, f\"FIG_A_BOOKSTYLE_alpha_PH__{sname}.png\")\n",
    "        plot_ph_alpha_absolute_band(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            alpha=ALPHA,\n",
    "            out_path=out_a,\n",
    "            ph_start=ph_start if np.isfinite(ph_start) else None,\n",
    "            title_prefix=title_prefix,\n",
    "        )\n",
    "\n",
    "        out_b = os.path.join(out_dir, f\"FIG_B_BOOKSTYLE_alpha_lambda__lam{LAMBDA_TO_PLOT:.2f}__{sname}.png\")\n",
    "        plot_alpha_lambda_relative_band(\n",
    "            df_eval=df_eval,\n",
    "            file_name=f,\n",
    "            alpha=ALPHA,\n",
    "            lambda_to_plot=LAMBDA_TO_PLOT,\n",
    "            t_lambda=int(t_lambda) if np.isfinite(t_lambda) else None,\n",
    "            out_path=out_b,\n",
    "            title_prefix=title_prefix,\n",
    "        )\n",
    "\n",
    "    print(f\"[{split}] DONE -> {out_dir}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.isdir(SEED_DIR):\n",
    "        raise FileNotFoundError(f\"Not found: {SEED_DIR}\")\n",
    "\n",
    "    # split별 실행\n",
    "    for split in SPLITS:\n",
    "        run_for_one_split(SEED_DIR, split)\n",
    "\n",
    "    print(\"\\nALL DONE.\")\n",
    "    print(\"Saved under:\", OUT_ROOT)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8784dfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT_DIR: ./Trial12\\seed_333\\best_by_val_norm\\xai_error_focused\\test\n",
      "Loaded windows: 8621\n",
      "High group: n=863 (thr_high=3065.911)\n",
      "Low  group: n=863 (thr_low =53.252)\n",
      "Saved stats: ./Trial12\\seed_333\\best_by_val_norm\\xai_error_focused\\test\\02_window_stats_high.csv ./Trial12\\seed_333\\best_by_val_norm\\xai_error_focused\\test\\02_window_stats_low.csv\n",
      "Saved mean±std plots.\n",
      "Saved exemplar overlays.\n",
      "Saved contrastive pairs: 30/30\n",
      "\n",
      "[DONE] Error-focused forensic pack saved to: ./Trial12\\seed_333\\best_by_val_norm\\xai_error_focused\\test\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ERROR-FOCUSED XAI / FORENSIC DEBUG (Trial12)\n",
    "# Goal:\n",
    "#  - \"왜 틀리는지\"를 window-level로 규명\n",
    "#\n",
    "# What it does:\n",
    "#  (1) High-error vs Low-error window 그룹을 만들고\n",
    "#  (2) raw min_vce / raw d_min_vce 파형 비교 (mean±std, exemplar overlay)\n",
    "#  (3) window 통계량 비교 (noise/variance/slope/monotonicity 등)\n",
    "#  (4) 어떤 파일/구간에서 에러가 집중되는지 (file ranking)\n",
    "#  (5) (옵션) high-error window와 \"비슷한 cycle의 low-error window\"를 매칭해서\n",
    "#      contrastive(쌍 비교) 파형을 저장\n",
    "#\n",
    "# Outputs:\n",
    "#  Trial12/seed_<seed>/<ckpt>/xai_error_focused/<split>/\n",
    "#    - 01_group_summary.csv\n",
    "#    - 02_window_stats_high.csv / 02_window_stats_low.csv\n",
    "#    - 03_file_error_ranking.csv\n",
    "#    - 10_meanstd_min_vce.png / 11_meanstd_d_min_vce.png\n",
    "#    - 12_exemplars_min_vce.png / 13_exemplars_d_min_vce.png\n",
    "#    - 20_pair_examples/PAIR_*.png   (contrastive pairs)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# USER CONFIG (Trial12)\n",
    "# ----------------------------\n",
    "DATA_DIR   = r\"C:\\Users\\11HOME_AHCI\\Desktop\\PoF\\Winter 2026\\Ref Data4\\100\"\n",
    "\n",
    "TRIAL_DIR  = r\"./Trial12\"          # ✅ Trial12 폴더\n",
    "SEED       = 333\n",
    "CKPT_TAG   = \"best_by_val_norm\"    # or \"last_epoch\"\n",
    "SPLIT      = \"test\"                # \"train\"/\"val\"/\"test\"\n",
    "\n",
    "SEQ_LEN      = 100\n",
    "PRED_HORIZON = 0\n",
    "\n",
    "# 그룹 정의\n",
    "ERROR_MODE = \"quantile\"     # \"quantile\" or \"fixed\"\n",
    "HIGH_Q = 0.90               # 상위 10%를 high-error\n",
    "LOW_Q  = 0.10               # 하위 10%를 low-error\n",
    "ERROR_FIXED = 300.0         # ERROR_MODE=\"fixed\"일 때 (cycles)\n",
    "\n",
    "# 샘플링/플롯\n",
    "N_EXEMPLARS_PER_GROUP = 30         # exemplar overlay 개수\n",
    "N_PAIRS_TO_SAVE = 30               # high-error window에 대해 low-error 매칭 pair 저장 개수\n",
    "PAIR_CYCLE_TOL = 200               # 같은 파일 내 cycle 차이 허용(대략 비슷한 stage 비교)\n",
    "\n",
    "# 저장 폴더\n",
    "OUT_DIR = os.path.join(TRIAL_DIR, f\"seed_{SEED}\", CKPT_TAG, \"xai_error_focused\", SPLIT)\n",
    "PAIR_DIR = os.path.join(OUT_DIR, \"20_pair_examples\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(PAIR_DIR, exist_ok=True)\n",
    "\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Helpers: load predictions_windows.csv\n",
    "# ============================================================\n",
    "seed_dir = os.path.join(TRIAL_DIR, f\"seed_{SEED}\")\n",
    "sub_dir = os.path.join(seed_dir, CKPT_TAG)\n",
    "\n",
    "win_csv = os.path.join(sub_dir, f\"{SPLIT}_predictions_windows.csv\")\n",
    "if not os.path.exists(win_csv):\n",
    "    raise FileNotFoundError(f\"Missing windows prediction CSV: {win_csv}\")\n",
    "\n",
    "dfw = pd.read_csv(win_csv)\n",
    "need_cols = [\"file\", \"start_idx\", \"cycle\", \"RUL_true\", \"RUL_pred\"]\n",
    "for c in need_cols:\n",
    "    if c not in dfw.columns:\n",
    "        raise ValueError(f\"windows CSV missing column: {c}\")\n",
    "\n",
    "dfw[\"abs_err\"] = np.abs(dfw[\"RUL_pred\"].values - dfw[\"RUL_true\"].values)\n",
    "dfw[\"signed_err\"] = (dfw[\"RUL_pred\"].values - dfw[\"RUL_true\"].values)\n",
    "print(\"Loaded windows:\", len(dfw))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Helpers: raw signal access\n",
    "# ============================================================\n",
    "_raw_cache: Dict[str, Tuple[np.ndarray, np.ndarray]] = {}\n",
    "\n",
    "def load_raw_file(file_name: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"returns (vce, rul) raw arrays\"\"\"\n",
    "    if file_name in _raw_cache:\n",
    "        return _raw_cache[file_name]\n",
    "    path = Path(DATA_DIR) / file_name\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing raw CSV: {path}\")\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    vce = df.iloc[:, 0].astype(np.float32).to_numpy()\n",
    "    rul = df.iloc[:, 1].astype(np.float32).to_numpy()\n",
    "    _raw_cache[file_name] = (vce, rul)\n",
    "    return vce, rul\n",
    "\n",
    "def compute_dvce(vce: np.ndarray) -> np.ndarray:\n",
    "    dv = np.zeros_like(vce, dtype=np.float32)\n",
    "    dv[1:] = vce[1:] - vce[:-1]\n",
    "    return dv\n",
    "\n",
    "def get_window_raw(file_name: str, start_idx: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    returns:\n",
    "      min_vce_window (SEQ_LEN,)\n",
    "      d_min_vce_window (SEQ_LEN,)\n",
    "    \"\"\"\n",
    "    vce, _rul = load_raw_file(file_name)\n",
    "    s = int(start_idx)\n",
    "    e = s + SEQ_LEN\n",
    "    if e > len(vce):\n",
    "        raise IndexError(f\"Window out of range: {file_name}, s={s}, e={e}, T={len(vce)}\")\n",
    "    w = vce[s:e].astype(np.float32)\n",
    "    dv = compute_dvce(vce)[s:e].astype(np.float32)\n",
    "    return w, dv\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Define high/low error groups\n",
    "# ============================================================\n",
    "if ERROR_MODE == \"quantile\":\n",
    "    thr_high = float(dfw[\"abs_err\"].quantile(HIGH_Q))\n",
    "    thr_low  = float(dfw[\"abs_err\"].quantile(LOW_Q))\n",
    "else:\n",
    "    thr_high = float(ERROR_FIXED)\n",
    "    thr_low  = float(ERROR_FIXED)  # fixed 모드면 low는 별도 정의가 애매해서 동일 임계값 사용\n",
    "\n",
    "df_high = dfw[dfw[\"abs_err\"] >= thr_high].copy()\n",
    "df_low  = dfw[dfw[\"abs_err\"] <= thr_low].copy()\n",
    "\n",
    "print(f\"High group: n={len(df_high)} (thr_high={thr_high:.3f})\")\n",
    "print(f\"Low  group: n={len(df_low)} (thr_low ={thr_low:.3f})\")\n",
    "\n",
    "# group summary\n",
    "summary_rows = [{\n",
    "    \"mode\": ERROR_MODE,\n",
    "    \"thr_high\": thr_high,\n",
    "    \"thr_low\": thr_low,\n",
    "    \"n_total\": len(dfw),\n",
    "    \"n_high\": len(df_high),\n",
    "    \"n_low\": len(df_low),\n",
    "    \"mean_abs_err_total\": float(dfw[\"abs_err\"].mean()),\n",
    "    \"mean_abs_err_high\": float(df_high[\"abs_err\"].mean()) if len(df_high) else np.nan,\n",
    "    \"mean_abs_err_low\":  float(df_low[\"abs_err\"].mean())  if len(df_low)  else np.nan,\n",
    "    \"mean_signed_err_high\": float(df_high[\"signed_err\"].mean()) if len(df_high) else np.nan,\n",
    "    \"mean_signed_err_low\":  float(df_low[\"signed_err\"].mean())  if len(df_low)  else np.nan,\n",
    "}]\n",
    "pd.DataFrame(summary_rows).to_csv(os.path.join(OUT_DIR, \"01_group_summary.csv\"), index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Window-level statistics (raw signal forensic)\n",
    "# ============================================================\n",
    "def window_stats(w_min_vce: np.ndarray, w_dvce: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    PHM 관점에서 '왜 틀리는지' 후보를 잡는 통계량들\n",
    "    \"\"\"\n",
    "    # min_vce stats\n",
    "    v_mean = float(np.mean(w_min_vce))\n",
    "    v_std  = float(np.std(w_min_vce))\n",
    "    v_rng  = float(np.max(w_min_vce) - np.min(w_min_vce))\n",
    "    v_slope = float((w_min_vce[-1] - w_min_vce[0]) / max(len(w_min_vce)-1, 1))\n",
    "\n",
    "    # dvce stats\n",
    "    d_mean = float(np.mean(w_dvce))\n",
    "    d_std  = float(np.std(w_dvce))\n",
    "    d_abs_mean = float(np.mean(np.abs(w_dvce)))\n",
    "    d_abs_max  = float(np.max(np.abs(w_dvce)))\n",
    "\n",
    "    # rough monotonicity score (min_vce)\n",
    "    diff = np.diff(w_min_vce)\n",
    "    mono = float(np.mean(diff >= 0.0))  # 증가 비율(0~1)\n",
    "\n",
    "    # spike ratio (dvce)\n",
    "    # \"dvce가 과하게 튀는 window는 모델이 헷갈릴 가능성\"\n",
    "    denom = (d_std + 1e-12)\n",
    "    spike_ratio = float(d_abs_max / denom)\n",
    "\n",
    "    return {\n",
    "        \"min_vce_mean\": v_mean,\n",
    "        \"min_vce_std\": v_std,\n",
    "        \"min_vce_range\": v_rng,\n",
    "        \"min_vce_slope\": v_slope,\n",
    "        \"min_vce_monotonicity\": mono,\n",
    "        \"dvce_mean\": d_mean,\n",
    "        \"dvce_std\": d_std,\n",
    "        \"dvce_abs_mean\": d_abs_mean,\n",
    "        \"dvce_abs_max\": d_abs_max,\n",
    "        \"dvce_spike_ratio\": spike_ratio,\n",
    "    }\n",
    "\n",
    "def build_stats_df(df_group: pd.DataFrame, max_rows: int = 5000, seed: int = 0) -> pd.DataFrame:\n",
    "    df = df_group.copy()\n",
    "    if len(df) > max_rows:\n",
    "        df = df.sample(n=max_rows, random_state=seed)\n",
    "\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        f = str(r[\"file\"])\n",
    "        s = int(r[\"start_idx\"])\n",
    "        try:\n",
    "            wv, wd = get_window_raw(f, s)\n",
    "            st = window_stats(wv, wd)\n",
    "            st.update({\n",
    "                \"file\": f,\n",
    "                \"start_idx\": s,\n",
    "                \"cycle\": int(r[\"cycle\"]),\n",
    "                \"abs_err\": float(r[\"abs_err\"]),\n",
    "                \"signed_err\": float(r[\"signed_err\"]),\n",
    "                \"RUL_true\": float(r[\"RUL_true\"]),\n",
    "                \"RUL_pred\": float(r[\"RUL_pred\"]),\n",
    "            })\n",
    "            rows.append(st)\n",
    "        except Exception as e:\n",
    "            # window out-of-range 등 예외 방어\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_high_stats = build_stats_df(df_high, max_rows=5000, seed=0)\n",
    "df_low_stats  = build_stats_df(df_low,  max_rows=5000, seed=1)\n",
    "\n",
    "df_high_stats.to_csv(os.path.join(OUT_DIR, \"02_window_stats_high.csv\"), index=False)\n",
    "df_low_stats.to_csv(os.path.join(OUT_DIR, \"02_window_stats_low.csv\"), index=False)\n",
    "\n",
    "print(\"Saved stats:\",\n",
    "      os.path.join(OUT_DIR, \"02_window_stats_high.csv\"),\n",
    "      os.path.join(OUT_DIR, \"02_window_stats_low.csv\"))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) File ranking: 에러가 특정 파일에 몰리는지\n",
    "# ============================================================\n",
    "file_rank = dfw.groupby(\"file\", as_index=False).agg(\n",
    "    n_windows=(\"abs_err\", \"count\"),\n",
    "    mean_abs_err=(\"abs_err\", \"mean\"),\n",
    "    p90_abs_err=(\"abs_err\", lambda x: float(np.quantile(x, 0.90))),\n",
    "    max_abs_err=(\"abs_err\", \"max\"),\n",
    ").sort_values(\"mean_abs_err\", ascending=False)\n",
    "\n",
    "file_rank.to_csv(os.path.join(OUT_DIR, \"03_file_error_ranking.csv\"), index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Plot: High vs Low mean±std trajectories (raw)\n",
    "# ============================================================\n",
    "def sample_windows(df_group: pd.DataFrame, n: int, seed: int) -> List[Tuple[str,int]]:\n",
    "    if df_group.empty:\n",
    "        return []\n",
    "    df_s = df_group.sample(n=min(n, len(df_group)), random_state=seed)\n",
    "    return [(str(r[\"file\"]), int(r[\"start_idx\"])) for _, r in df_s.iterrows()]\n",
    "\n",
    "def collect_windows(pairs: List[Tuple[str,int]]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    Wv, Wd = [], []\n",
    "    for f,s in pairs:\n",
    "        try:\n",
    "            wv, wd = get_window_raw(f, s)\n",
    "            Wv.append(wv)\n",
    "            Wd.append(wd)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if len(Wv) == 0:\n",
    "        raise ValueError(\"No windows collected for plotting.\")\n",
    "    return np.stack(Wv, axis=0), np.stack(Wd, axis=0)\n",
    "\n",
    "high_pairs = sample_windows(df_high, n=2000, seed=0)\n",
    "low_pairs  = sample_windows(df_low,  n=2000, seed=1)\n",
    "\n",
    "Wv_h, Wd_h = collect_windows(high_pairs)\n",
    "Wv_l, Wd_l = collect_windows(low_pairs)\n",
    "\n",
    "t = np.arange(SEQ_LEN)\n",
    "\n",
    "def plot_meanstd(title: str, y_h: np.ndarray, y_l: np.ndarray, ylabel: str, out_path: str) -> None:\n",
    "    # y_* shape: (N, T)\n",
    "    m_h = np.mean(y_h, axis=0); s_h = np.std(y_h, axis=0)\n",
    "    m_l = np.mean(y_l, axis=0); s_l = np.std(y_l, axis=0)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t, m_h, label=\"High-error mean\")\n",
    "    plt.fill_between(t, m_h - s_h, m_h + s_h, alpha=0.2)\n",
    "\n",
    "    plt.plot(t, m_l, label=\"Low-error mean\")\n",
    "    plt.fill_between(t, m_l - s_l, m_l + s_l, alpha=0.2)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"t in window\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "plot_meanstd(\n",
    "    title=f\"High vs Low Error | mean±std | min_vce (raw) | {SPLIT}\",\n",
    "    y_h=Wv_h, y_l=Wv_l,\n",
    "    ylabel=\"min_vce\",\n",
    "    out_path=os.path.join(OUT_DIR, \"10_meanstd_min_vce.png\")\n",
    ")\n",
    "plot_meanstd(\n",
    "    title=f\"High vs Low Error | mean±std | d_min_vce (raw) | {SPLIT}\",\n",
    "    y_h=Wd_h, y_l=Wd_l,\n",
    "    ylabel=\"d_min_vce\",\n",
    "    out_path=os.path.join(OUT_DIR, \"11_meanstd_d_min_vce.png\")\n",
    ")\n",
    "\n",
    "print(\"Saved mean±std plots.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Plot: Exemplars overlay (raw)\n",
    "# ============================================================\n",
    "def plot_exemplars(df_group: pd.DataFrame, n: int, seed: int, mode: str, out_path: str, which: str):\n",
    "    if df_group.empty:\n",
    "        return\n",
    "    df_s = df_group.sample(n=min(n, len(df_group)), random_state=seed)\n",
    "\n",
    "    plt.figure()\n",
    "    for _, r in df_s.iterrows():\n",
    "        f = str(r[\"file\"]); s = int(r[\"start_idx\"])\n",
    "        try:\n",
    "            wv, wd = get_window_raw(f, s)\n",
    "            y = wv if which == \"min_vce\" else wd\n",
    "            plt.plot(t, y, alpha=0.25)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    plt.title(f\"{mode} exemplars overlay | {which} (raw) | {SPLIT}\")\n",
    "    plt.xlabel(\"t in window\")\n",
    "    plt.ylabel(which)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "plot_exemplars(df_high, N_EXEMPLARS_PER_GROUP, 0, \"High-error\", os.path.join(OUT_DIR, \"12_exemplars_min_vce.png\"), \"min_vce\")\n",
    "plot_exemplars(df_high, N_EXEMPLARS_PER_GROUP, 0, \"High-error\", os.path.join(OUT_DIR, \"13_exemplars_d_min_vce.png\"), \"d_min_vce\")\n",
    "plot_exemplars(df_low,  N_EXEMPLARS_PER_GROUP, 1, \"Low-error\",  os.path.join(OUT_DIR, \"14_exemplars_min_vce.png\"), \"min_vce\")\n",
    "plot_exemplars(df_low,  N_EXEMPLARS_PER_GROUP, 1, \"Low-error\",  os.path.join(OUT_DIR, \"15_exemplars_d_min_vce.png\"), \"d_min_vce\")\n",
    "\n",
    "print(\"Saved exemplar overlays.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Contrastive Pairs: high-error window와 \"같은 파일에서 비슷한 cycle\" low-error window 매칭\n",
    "# ============================================================\n",
    "# low 그룹을 파일별로 인덱싱해두면 빠르게 매칭 가능\n",
    "low_by_file: Dict[str, pd.DataFrame] = {}\n",
    "for f, sub in df_low.groupby(\"file\"):\n",
    "    low_by_file[str(f)] = sub.copy().sort_values(\"cycle\")\n",
    "\n",
    "def find_low_match(file_name: str, cycle: int, tol: int) -> Dict:\n",
    "    \"\"\"\n",
    "    같은 파일 내에서 cycle이 비슷한 low-error window를 찾는다.\n",
    "    \"\"\"\n",
    "    if file_name not in low_by_file:\n",
    "        return {}\n",
    "    sub = low_by_file[file_name]\n",
    "    # cycle 차이 최소\n",
    "    idx = np.argmin(np.abs(sub[\"cycle\"].values - int(cycle)))\n",
    "    cand = sub.iloc[int(idx)].to_dict()\n",
    "    if abs(int(cand[\"cycle\"]) - int(cycle)) <= tol:\n",
    "        return cand\n",
    "    return {}\n",
    "\n",
    "df_high_sorted = df_high.sort_values(\"abs_err\", ascending=False).copy()\n",
    "saved = 0\n",
    "\n",
    "for _, r in df_high_sorted.iterrows():\n",
    "    if saved >= N_PAIRS_TO_SAVE:\n",
    "        break\n",
    "    f = str(r[\"file\"])\n",
    "    cyc = int(r[\"cycle\"])\n",
    "    match = find_low_match(f, cyc, PAIR_CYCLE_TOL)\n",
    "    if not match:\n",
    "        continue\n",
    "\n",
    "    s_hi = int(r[\"start_idx\"])\n",
    "    s_lo = int(match[\"start_idx\"])\n",
    "\n",
    "    try:\n",
    "        v_hi, d_hi = get_window_raw(f, s_hi)\n",
    "        v_lo, d_lo = get_window_raw(f, s_lo)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    # pair plot\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(t, v_hi, label=f\"HIGH (abs_err={float(r['abs_err']):.1f}, cycle={cyc}, s={s_hi})\")\n",
    "    plt.plot(t, v_lo, label=f\"LOW  (abs_err={float(match['abs_err']):.1f}, cycle={int(match['cycle'])}, s={s_lo})\")\n",
    "    plt.title(f\"PAIR {saved+1:02d} | file={f} | min_vce (raw)\")\n",
    "    plt.xlabel(\"t in window\"); plt.ylabel(\"min_vce\"); plt.grid(True); plt.legend()\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(t, d_hi, label=\"HIGH d_min_vce\")\n",
    "    plt.plot(t, d_lo, label=\"LOW  d_min_vce\")\n",
    "    plt.xlabel(\"t in window\"); plt.ylabel(\"d_min_vce\"); plt.grid(True); plt.legend()\n",
    "\n",
    "    safe_f = f.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "\n",
    "    outp = os.path.join(\n",
    "        PAIR_DIR,\n",
    "        f\"PAIR_{saved+1:02d}__{safe_f}__cycle{cyc}.png\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outp, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    saved += 1\n",
    "\n",
    "print(f\"Saved contrastive pairs: {saved}/{N_PAIRS_TO_SAVE}\")\n",
    "print(\"\\n[DONE] Error-focused forensic pack saved to:\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igbt_rnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
